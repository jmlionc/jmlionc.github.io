---
title: "M√≥dulo 7: M√©todos de Regresi√≥n"
subtitle: "Bioestad√≠stica Fundamental y Estad√≠stica Fundamental para las Ciencias de la Salud"
author: 
- name: "Jose Miguel Leon Puentes"
  affiliation: "Departamento de Estad√≠stica"
institute: "Universidad Nacional de Colombia"
format:
  html:
    theme: cosmo
    toc: true
    toc-depth: 4
    toc-title: Tabla de Contenido
    other-links:
      - text: Contacto
        icon: mailbox
        href: mailto:joleonp@unal.edu.co
    code-links:
      - text: GitHub
        icon: github
        href: https://github.com/jmlionc/AppliedBiostats

editor: visual
---

## üî∞ Introducci√≥n

::: {style="text-align: justify;"}
El an√°lisis de regresi√≥n es una herramienta fundamental en bioestad√≠stica para estudiar la relaci√≥n entre una variable respuesta y una o m√°s variables explicativas. En este m√≥dulo nos enfocaremos en el modelo lineal simple o normal, uno de los m√©todos m√°s utilizados para describir y predecir relaciones lineales entre variables cuantitativas.

A lo largo del m√≥dulo, se abordar√° la formulaci√≥n te√≥rica del modelo, los supuestos que lo sustentan, y los m√©todos necesarios para su ajuste e interpretaci√≥n en el entorno de programaci√≥n `R`. Adem√°s, se explorar√°n herramientas diagn√≥sticas que permiten evaluar la validez del modelo, identificar observaciones at√≠picas o influyentes, y proponer posibles transformaciones cuando los supuestos no se cumplen.

El enfoque de este m√≥dulo estar√° orientado a darle las herramientas necesarias para que pueda realizar una implementaci√≥n del modelo con datos reales, un an√°lisis de la salida generada por R e interpretar adecuadamente los resultados en contextos aplicados de la bioestad√≠stica.
:::

## üéØ Objetivos

1.  Formular e interpretar el modelo lineal simple bajo el enfoque cl√°sico y sus supuestos fundamentales.

2.  Ajustar el modelo lineal simple utilizando funciones del entorno R.

3.  Seleccionar variables explicativas relevantes para el modelo.

4.  Analizar los residuos y coeficientes del modelo para evaluar su ajuste.

5.  Interpretar los par√°metros estimados y la calidad global del modelo.

6.  Aplicar t√©cnicas diagn√≥sticas para detectar problemas como heterocedasticidad, colinealidad, influencia y puntos de apalancamiento, proponiendo soluciones mediante transformaciones cuando sea necesario.

## üß∞ Contenido

1.  Selecci√≥n de variables

2.  Ajuste del modelo

3.  Informaci√≥n de los residuos

4.  Informaci√≥n sobre los coeficientes

5.  Informaci√≥n sobre el modelo

6.  Interpretaci√≥n de los resultados

7.  M√©todos diagn√≥sticos\
    7.1. An√°lisis residual\
    7.2. An√°lisis de sensibilidad o influencia\
    7.3. Puntos de apalancamiento\
    7.4. Heterocedasticidad\
    7.5. Colinealidad\
    7.6 Transformaciones

## üìñ Desarrollo

### Modelo Lineal

#### 1. Formulaci√≥n y supuestos

En un **modelo de regresi√≥n lineal simple** se estudia la relaci√≥n entre una variable dependiente $Y$ y una sola variable explicativa $X$:

$$Y_i=\beta_0+\beta_1X_i+\varepsilon_i \quad i=1,2,\dots, n$$

donde:

-   $Y_i:$ variable respuesta para la observaci√≥n $i$.

-   $X_i:$ variable explicativa para la observaci√≥n $i$.

-   $\beta_0:$ intercepto o t√©rmino constante.

-   $\beta_1:$ pendiente, mide el cambio esperado en $Y$ por un cambio unitario en $X$.

-   $\varepsilon_i:$ t√©rmino de error aleatorio.

En un **modelo de regresi√≥n lineal m√∫ltiple** se estudia la relaci√≥n entre una variable dependiente $Y$ y una varias variables explicativas $(X_1, X_2, \dots, X_p)$ :

$$Y_i=\beta_0+\beta_1X_{i1}+\beta_2X_{i2}+\cdots+\beta_pX_{ip}+\varepsilon_i \quad i=1,2,\dots, n$$ Cuya forma matricial est√° dada por:

$$\mathbf{Y} = \mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}$$ donde:

-   $\mathbf{Y}$ es un vector $n\times1$ de la variable dependiente.

-   $\mathbf{Y}$ es la matriz de dise√±o $(n\times(p+1))$, que incluye una columna de 1's para el intercepto.

-   $\boldsymbol{\beta}$ es el vector de par√°metros $(p+1)\times1$

-   $\boldsymbol{\varepsilon}$ es el vector de errores aleatorios

Algunos de los supuestos b√°sicos de la regresi√≥n lineal son los siguientes:

1.  Linealidad: la relaci√≥n entre $X$ y $Y$ es lineal.

2.  Independencia: los errores son independientes entre s√≠.

3.  Homoscedasticidad: la varianza de los errores es constante.

4.  No multicolinealidad (solo en modelos m√∫ltiples).

5.  Normalidad de los errores (opcional, seg√∫n el objetivo).

Sobre este √∫ltimo supuesto, no es necesario para estimar los coeficientes $(\hat{\beta}_0,\hat{\beta}_1)$ ya que gracias al teorema de Gauss‚ÄìMarkov, bajo los tres primeros supuestos los estimadores son insesgados y de varianza m√≠nima (BLUE). Sin embargo, s√≠ es necesario para la inferencia estad√≠stica: pruebas de significancia y construcci√≥n de intervalos de confianza.

Si nos limitamos a estimar los coeficientes, a√∫n podremos:

-   Predecir valores de $Y$ para nuevos $X$ a√∫n sin saber si la pendiente es "significativamente distinta de cero".

-   Describir la relaci√≥n observada, el coeficiente pendiente indica cu√°nto cambia $Y$ en promedio cuando $X$ cambia una unidad, en la muestra observada, sin necesidad de inferir a la poblaci√≥n.

-   Revisar el ajuste global del modelo (R¬≤, residuos, etc.)

Luego, si el prop√≥sito es predecir o describir, basta con estimar coeficientes, pero si se desea generalizar a la poblaci√≥n o validar hip√≥tesis, requerimos inferencia, por efecto, normalidad o tama√±o de muestra "grande" para que de manera asint√≥tica esta sea respaldada por el teorema central del l√≠mite.

#### 2. Comentarios sobre la interpretaci√≥n de las salidas de R

-   Evaluar el efecto del termino interacci√≥n en el modelo, es esencialmente, examinar si el efecto de una variable en el resultado depende de los valores de otra variable.

-   El resultado de un modelo de regresi√≥n en `R` al hacer uso de la rutina `summary(modelo)` consiste en 4 partes:

    -   **Formula del modelo ajustado**

    -   **Estad√≠stica descriptiva de los residuos\
        **Este resumen estad√≠stico de los residuos, representa las diferencias entre las predicciones del modelo y las observaciones reales. Los residuos muestran que tan bien no se ajusta el modelo. La media de los residuos siempre es cero. Si los residuos se distribuyen con distribuci√≥n normal, la mediana se espera que sea cero o un valor muy cercano a este, el primer y tercer cuartil sean sim√©tricos al igual que el m√≠nimo y el m√°ximo.

    -   **Informaci√≥n sobre coeficientes\
        **Esta secci√≥n muestra 4 apartados que se detallan a continuaci√≥n:

        -   Coeficientes estimados (*"`ESTIMATE`"*): contiene los valores de cada variable explicatoria que representan el efecto de esa variable sobre la variable dependiente.

        -   Errores est√°ndar ("`Std. Error`"): es el valor que mide que tan precisa es la estimaci√≥n de cada coeficiente. Valores altos indican que la predicci√≥n es menos precisa.

        -   Valores t ("`t-values`"): valor estad√≠stico para probar que el coeficiente no es cero. Un valor positivo o negativo indica que el coeficiente no es cero. Entre m√°s grande el valor, se indica que el coeficiente es mas fiable. $t=estimate/std. error$

        -   Valores p ("`p-values`"): indican la probabilidad de obtener un resultado tan extremo como el observado (o m√°s), suponiendo que la hip√≥tesis nula es verdadera. En el caso de un coeficiente de regresi√≥n, la hip√≥tesis nula plantea que dicho coeficiente es igual a cero (es decir, que la variable no tiene efecto).

            Si el $valor-p < 0.05$, existe evidencia estad√≠sticamente significativa al nivel del 5% para rechazar la hip√≥tesis nula y concluir que el coeficiente es distinto de cero.

    -   **Informaci√≥n sobre el modelo**

-   La interpretaci√≥n de los coeficientes se suele dar como sigue: Un incremento de una unidad en la variable distancia, causa un incremento de 4.96 unidades.

-   El intercepto representa el valor predicho de la variable dependiente cuando las otras variables son cero.

-   La linealidad del modelo est√° dada por los coeficientes (los $\beta$'s) mas no hay restricciones de la naturaleza de las covariables respecto a esta caracter√≠stica.

-   El sistema de hip√≥tesis para los coeficientes es el siguiente:

    $$H_0:\beta_j=\beta_j¬∞ \quad \text{vs} \quad H_1:\beta_j\neq\beta_j¬∞$$

    la regla de decisi√≥n para el anterior sistema de hip√≥tesis es:

    Rechazar H_0 con un nivel de significancia de $100(\alpha)\%$ si $p-value < \alpha$

    De aqu√≠, el error tipo 1 consiste en rechazar $H_0$ cuando ella es verdadera y el error tipo 2 consiste en no rechazar $H_0$ cuando es falsa.

-   Existen varias rutinas disponibles en `R` para seleccionar variables significativas. algunas de estas son:

    **Best Subset Selection**

    ```{r}
    #| eval: false
    library(leaps)
    fit_a <- regsubsets(Y ~ ., data = datos, nvmax = 10)  # hasta 10 predictores
    summary(fit_a)
    ```

    **Selecci√≥n paso a paso (Stepwise Selection)**

    ```{r}
    #| eval: false
    library(glmtoolbox)
    data(Auto, package = "ISLR")
    fit_b <- lm(mpg ~ horsepower + weight +origin, data = Auto)  
    stepCriterion(fit_b, direction="forward", criterion="bic")
    ```

#### 3. Ejemplo 1: *races - glmtoolbox*

Estos datos, disponibles en el objeto "races" de la biblioteca "glmtoolbox", consisten en el tiempo r√©cord, la distancia y la subida acumulada de 35 carreras en cuesta en Escocia. El objetivo del an√°lisis estad√≠stico de estos datos es explicar las diferencias entre el tiempo r√©cord de las carreras (rtime), en minutos, utilizando sus diferencias en distancia (distance), en millas, y subida acumulada (cclimb), en miles de pies.

```{r warning=FALSE}
library(glmtoolbox) 
data(races)
```

1.  Ajuste a los datos un modelo lineal normal en el que el tiempo r√©cord de las carreras sea la variable de respuesta, y la distancia y la subida acumulada sean las variables explicativas.

```{r glmtoolbox}
fit <- lm(rtime ~ distance + cclimb, data = races)
```

2.  Eval√∫e al nivel de signiÔ¨Åcancia del 5% si el efecto de la distancia sobre el tiempo r√©cord esperado de la carrera depende de la escalada acumulada.

```{r}
fit2 <- lm(rtime ~ distance + cclimb + distance:cclimb, data = races)
summary(fit2)
anova(fit,fit2)
```

3.  Interprete las estimaciones de los par√°metros, excepto el t√©rmino de intercepci√≥n.

Interpretaci√≥n de la estimaci√≥n de distacia: Por cada milla recorrida se incrementan 4.96 minutos en el tiempo record manteniendo constante la subida acumulada en la carrera. Altamente significante para un nivel del 5%.

Interpretaci√≥n de la estimacion de subida acumulada: Por cada mil pies que se suban hay un incremento de 3.71 minutos en el tiempo tiempo record manteniendo constante la distancia que se recorre en la carrera. Sin embargo el p-valor no es significante para un nivel del 5%.

Interpretaci√≥n de la estimacion de la interacci√≥n entre distancia y subida acumulada: Por cada unidad incrementada en la interacci√≥n entre distancia y subida acumulada, el cambio esperado en el tiempo record ser√° aproximadamente de 0.66 unidades, manteniendo las otras variables constantes.

4.  Estime el tiempo r√©cord esperado, en minutos, de una carrera cuya distancia y ascenso acumulado son 7.5 millas y 1800 pies, respectivamente. Calcule esta estimaci√≥n "manualmente" y utilizando la funci√≥n predict()

Manualmente:

```{r}
fit$coefficients

distance <- 7.5
cclimb <- 1.8

rtime = -13.108551 + 6.350955*distance + 11.780133*cclimb
rtime
```

Usando la funci√≥n predict()

```{r}
new_distance <- 7.5
new_cclimb <- 1.8

y <- predict(fit, newdata = data.frame(distance=new_distance, cclimb=new_cclimb))

y
```

#### 4. Ejemplo 2: *whiteside - MASS*

Estos datos, disponibles en el objeto whiteside de la biblioteca MASS, se recopilaron para evaluar el efecto del aislamiento en el consumo de gas. El consumo semanal de gas (Gas), en miles de pies c√∫bicos, y la temperatura exterior media (Temp), en grados cent√≠grados, se registraron durante 26 semanas antes (Insul="Antes") y durante 30 semanas despu√©s (Insul="Despu√©s") de que se instalara un aislamiento de la pared hueca de una casa.

```{r}
library(MASS)
data("whiteside")
```

1.  Ajuste a los datos un modelo lineal normal en el que el consumo de gas sea la variable de respuesta, y la temperatura exterior media y la presencia/ausencia de aislamiento de la pared de la cavidad sean las variables explicativas.

    ```{r}
    fit3 <- lm(Gas ~ Temp + Insul, data = whiteside)
    ```

    $$
    Gas = 6.55133 ‚àí 0.33670(Temp) ‚àí 1.56520
    $$

2.  Eval√∫e al nivel de signiÔ¨Åcancia del 5% si el efecto de la temperatura exterior media sobre el consumo de gas esperado depende de la presencia/ausencia de aislamiento en la pared.

    ```{r}
    fit4 <- lm(Gas ~ Temp*Insul, data = whiteside)
    summary(fit4)
    anova(fit4)
    ```

    Al nivel de significancia del 5%, existe evidencia estad√≠sticamente significativa (0.00073 \< 0.05) de que el impacto de un incremento en la temperatura exterior media sobre el consumo de gas depende de la presencia/ausencia de aislamiento en la pared. El consumo de gas esperado disminuye tras la instalaci√≥n del aislamiento, pero la velocidad a la que ocurre esta disminuci√≥n se acent√∫a a medida que la temperatura aumenta.

3.  Interprete las estimaciones de los par√°metros excepto el t√©rmino de intercepci√≥n.

    Interpretaci√≥n de la estimaci√≥n de la temperatura: Por cada grado centr√≠grado que se incrementa la temperatura exterior, se disminuyen 0.39324 miles de pies c√∫bicos en el consumo semanal de gas. Altamente significante para un nivel del 5%.\

    Interpretaci√≥n de la estimacion de la instalaci√≥n del aislamiento (despu√©s): Tras la instalacion del aislamiento de la pared hueca de la casa, se disminuyen 2.12998 miles de pies c√∫bico en el consumo de gas semanal esperado, controlando por temperatura. Altamente significante para un nivel del 5%.\

    Interpretaci√≥n de la interacci√≥n entre estimacion de la temperatura e instalaci√≥n del aislamiento (despu√©s): La velocidad a la que disminuye el consumo de gas semanal es diferente con la ausencia o presencia de aislameinto en la pared de la casa. El cambio esperado en el consumo de gas semanal esperado sera de 0.1153 unidades posterior a la instalaci√≥n del aislamiento e incrementando la temperatura una unidad.

4.  Estime el consumo de gas esperado, en miles de pies c√∫bicos, en una semana en la que la temperatura exterior media sea de 5 grados cent√≠grados y el aislamiento de la pared est√© presente. Calcule esta estimaci√≥n "manualmente" y utilizando la funci√≥n predict(). \##### 2.1 Selecci√≥n de variables

    4.1 [Estimaci√≥n manual]{.underline} :

    ```{r}
    fit3$coefficients
    Temp <- 5
    InsulAfter <- 1
    Gas = 6.551329 + -0.336697*Temp - 1.565205*InsulAfter
    Gas
    ```

    4.2 [Estimaci√≥n con funci√≥n `predict()`]{.underline} :

    ```{r}
    new_Temp <- 5
    y <- predict(fit3, newdata = data.frame(Temp = new_Temp, Insul = "After"))
    y
    ```

    En una semana, donde la temperatura promedio exterior es de 5¬∞C y el aislamiento en la pared hueca de la casa ya se encuentra instalado, el consumo de gas estimado ser√° de 3.3026 miles de pies c√∫bicos.

::: {style="text-align: center;"}
Copyright ¬© 2025 Jose Miguel Leon - Created with [Quarto](https://quarto.org)
:::
