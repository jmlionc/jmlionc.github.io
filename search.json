[
  {
    "objectID": "teaching.html",
    "href": "teaching.html",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "",
    "text": "Este programa est√° dirigido a estudiantes de diversas √°reas del conocimiento que est√©n interesados en la aplicaci√≥n de conceptos estad√≠sticos a trav√©s del software RStudio, una de las herramientas m√°s utilizadas a nivel mundial en investigaci√≥n, docencia y an√°lisis de datos. El curso se enfoca en la ense√±anza pr√°ctica de la Estad√≠stica Fundamental, asignatura que conforman la oferta acad√©mica del Departamento de Estad√≠stica en el nivel de pregrado de la Facultad de Ciencias de la Universidad Nacional de Colombia Sede Bogot√°.\nLa propuesta de este curso es brindar al estudiante una gu√≠a pr√°ctica que complemente el aprendizaje te√≥rico recibido en clase. A lo largo de los m√≥dulos se presentar√°n ejemplos, bases de datos y ejercicios que permitir√°n afianzar la comprensi√≥n de los temas y, sobre todo, adquirir destrezas en el uso de R para el an√°lisis estad√≠stico.\nEs importante destacar que este curso tiene un car√°cter acad√©mico complementario y en ning√∫n momento reemplaza ni sustituye las clases programadas por el docente de la asignatura. Ante dudas conceptuales, ser√° indispensable consultar con el profesor encargado, dado que la claridad en los fundamentos te√≥ricos es esencial para llevar a cabo la correcta implementaci√≥n de los procedimientos estad√≠sticos en R.\nSe recomienda avanzar en paralelo con los contenidos de la asignatura, replicando los ejemplos y ejercicios de cada m√≥dulo conforme se desarrollen los temas en clase. De esta manera, al finalizar el curso el estudiante no solo comprender√° los conceptos fundamentales de la estad√≠stica, sino que tambi√©n adquirir√° habilidades pr√°cticas para aplicar estos conocimientos en diferentes contextos acad√©micos y profesionales, desde proyectos de investigaci√≥n hasta an√°lisis de datos en entornos laborales."
  },
  {
    "objectID": "teaching.html#introducci√≥n",
    "href": "teaching.html#introducci√≥n",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "",
    "text": "Este programa est√° dirigido a estudiantes de diversas √°reas del conocimiento que est√©n interesados en la aplicaci√≥n de conceptos estad√≠sticos a trav√©s del software RStudio, una de las herramientas m√°s utilizadas a nivel mundial en investigaci√≥n, docencia y an√°lisis de datos. El curso se enfoca en la ense√±anza pr√°ctica de la Estad√≠stica Fundamental, asignatura que conforman la oferta acad√©mica del Departamento de Estad√≠stica en el nivel de pregrado de la Facultad de Ciencias de la Universidad Nacional de Colombia Sede Bogot√°.\nLa propuesta de este curso es brindar al estudiante una gu√≠a pr√°ctica que complemente el aprendizaje te√≥rico recibido en clase. A lo largo de los m√≥dulos se presentar√°n ejemplos, bases de datos y ejercicios que permitir√°n afianzar la comprensi√≥n de los temas y, sobre todo, adquirir destrezas en el uso de R para el an√°lisis estad√≠stico.\nEs importante destacar que este curso tiene un car√°cter acad√©mico complementario y en ning√∫n momento reemplaza ni sustituye las clases programadas por el docente de la asignatura. Ante dudas conceptuales, ser√° indispensable consultar con el profesor encargado, dado que la claridad en los fundamentos te√≥ricos es esencial para llevar a cabo la correcta implementaci√≥n de los procedimientos estad√≠sticos en R.\nSe recomienda avanzar en paralelo con los contenidos de la asignatura, replicando los ejemplos y ejercicios de cada m√≥dulo conforme se desarrollen los temas en clase. De esta manera, al finalizar el curso el estudiante no solo comprender√° los conceptos fundamentales de la estad√≠stica, sino que tambi√©n adquirir√° habilidades pr√°cticas para aplicar estos conocimientos en diferentes contextos acad√©micos y profesionales, desde proyectos de investigaci√≥n hasta an√°lisis de datos en entornos laborales."
  },
  {
    "objectID": "teaching.html#objetivos",
    "href": "teaching.html#objetivos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üèÅ Objetivos",
    "text": "üèÅ Objetivos\n\nüèÜ Objetivo General\n\nFortalecer la comprensi√≥n y aplicaci√≥n de los conceptos fundamentales de la estad√≠stica mediante el uso del software RStudio, promoviendo un aprendizaje pr√°ctico y aut√≥nomo que complemente la formaci√≥n te√≥rica de los estudiantes universitarios.\n\n\n\nüéØ Objetivos Especificos\n\n\nFamiliarizar al estudiante con el entorno de R y RStudio como herramienta de an√°lisis estad√≠stico.\nDesarrollar competencias en la importaci√≥n, manipulaci√≥n y organizaci√≥n de bases de datos.\nAplicar m√©todos de an√°lisis descriptivo y exploratorio para la caracterizaci√≥n de datos.\nIntroducir los fundamentos de la probabilidad y su aplicaci√≥n en el an√°lisis estad√≠stico.\nComprender e implementar t√©cnicas b√°sicas de inferencia estad√≠stica en R.\nExplorar modelos de regresi√≥n como herramientas de an√°lisis y predicci√≥n.\nMotivar la aplicaci√≥n de los m√©todos estad√≠sticos en problemas de diversas disciplinas acad√©micas y profesionales."
  },
  {
    "objectID": "teaching.html#estructura-de-los-m√≥dulos",
    "href": "teaching.html#estructura-de-los-m√≥dulos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üß± Estructura de los m√≥dulos",
    "text": "üß± Estructura de los m√≥dulos\n\nCada uno de los m√≥dulos est√° dise√±ado bajo una estructura clara y progresiva que busca facilitar la comprensi√≥n y aplicaci√≥n de los contenidos. La organizaci√≥n incluye:\n\nIntroducci√≥n a la Tem√°tica: contextualizaci√≥n del tema, su importancia dentro de la bioestad√≠stica y la justificaci√≥n de su aplicaci√≥n en R.\nObjetivos del M√≥dulo: enunciado de las metas de aprendizaje que el estudiante debe alcanzar al finalizar el trabajo con el m√≥dulo.\nDesarrollo del Contenido: explicaciones detalladas acompa√±adas de ejemplos pr√°cticos en R, anotaciones te√≥ricas de apoyo, consejos t√©cnicos y recomendaciones para el uso eficiente del software.\nActividades de Aplicaci√≥n: ejercicios guiados y aut√≥nomos orientados a la pr√°ctica, que permiten al estudiante comprobar su comprensi√≥n y afianzar el aprendizaje.\nTareas y Repaso: conjunto de actividades de evaluaci√≥n y autoevaluaci√≥n que refuerzan lo aprendido y preparan al estudiante para avanzar al siguiente m√≥dulo."
  },
  {
    "objectID": "teaching.html#m√≥dulos",
    "href": "teaching.html#m√≥dulos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üìö M√≥dulos",
    "text": "üìö M√≥dulos\n\nA continuaci√≥n se presentan los m√≥dulos que conforman el curso Bioestad√≠stica Fundamental Aplicada en R.\n\nüß† M√≥dulo 1: Introducci√≥n al programa\nüñ•Ô∏è M√≥dulo 2:Introducci√≥n al Software RStudio\nüßÆ M√≥dulo 3: Manipulaci√≥n de Bases de Datos\nüìä M√≥dulo 4: An√°lisis Descriptivo y Exploratorio\nüé≤ M√≥dulo 5: Probabilidad\nüí≠ M√≥dulo 6: Inferencia Estad√≠stica\nüîÆ M√≥dulo 7: M√©todos de Regresi√≥n\n\n\n\n\n\n\n\n\nüöß Acerca de\n\n\n\n\n\nEste proyecto ha sido elaborado por Jos√© Miguel Le√≥n Puentes (Teaching Assistant) durante el primer semestre acad√©mico del a√±o 2025 y se encontrar√° en continua construcci√≥n y supervisi√≥n por parte del autor.\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jose Miguel Leon P.",
    "section": "",
    "text": "Jose Miguel Leon P.\n\n Email\n GitHub\n LinkedIn\n ORCID\n\n\n\n\nAbout me\nI am a final-year Statistics student at the National University of Colombia. I am passionate about applying statistics to complex problems in interdisciplinary contexts, particularly in economics and social sciences, combining methodological rigor with an applied approach to generate reliable evidence that supports data-driven strategic decisions.\nI have participated in research projects leading quantitative analyses, managing databases, and preparing reports. I have solid experience in data processing using programming tools, which has allowed me to develop critical thinking, strong analytical skills, and meticulous attention to detail in the quality of results delivered.\nI have also distinguished myself through communication skills that enabled me to present at international conferences, hold student leadership positions, perform in theater thanks to my acting background, and support teaching processes over recent years. These experiences provided me with a comprehensive perspective, leadership abilities, and a strong commitment to teamwork. In addition, I am fluent in English, acquired through years of study in Colombia, professional experience supporting international clients, and an academic exchange in Canada that strengthened my global outlook and confidence in diverse environments.\n\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html",
    "href": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html",
    "title": "M√≥dulo 6: Inferencia Estad√≠stica",
    "section": "",
    "text": "En la pr√°ctica del an√°lisis de datos rara vez se cuenta con informaci√≥n completa de toda una poblaci√≥n; en su lugar, trabajamos con muestras que deben servirnos como base para responder preguntas sobre el comportamiento general de dicha poblaci√≥n. El proceso de trasladar hallazgos obtenidos a partir de una muestra hacia conclusiones m√°s amplias recibe el nombre de inferencia estad√≠stica.\nEste m√≥dulo introduce al estudiante en los fundamentos de la inferencia estad√≠stica aplicada a la bioestad√≠stica, partiendo de la noci√≥n de muestreo como puente entre la poblaci√≥n y la muestra. A continuaci√≥n, se abordan tres ejes centrales: la estimaci√≥n puntual, que busca obtener un valor representativo para un par√°metro poblacional; la estimaci√≥n por intervalos, que permite cuantificar la incertidumbre de la estimaci√≥n mediante intervalos de confianza; y las pruebas de hip√≥tesis, que proporcionan un marco formal para evaluar afirmaciones sobre par√°metros poblacionales a partir de la evidencia muestral.\nAdem√°s de la formulaci√≥n te√≥rica, se har√° √©nfasis en la implementaci√≥n pr√°ctica en R, de manera que el estudiante pueda adquirir destrezas tanto en el c√°lculo como en la interpretaci√≥n cr√≠tica de resultados, fortaleciendo as√≠ la capacidad de responder preguntas cient√≠ficas en el campo de la biostat√≠stica de forma rigurosa, contextualizada y √©tica."
  },
  {
    "objectID": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#introducci√≥n",
    "href": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#introducci√≥n",
    "title": "M√≥dulo 6: Inferencia Estad√≠stica",
    "section": "",
    "text": "En la pr√°ctica del an√°lisis de datos rara vez se cuenta con informaci√≥n completa de toda una poblaci√≥n; en su lugar, trabajamos con muestras que deben servirnos como base para responder preguntas sobre el comportamiento general de dicha poblaci√≥n. El proceso de trasladar hallazgos obtenidos a partir de una muestra hacia conclusiones m√°s amplias recibe el nombre de inferencia estad√≠stica.\nEste m√≥dulo introduce al estudiante en los fundamentos de la inferencia estad√≠stica aplicada a la bioestad√≠stica, partiendo de la noci√≥n de muestreo como puente entre la poblaci√≥n y la muestra. A continuaci√≥n, se abordan tres ejes centrales: la estimaci√≥n puntual, que busca obtener un valor representativo para un par√°metro poblacional; la estimaci√≥n por intervalos, que permite cuantificar la incertidumbre de la estimaci√≥n mediante intervalos de confianza; y las pruebas de hip√≥tesis, que proporcionan un marco formal para evaluar afirmaciones sobre par√°metros poblacionales a partir de la evidencia muestral.\nAdem√°s de la formulaci√≥n te√≥rica, se har√° √©nfasis en la implementaci√≥n pr√°ctica en R, de manera que el estudiante pueda adquirir destrezas tanto en el c√°lculo como en la interpretaci√≥n cr√≠tica de resultados, fortaleciendo as√≠ la capacidad de responder preguntas cient√≠ficas en el campo de la biostat√≠stica de forma rigurosa, contextualizada y √©tica."
  },
  {
    "objectID": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#objetivos",
    "href": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#objetivos",
    "title": "M√≥dulo 6: Inferencia Estad√≠stica",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\nObjetivos espec√≠ficos\n\nComprender el rol del muestreo en la inferencia estad√≠stica y su relaci√≥n con la validez de las conclusiones.\nCalcular e interpretar estimadores puntuales para par√°metros poblacionales, reconociendo sus propiedades y limitaciones.\nConstruir e interpretar intervalos de confianza como medida de precisi√≥n y de incertidumbre en la estimaci√≥n.\nFormular y aplicar pruebas de hip√≥tesis estad√≠sticas, entendiendo su l√≥gica y los posibles errores involucrados.\nImplementar en R los principales m√©todos de estimaci√≥n puntual, intervalos de confianza y pruebas de hip√≥tesis en ejemplos pr√°cticos de bioestad√≠stica.\nDesarrollar una actitud cr√≠tica y responsable frente a los resultados inferenciales, enfatizando la importancia del contexto, los supuestos estad√≠sticos y la √©tica en la interpretaci√≥n y comunicaci√≥n de hallazgos."
  },
  {
    "objectID": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#desarrollo",
    "href": "biostats/M√≥dulo 6 - Inferencia/mod6_inferen.html#desarrollo",
    "title": "M√≥dulo 6: Inferencia Estad√≠stica",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\n\nEn R existen diferentes funciones ya implementadas que realizan estimaciones puntuales, intervalos de confianza y pruebas de hip√≥tesis, sin embargo con lo que ya hemos aprendido, vamos a realizar los siguientes ejercicios haciendo las cuentas en el software.\n\n\nEstimaci√≥n puntual\n\n\n\nEl proceso de utilizar una muestra de una poblaci√≥n m√°s amplia para obtener una estimaci√≥n puntual de un par√°metro poblacional. Tomado de Data Science: A First Introduction.\n\n\n\nRecordemos que existen diferentes estimadores puntuales, por un lado tenemos el estimador de m√°xima verosimilitud \\(\\hat{\\theta}_{MLE}\\), y por otro lado tenemos el estimador por el m√©todo de momentos \\(\\hat{\\theta}_{MM}\\). \nEjercicios\n\nConsidere la siguiente muestra aleatoria proveniente de una distribuci√≥n normal, calcule los estimadores de m√°xima verosimilitud para la media \\(\\mu\\) y la varianza \\(\\sigma^2\\). Rta:\\(\\mu=9\\) y \\(\\sigma=1.5\\)\n\n\n\n\n8.103897\n6.032269\n10.890451\n10.080311\n8.649592\n\n\n9.601323\n8.603231\n7.745418\n9.564388\n8.812499\n\n\n9.569101\n9.855030\n9.235493\n12.510848\n8.903146\n\n\n8.936986\n5.761009\n9.073930\n7.620851\n7.177691\n\n\n8.218177\n10.943572\n10.246323\n9.049131\n6.459304\n\n\n\n\nmuestra&lt;- c(8.103897 ,6.032269,10.890451,10.080311,8.649592,9.601323,8.603231,7.745418,9.564388,8.812499,9.569101,9.855030,9.235493, 12.510848,8.903146,8.936986,5.761009,9.073930,7.620851,7.177691,8.218177 ,10.943572, 10.246323,9.049131,6.459304)\n\n\n\n\nEstimaci√≥n por intervalos\n\nLa estimaci√≥n por intervalos est√° basada en encontrar una variable pivote que contega en su expresi√≥n al par√°metro, a la informaci√≥n que proporciona la muestra y que su distribuci√≥n no dependa del par√°metro a estimar. Recordemos las f√≥rmulas de los intervalos de confianza para una sola poblaci√≥n.\n\n\n\n\n\n\n\n\nPar√°metro\nVariable pivote\nF√≥rmula del intervalo de confianza\n\n\n\n\nMedia \\(\\mu\\) con \\(\\sigma\\) conocida\n\\(Z = \\frac{\\bar{x} - \\mu}{\\sigma / \\sqrt{n}}\\sim N(0,1)\\)\n\\(\\bar{x} \\pm z_{1 - \\alpha/2} \\cdot \\frac{\\sigma}{\\sqrt{n}}\\)\n\n\nMedia \\(\\mu\\) con \\(\\sigma\\) desconocida\n\\(T = \\frac{\\bar{x} - \\mu}{s / \\sqrt{n}}\\sim t_{n-1}\\)\n\\(\\bar{x} \\pm t_{n-1, 1 - \\alpha/2} \\cdot \\frac{s}{\\sqrt{n}}\\)\n\n\nProporci√≥n \\(\\hat{p}\\)\n\\(Z = \\frac{\\hat{p} - p}{\\sqrt{ \\frac{\\hat{p}(1 - \\hat{p})}{n} }}\\sim N(0,1)\\)\n\\(\\hat{p} \\pm z_{1 - \\alpha/2} \\cdot \\sqrt{ \\frac{\\hat{p}(1 - \\hat{p})}{n} }\\)\n\n\nVarianza \\(\\sigma^2\\) con \\(\\mu\\) conocida\n\\(\\chi^2 = \\frac{\\sum_{i=1}^{n}(x_i-\\mu)^2}{\\sigma^2} \\sim \\chi^2_{n}\\)\n\\(\\left[ \\frac{(n - 1)s^2}{\\chi^2_{n,1 - \\alpha/2}},\\ \\frac{(n - 1)s^2}{\\chi^2_{n,\\alpha/2}} \\right]\\)\n\n\nVarianza \\(\\sigma^2\\) con \\(\\mu\\) desconocida\n\\(\\chi^2 = \\frac{(n-1)s^2}{\\sigma^2}\\sim\\chi^2_{n-1}\\)\n\\(\\left[ \\frac{(n - 1)s^2}{\\chi^2_{n-1,1 - \\alpha/2}},\\ \\frac{(n - 1)s^2}{\\chi^2_{n-1,\\alpha/2}} \\right]\\)\n\n\n\nEjercicio\nSe obtuvo una muestra de los niveles de ars√©nico encontrados en paquetes de arroz de cierta marca. Se sabe que los niveles de arsenico siguen una distribuci√≥n normal y seg√∫n la FDA el l√≠mite m√°ximo permitido ars√©nico en arroz es 0.25 mg/kg. Encuentra un intervalo de confianza del 99% para el nivel medio de ars√©nico y decide si la marca de arroz debe ser o no retirada del mercado. Adicionalmente encuentra intervalo de confianza al 95% para la variabilidad de los niveles de ars√©nico en el arroz de la marca.\n\n\n\n0.1668462\n0.1834053\n0.1477304\n0.1517635.\n0.1603168\n\n\n0.1698843\n0.1516698\n0.2232762\n0.1890869\n0.1747316\n\n\n0.1273578\n0.2135094\n0.1523728\n0.1663394.\n0.1865947\n\n\n0.1580923\n0.1299129\n0.1715803\n0.1140778\n0.1999403\n\n\n\n\narsenico&lt;-c(0.1668462,0.1834053,0.1477304,0.1517635,0.1603168,0.1698843,0.1516698,0.2232762,0.1890869,0.1747316,0.1273578,0.215094,0.1523728,0.1663394,0.1865947,0.1580923,0.1299129,0.1715803,0.1140778,0.1999403)\n\nmean(arsenico)\n\n[1] 0.1670037\n\nsd(arsenico)\n\n[1] 0.02783384\n\nqt(0.995,19)\n\n[1] 2.860935\n\nmean(arsenico)+c(-qt(0.995,19)*sd(arsenico)/sqrt(20),qt(0.995,19)*sd(arsenico)/sqrt(20))\n\n[1] 0.1491977 0.1848097\n\n(length(arsenico)-1)*sd(arsenico)*c(1/qchisq(0.975,19),1/qchisq(0.025,19))\n\n[1] 0.01609758 0.05937708\n\n\nTambi√©n podemos construir intervalos de confianza para comparar el comportamiento de dos poblaciones, la siguiente tabla resume las variables pivote a usar seg√∫n sea el caso. Sup√≥n dos muestras aleatorias \\(X_1,X_2,...,X_n\\) y \\(Y_1,Y_2,...,Y_m\\) provenientes de dos distribuciones normales con medias y varianzas \\(\\mu_X\\), \\(\\sigma^2_X\\) y \\(\\mu_Y\\), \\(\\sigma^2_Y\\), respectivamennte.\n\n\n\n\n\n\n\n\nComparaci√≥n\nSupuestos\nVariable pivote\n\n\n\n\nDiferencia de medias\nMuestras pareadas\n\\(T=\\frac{\\sqrt{n}(\\bar{d}-\\mu_d)}{S_d}\\sim t_{n-1}\\) con \\(d_i=X_i-Y_i\\), \\(S_d^2=\\frac{1}{n-1}\\sum_{i=1}^{n}(d_i-\\bar{d})^2\\) y \\(\\mu_d=\\mu_X-\\mu_Y\\)\n\n\n\nMuestras Independientes, varianzas conocidas\n\\(Z=\\frac{\\bar{X}-\\bar{Y}-(\\mu_X-\\mu_Y)}{\\sqrt{\\frac{\\sigma^2_X}{n}+\\frac{\\sigma^2_Y}{m}}}\\sim N(0,1)\\)\n\n\n\nMuestras Independientes, varianzas desconocidas e iguales\n\\(T=\\frac{\\bar{X}-\\bar{Y}-(\\mu_X-\\mu_Y)}{S_p\\sqrt{\\frac{1}{n}+\\frac{1}{m}}}\\sim t_{n+m-2}\\) con \\(S_p^2=\\frac{(n-1)S_X^2+(m-2)S_Y^2}{n+m-2}\\)\n\n\n\nMuestras Independientes, varianzas desconocidas y diferentes\n\\(T=\\frac{\\bar{X}-\\bar{Y}-(\\mu_X-\\mu_Y)}{\\sqrt{\\frac{S_X^2}{n}+\\frac{S_Y^2}{m}}}\\sim t_{v}\\) con \\(v\\approx \\frac{\\left(\\sqrt{\\frac{S_X^2}{n}+\\frac{S_Y^2}{m}}\\right)^2}{\\frac{\\left(\\frac{S_X^2}{n}\\right)^2}{n-1}+\\frac{\\left(\\frac{S_Y^2}{m}\\right)^2}{m-1}}\\)\n\n\nRaz√≥n de Varianzas\nMedias conocidas\n\\(F=\\frac{\\frac{\\sum_{i=1}^{n}(Y_i-\\mu_Y)^2}{m}}{\\frac{\\sum_{i=1}^{n}(X_i-\\mu_X)^2}{n}}\\frac{\\sigma^2_X}{\\sigma^2_Y}\\sim F_{(m,n)}\\)\n\n\n\nMedias desconocidas\n\\(F=\\frac{\\frac{\\sum_{i=1}^{n}(Y_i- \\bar{Y})^2}{m-1}}{\\frac{\\sum_{i=1}^{n}(X_i-\\bar{X})^2}{n-1}}\\frac{\\sigma^2_X}{\\sigma^2_Y}=\\frac{S_Y^2}{S_X^2}\\frac{\\sigma^2_X}{\\sigma^2_Y}\\sim F_{(m-1,n-1)}\\)\n\n\nDiferencia  de proporciones\n\n\\(Z=\\frac{\\hat{p}_X-\\hat{p}_Y -(P_X-P_Y)}{\\sqrt{\\frac{\\hat{p}_X(1-\\hat{p}_X)}{n}+\\frac{\\hat{p}_Y(1-\\hat{p}_Y)}{m}}}\\sim N(0,1)\\)\n\n\n\nEjercicio Se desea testear la eficiencia de un nuevo medicamento para regular la presi√≥n arterial con respecto a la f√≥rmula actual, se consider√≥ un grupo de 10 personas con hipertensi√≥n, se les suministr√≥ el medicamento actual y se registr√≥ el tiempo en minutos que tard√≥ en hacer efecto; al siguiente d√≠a se les suministr√≥ a las mismas 10 personas el medicamento nuevo y se registr√≥ el tiempo que tard√≥ en hacer efecto. Construye un intervalo de confianza con nivel de signficancia del 95% para la diferencia de los tiempos medios que tardan los medicamentos en hacer efecto ¬øDir√≠as que el nuevo medicamento es m√°s efectivo?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n\n\n\n\nNuevo\n17.639\n19.184\n19.613\n20.662\n25.077\n27.008\n16.371\n12.656\n14.895\n23.791\n\n\nActual\n21.269\n24.146\n29.237\n25.649\n23.448\n26.833\n21.909\n25.005\n25.877\n24.692\n\n\n\n\nnuevo&lt;-c(17.63971,19.18418,19.61335,20.66206,25.07705,27.00823,16.37143,12.65593,14.89515,23.79106)\nactual&lt;-c(21.26914,24.14610,29.23737,25.64860,23.44820,26.83353,21.90869,25.00543,25.87751,24.69202)\n\ndif&lt;-nuevo-actual\n\nmean(dif)\n\n[1] -5.116844\n\nsd(dif)\n\n[1] 4.722745\n\nqt(0.975,9)\n\n[1] 2.262157\n\nmean(dif)+c(-qt(0.975,9)*sd(dif)/sqrt(10),qt(0.975,9)*sd(dif)/sqrt(10))\n\n[1] -8.495292 -1.738396\n\n\n\n\n\nPruebas de Hip√≥tesis\n\nLas pruebas de hip√≥tesis est√°n estrechamente relacionadas con los intervalos confianza, y podemos usar las mismas variables pivotales para juzgar los sistemas de hip√≥tesis dados pues; un intervalo de confianza proporciona un rango de valores plausibles para un par√°metro poblacional, como la media. Por ejemplo, un intervalo de confianza del 95% indica que, si se repitiera el muestreo muchas veces, aproximadamente el 95% de los intervalos construidos incluir√≠an el valor verdadero del par√°metro. Por otro lado, una prueba de hip√≥tesis eval√∫a una afirmaci√≥n espec√≠fica sobre un par√°metro poblacional, como si la media es igual a un valor dado. La relaci√≥n entre ambos m√©todos es que si un valor hipot√©tico (por ejemplo, \\(\\mu=\\mu_0\\)) no est√° dentro del intervalo de confianza, entonces se rechaza la hip√≥tesis nula al mismo nivel de significancia.\nEjercicio\nLas siguientes son dos muestras aleatorias provenientes de dos poblaciones con distribuci√≥n normal.\n\nJuzga el sistema de hip√≥tesis sobre la igualdad de varianzas: \\[H_0: \\frac{\\sigma^2_1}{\\sigma^2_2}=1 \\quad \\text{vs} \\quad H_a: \\frac{\\sigma^2_1}{\\sigma^2_2}\\neq1\\]\nBasado en el resultado anterior elige la variable pivote adecuada para juzgar el siguiente sistema de hip√≥tesis sobre la diferencia de medias.\n\n\\[H_0: \\mu_1=\\mu_2 \\quad \\text{vs} \\quad H_a: \\mu_1\\neq\\mu_2\\] \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoblacion\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n0.3326\n1.5008\n-2.1765\n2.2790\n-1.0189\n1.4064\n-0.1456\n2.2994\n-0.9407\n-0.6975\n\n\n\n-2.2288\n0.9060\n1.0195\n0.8002\n0.3404\n\n\n\n\n\n\n\n2\n1.2545\n1.8423\n1.9791\n4.6087\n0.7123\n1.4672\n-5.7277\n2.6101\n-0.7495\n-1.9610\n\n\n\n-2.8334\n1.1577\n3.90824\n-1.2104\n-3.3756\n-1.9825\n-0.8446\n3.1946\n2.7747\n-1.0302\n\n\n\n\npob1 &lt;- c(0.3326, 1.5008, -2.1765, 2.2790, -1.0189, 1.4064, -0.1456, 2.2994, -0.9407, -0.6975, -2.2288, 0.9060, 1.0195, 0.8002, 0.3404)\n\npob2 &lt;- c(1.2545, 1.8423, 1.9791, 4.6087, 0.7123, 1.4672, -5.7277, 2.6101, -0.7495, -1.9610, -2.8334, 1.1577, 3.9082, -1.2104, -3.3756, -1.9825, -0.8446, 3.1946, 2.7747, -1.0302)\n\n\n\n\nEjemplos\nPrimer punto: En la siguiente tabla se presentan los pesos en gramos, de dos grupos de conejos con diferentes dietas despues de 64 d√≠as de aplicadas.\n\nlibrary(knitr)\n\nWarning: package 'knitr' was built under R version 4.4.3\n\n# Crear los vectores\ndieta_a &lt;- c(800, 850, 900, 870, 890, 960, 970, 950, 880, 900)\ndieta_b &lt;- c(700, 780, 700, 900, 800, 780, 850, 890)\n\n# Combinar en un data frame\ntabla &lt;- data.frame(\n  Grupo = c(\"Dieta A\", \"Dieta B\"),\n  rbind(\n    dieta_a,\n    c(dieta_b, rep(NA, length(dieta_a) - length(dieta_b)))  # completar con NA si es m√°s corto\n  )\n)\n\n# Asignar nombres a las columnas\ncolnames(tabla) &lt;- c(\"Grupo\", paste0(\"V\", 1:(ncol(tabla)-1)))\n\n# Mostrar la tabla\nkable(tabla, caption = \"Valores por grupo en formato ancho\")\n\n\nValores por grupo en formato ancho\n\n\n\nGrupo\nV1\nV2\nV3\nV4\nV5\nV6\nV7\nV8\nV9\nV10\n\n\n\n\ndieta_a\nDieta A\n800\n850\n900\n870\n890\n960\n970\n950\n880\n900\n\n\n\nDieta B\n700\n780\n700\n900\n800\n780\n850\n890\nNA\nNA\n\n\n\n\n\n\nEncuentre el estimador puntual para la media y la varianza de los pesos en gramos de los dos grupos de conejos.\nUn estimador puntual para la media \\(\\theta = \\mu\\) est√° dado por la siguiente expresi√≥n:\n\\[\n\\bar{X} = \\dfrac{1}{n}\\sum_{i=1}^nX_i\n\\]\nUna estimaci√≥n puntual para la media \\(\\theta = \\mu\\) est√° dada por la siguiente expresi√≥n:\n\\[\n\\bar{x} = \\dfrac{1}{n}\\sum_{i=1}^nx_i\n\\]\n\nmean(dieta_a)\n\n[1] 897\n\nmean(dieta_b)\n\n[1] 800\n\n\nLa estimaci√≥n puntual para la media de los pesos, en gramos, del grupo A de conejos es: 897\nLa estimaci√≥n puntual para la media de los pesos, en gramos, del grupo B de conejos es: 800\nUn estimador puntual para la varianza \\(\\theta = \\sigma^2\\) est√° dado por la siguiente expresi√≥n:\n\\[\nS^2 = \\dfrac{1}{n-1}\\sum_{i=1}^n(X_i-\\bar{X})^2\n\\]\nUna estimaci√≥n puntual para la varianza \\(\\theta = \\sigma^2\\) est√° dada por la siguiente expresi√≥n:\n\\[\ns^2 = \\dfrac{1}{n-1}\\sum_{i=1}^n(x_i-\\bar{x})^2\n\\]\nLa estimaci√≥n puntual para la varianza de los pesos, en gramos al cuadrado, del grupo A de conejos es: 2756.67 g^2\n\nround(var(dieta_a),2)\n\n[1] 2756.67\n\nround(var(dieta_b),2)\n\n[1] 5914.29\n\n\n¬øExiste alguna raz√≥n para creer, con un nivel de significancia de 0.05, que el peso en gramos despu√©s de 64 d√≠as de aplicada la dieta A es mayor a 950 gramos? Indique los supuestos. Adicionalmente, calcule el p-valor.\n\nDefinimos el siguiente sistema de hip√≥tesis a una cola a la derecha:\n\\[\n\\begin{align*}\nH_0 &: \\mu \\leq 950\\\\\nH_1 &: \\mu &gt; 950\\\\\n\\end{align*}\n\\]\nAsumimos varianza poblacional \\((\\sigma^2)\\) desconocida, datos provenientes de una poblaci√≥n normal y una muestra peque√±a. Por ende, usamos la prueba t de Student.\nAs√≠, el estad√≠stico de prueba T esta dado por la siguiente expresi√≥n:\n\\[\nt = \\dfrac{\\bar{x}-\\mu_0}{s/\\sqrt{n}}\n\\]\nNote que, en nuestro caso particular, para el grupo que recibio la dieta A, \\(\\bar{x}=897\\), \\(\\mu_0=950\\), \\(s = \\sqrt{2756.67} = 52.5\\) y \\(n=10\\).\n\nt.test(dieta_a, mu = 950, alternative = \"greater\")\n\n\n    One Sample t-test\n\ndata:  dieta_a\nt = -3.1922, df = 9, p-value = 0.9945\nalternative hypothesis: true mean is greater than 950\n95 percent confidence interval:\n 866.5644      Inf\nsample estimates:\nmean of x \n      897 \n\n\nDe aqu√≠ que t =-3.1922 y p-value = 0.9945.\nLas reglas de desici√≥n estan dadas por:\nRechazar \\(H_0\\) si \\(t &gt; t_\\alpha\\) donde \\(t_\\alpha = t_{0.05,9}\\)\nEl valor de \\(t_{0.05,9}\\approx 1.83\\) obtenido a trav√©s de:\n\nqt(0.05,9,lower.tail = F)\n\n[1] 1.833113\n\n\nRecordemos que \\(P(T&gt;-3.19) = \\text{p-value}\\). Note que el \\(\\text{p-value}\\) ser√° muy cercano a 1 ya que, por una parte, al estar por debajo de cero, este ser√° mayor a 0.5. Adem√°s, este es un valor relativamente ‚Äúgrande‚Äù, con lo que por la simetr√≠a de la distribuci√≥n es f√°cil ver que tendremos un valor alto de √°rea acumulada por debajo de la funci√≥n de distribuci√≥n t.\n\n\n\n\n\n\n\n\n\n\n¬øExiste alguna raz√≥n para creer, con un nivel de significancia de 0.05, que el peso en gramos despu√©s de 64 d√≠as de aplicada la dieta B es mayor a 850 gramos? Indique los supuestos. Adicionalmente, calcule el p-valor.\n\nDefinimos el siguiente sistema de hip√≥tesis a una cola a la derecha:\n\\[ \\begin{align*} H_0 &: \\mu \\leq 950\\\\ H_1 &: \\mu &gt; 950\\\\ \\end{align*} \\]\nAsumimos varianza poblacional \\((\\sigma^2)\\) desconocida. Por ende, usamos la prueba t de Student.\nAs√≠, el estad√≠stico de prueba T esta dado por la siguiente expresi√≥n:\n\\[ t = \\dfrac{\\bar{x}-\\mu_0}{s/\\sqrt{n}} \\]\nEl grupo al que se le administro la dieta b, cuenta con los siguientes valores: \\(\\bar{x}=800\\), \\(\\mu_0=850\\), \\(s = \\sqrt{5914.29} = 76.9\\) y \\(n=8\\).\n\n¬øExiste evidencia de que los pesos promedios de ambos grupos de conejos son distintos? Use Œ± = 0.01. Indique los supuestos y pruebe el supuesto de varianzas.\n\nDefinimos el siguiente sistema de hip√≥tesis a una cola a la derecha:\n\\[ \\begin{align*} H_0 &: \\mu_A = \\mu_B\\\\ H_1 &: \\mu_A \\neq \\mu_B\\\\ \\end{align*} \\]\nPrimero realizaremos una prueba para el supuesto de varianzas iguales.\n\\[ H_0 : \\sigma^2_A = \\sigma^2_B \\qquad \\text{vs} \\qquad H_1 : \\sigma^2_A \\neq \\sigma^2_B \\]\nPara este caso, haremos una prueba de raz√≥n de varianzas tambien conocida como una prueba F de Fisher.\n\\[ F = \\frac{S_1^2}{S_2^2} \\]\nLa regla de decisi√≥n est√° dada por:\n\\[\nF &gt; F_{\\alpha/2;\\, n_1 - 1,\\, n_2 - 1}\n\\]\nDonde \\(F =0.466\\) y \\(F_{\\alpha/2;\\, n_1 - 1,\\, n_2 - 1}=F_{0.01/2;\\,9,\\, 7}=8.51\\). Adem√°s, \\(\\text{p-value}=0.28\\)\n\nvar.test(dieta_a,dieta_b, alternative = \"two.sided\", coef.level = 0.99)\n\n\n    F test to compare two variances\n\ndata:  dieta_a and dieta_b\nF = 0.4661, num df = 9, denom df = 7, p-value = 0.2836\nalternative hypothesis: true ratio of variances is not equal to 1\n95 percent confidence interval:\n 0.09663738 1.95625628\nsample estimates:\nratio of variances \n         0.4661031 \n\nqf(0.01/2,9,7,lower.tail = F)\n\n[1] 8.513823\n\n\nPodemos asumir varianzas iguales y continuar con el an√°lisis sobre los pesos promedios de ambos grupos de conejos.\nAs√≠, el estad√≠stico de prueba T para muestras independientes est√° dado por la siguiente expresi√≥n, note que estamos en un caso de Diferencia de Medias con Varianzas Desconocidas suponiendo igualdad :\n\\[ T = \\dfrac{(\\bar{X}-\\bar{Y})-(\\mu_X-\\mu_Y)}{S_p\\sqrt{\\frac{1}{n}+\\frac{1}{m}}}\\sim t_{n+m-2}\\]\n\\[\nS_p = \\sqrt{\\frac{(n-1)S_X^2+(m-2)S_Y^2}{n+m-2}}\n\\]\nNote que, en nuestro caso particular, para el grupo que recibio la dieta A, \\(\\bar{x}=897\\), \\(\\mu_0=950\\), \\(s = \\sqrt{2756.67} = 52.5\\) y \\(n=10\\).\n\\[ T = \\dfrac{(897-800)-(0)}{S_p\\sqrt{\\frac{1}{10}+\\frac{1}{8}}}\\sim t_{10+8-2}\\] \\[\nS_p = \\sqrt{\\frac{(10-1)*2756.67+(8-2)*5914.29}{10+8-2}}\n\\]\n\\[\nS_p = \\sqrt{\\frac{60295.77}{16}} = 61.39\n\\]\nObtenemos un valor del estad√≠stico T = 0.75 que comparamos con el valor de una t con 16 grados de libertad al nivel de significacncia del 1% con lo que obtenemos \\(t_c=2.58\\)\n\nqt(0.01,16,lower.tail = F)\n\n[1] 2.583487\n\n\n\nt.test(dieta_a, dieta_b, var.equal = TRUE, alternative = \"two.sided\")\n\n\n    Two Sample t-test\n\ndata:  dieta_a and dieta_b\nt = 3.1789, df = 16, p-value = 0.00583\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n  32.31412 161.68588\nsample estimates:\nmean of x mean of y \n      897       800 \n\n\n\\[\nT = \\frac{(\\bar{X} - \\bar{Y}) - (\\mu_X - \\mu_Y)}{S_p \\sqrt{\\frac{1}{n} + \\frac{1}{m}}} \\sim t_{n+m-2}\n\\]\n\\[\nS_p^2 = \\frac{(n - 1) S_X^2 + (m - 1) S_Y^2}{n + m - 2}\n\\]\nSustituyendo con nuestros valores:\n\\[\nS_p^2 = \\frac{(10 - 1)(2756.667) + (8 - 1)(5914.286)}{10 + 8 - 2}\n= \\frac{9 \\cdot 2756.667 + 7 \\cdot 5914.286}{16}\n\\]\n\\[\nS_p^2 = \\frac{24810.003 + 41400.002}{16}\n= \\frac{66210.005}{16}\n= 4138.125\n\\]\n\\[\nS_p = \\sqrt{4138.125} \\approx 64.31\n\\]\nAhora calculamos el estad√≠stico ( T ):\n\\[\nT = \\frac{897 - 800}{64.31 \\cdot \\sqrt{\\frac{1}{10} + \\frac{1}{8}}}\n= \\frac{97}{64.31 \\cdot \\sqrt{0.225}}\n= \\frac{97}{64.31 \\cdot 0.4743}\n= \\frac{97}{30.49} \\approx 3.18\n\\]\nObtenemos un valor de la estad√≠stica \\[ T = 3.18 \\], que comparamos con el valor cr√≠tico de una t con \\[ 16 \\] grados de libertad.\n\n\n\n\n\n\nüìö Bibliograf√≠a\n\n\n\n\n\n\nTimbers, Tiffany; Campbell, Trevor and Lee,¬†Melissa. 2024. Data Science: A First Introduction. CRC Press.https://datasciencebook.ca/\n\n\n\n\n\nCopyright ¬© 2025 Jose M. Leon & Laura E. Pardo - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html",
    "href": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html",
    "title": "M√≥dulo 4: An√°lisis Descriptivo y Exploratorio",
    "section": "",
    "text": "En este m√≥dulo se espera introducir al estudiante a una filosof√≠a de razonamiento estad√≠stico a trav√©s de la cual adquirir√° los principios del pensamiento cient√≠fico respecto a la descripci√≥n organizada de los datos, realizando una traducci√≥n de un conjunto de datos en informaci√≥n y hallazgos divulgables por medio de t√©cnicas de potencializaci√≥n del uso de gr√°ficos y obtenci√≥n de √≠ndices. Se presentar√°n los diferentes √≠ndices o estad√≠sticos junto a su respectiva descripci√≥n, f√≥rmula te√≥rica, implementaci√≥n en R e interpretaci√≥n, destacando la importancia de que si bien este material es aplicado y pr√°ctico, resulta inservible de no comprender que m√°s all√° del correcto y √©tico c√°lculo de estas medidas, el cumplimiento de los supuestos requeridos y la interpretaci√≥n es vital, as√≠ como el entendimiento del contexto y de la naturaleza de la distribuci√≥n de nuestros datos.\nEl m√≥dulo se centra tanto en el c√°lculo num√©rico como en la exploraci√≥n visual, permitiendo que el estudiante desarrolle una mirada cr√≠tica sobre las diferentes maneras de representar la informaci√≥n. A lo largo de este espacio se abordar√°n medidas de tendencia central, medidas robustas y resistentes a valores at√≠picos, medidas de posici√≥n o localizaci√≥n, medidas de dispersi√≥n, medidas de forma (asimetr√≠a y curtosis) y medidas de asociaci√≥n entre dos variables. Paralelamente, se explorar√° el papel de la visualizaci√≥n gr√°fica en la comprensi√≥n de los datos, destacando c√≥mo los gr√°ficos complementan y refuerzan los an√°lisis num√©ricos, y c√≥mo las herramientas de R permiten generar representaciones vers√°tiles, reproducibles y adaptables a diferentes contextos.\nCon ello, se busca que el estudiante logre no solo manipular adecuadamente datos en R, sino tambi√©n construir narrativas estad√≠sticas fundamentadas en evidencia, con capacidad de comunicar hallazgos de manera clara, precisa y √©tica en entornos cient√≠ficos y profesionales."
  },
  {
    "objectID": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#introducci√≥n",
    "href": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#introducci√≥n",
    "title": "M√≥dulo 4: An√°lisis Descriptivo y Exploratorio",
    "section": "",
    "text": "En este m√≥dulo se espera introducir al estudiante a una filosof√≠a de razonamiento estad√≠stico a trav√©s de la cual adquirir√° los principios del pensamiento cient√≠fico respecto a la descripci√≥n organizada de los datos, realizando una traducci√≥n de un conjunto de datos en informaci√≥n y hallazgos divulgables por medio de t√©cnicas de potencializaci√≥n del uso de gr√°ficos y obtenci√≥n de √≠ndices. Se presentar√°n los diferentes √≠ndices o estad√≠sticos junto a su respectiva descripci√≥n, f√≥rmula te√≥rica, implementaci√≥n en R e interpretaci√≥n, destacando la importancia de que si bien este material es aplicado y pr√°ctico, resulta inservible de no comprender que m√°s all√° del correcto y √©tico c√°lculo de estas medidas, el cumplimiento de los supuestos requeridos y la interpretaci√≥n es vital, as√≠ como el entendimiento del contexto y de la naturaleza de la distribuci√≥n de nuestros datos.\nEl m√≥dulo se centra tanto en el c√°lculo num√©rico como en la exploraci√≥n visual, permitiendo que el estudiante desarrolle una mirada cr√≠tica sobre las diferentes maneras de representar la informaci√≥n. A lo largo de este espacio se abordar√°n medidas de tendencia central, medidas robustas y resistentes a valores at√≠picos, medidas de posici√≥n o localizaci√≥n, medidas de dispersi√≥n, medidas de forma (asimetr√≠a y curtosis) y medidas de asociaci√≥n entre dos variables. Paralelamente, se explorar√° el papel de la visualizaci√≥n gr√°fica en la comprensi√≥n de los datos, destacando c√≥mo los gr√°ficos complementan y refuerzan los an√°lisis num√©ricos, y c√≥mo las herramientas de R permiten generar representaciones vers√°tiles, reproducibles y adaptables a diferentes contextos.\nCon ello, se busca que el estudiante logre no solo manipular adecuadamente datos en R, sino tambi√©n construir narrativas estad√≠sticas fundamentadas en evidencia, con capacidad de comunicar hallazgos de manera clara, precisa y √©tica en entornos cient√≠ficos y profesionales."
  },
  {
    "objectID": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#objetivos",
    "href": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#objetivos",
    "title": "M√≥dulo 4: An√°lisis Descriptivo y Exploratorio",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\nComprender el papel del an√°lisis descriptivo y exploratorio como etapa inicial y fundamental del razonamiento estad√≠stico.\n\n\n\nCalcular e interpretar medidas de tendencia central, dispersi√≥n, posici√≥n y forma, reconociendo su utilidad y limitaciones.\n\n\n\nIncorporar medidas robustas y resistentes para el an√°lisis de datos en presencia de valores at√≠picos.\n\n\n\nAnalizar relaciones entre dos variables mediante √≠ndices y representaciones gr√°ficas apropiadas.\n\n\n\nUtilizar R para implementar de manera pr√°ctica las medidas descriptivas y visualizaciones necesarias para resumir datos.\n\n\n\nFomentar una interpretaci√≥n cr√≠tica y contextualizada de los resultados estad√≠sticos, destacando la importancia de los supuestos y la √©tica en su comunicaci√≥n."
  },
  {
    "objectID": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#desarrollo",
    "href": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#desarrollo",
    "title": "M√≥dulo 4: An√°lisis Descriptivo y Exploratorio",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\n\nMedidas de Tendencia Central\n\nMedia Aritm√©tica\nDescripci√≥n:\nLa media aritm√©tica es el promedio de un conjunto de datos. Se obtiene sumando todos los valores y dividiendo entre el n√∫mero total de observaciones.\nF√≥rmula\n\\[\n\\bar{x} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n\\]\ndonde \\(n\\) es el n√∫mero de observaciones y \\(x_i\\) cada valor de la variable.\nImplementaci√≥n en R\n\n# Datos de ejemplo\nx &lt;- c(5, 7, 8, 9, 10)\n\nmean(x)\n\n[1] 7.8\n\n\nInterpretaci√≥n\nLa media aritm√©tica indica el valor central promedio de los datos. Es sensible a valores extremos\n\n\nMedia Aritm√©tica Ponderada\nDescripci√≥n:\nPromedio que asigna un peso a cada observaci√≥n para reflejar su importancia relativa.\nF√≥rmula \\[\n\\bar{x}_p = \\frac{\\sum_{i=1}^{n} w_i x_i}{\\sum_{i=1}^{n} w_i}\n\\] Implementaci√≥n en R\n\nx &lt;- c(3, 5, 7)\nw &lt;- c(1, 2, 3)\nweighted.mean(x, w, na.rm = TRUE)\n\n[1] 5.666667\n\n\nInterpretaci√≥n\nPromedio ajustado por importancia; √∫til en calificaciones, √≠ndices y agregaci√≥n de indicadores.\n\n\nMediana\nDescripci√≥n:\nValor central de los datos ordenados; divide la muestra en dos mitades del mismo tama√±o. Es robusta frente a valores at√≠picos.\nF√≥rmula \\[\n\\tilde{x} =\n\\begin{cases}\nx_{(\\frac{n+1}{2})}, & \\text{si } n \\text{ es impar} \\\\\n\\dfrac{x_{(\\frac{n}{2})} + x_{(\\frac{n}{2}+1)}}{2}, & \\text{si } n \\text{ es par}\n\\end{cases}\n\\] Implementaci√≥n en R\n\nx &lt;- c(1, 3, 5, 7, 9, 11)\nmedian(x, na.rm = TRUE)\n\n[1] 6\n\n\nInterpretaci√≥n\nLa mitad de las observaciones est√° por debajo y la otra mitad por encima de la mediana.\n\n\nModa\nDescripci√≥n:\nValor (o valores) m√°s frecuente(s) en el conjunto de datos. Puede no ser √∫nica (bimodal/multimodal) o no existir en datos continuos sin discretizaci√≥n.\nF√≥rmula \\[\n\\text{Moda} = \\arg\\max_{v} \\; f(v)\n\\] donde \\(f(v)\\) es la frecuencia del valor \\(v\\).\nImplementaci√≥n en R\n\nmode_all &lt;- function(v) {\n  v &lt;- v[!is.na(v)]\n  if (length(v) == 0) return(NA)\n  tab &lt;- table(v)\n  tab &lt;- tab[tab == max(tab)]\n  as.vector(names(tab))\n}\nx &lt;- c(2, 3, 3, 4, 4, 4, 5, NA)\nmode_all(x)\n\n[1] \"4\"\n\n\nInterpretaci√≥n\nIndica el(los) valor(es) m√°s com√∫n(es). √ötil para variables categ√≥ricas.\n\n\nMedia Geom√©trica\nDescripci√≥n:\nPromedio multiplicativo; apropiada para tasas de crecimiento, razones y datos en escala logar√≠tmica. Requiere valores positivos.\nF√≥rmula\n\\[\n\\bar{x}_g = \\left( \\prod_{i=1}^{n} x_i \\right)^{\\frac{1}{n}}\n= \\exp\\!\\left( \\frac{1}{n} \\sum_{i=1}^{n} \\ln x_i \\right)\n\\] Implementaci√≥n en R\n\nx &lt;- c(1.2, 1.5, 0.9, 1.1)  # todos &gt; 0\nexp(mean(log(x), na.rm = TRUE))\n\n[1] 1.155386\n\n\nInterpretaci√≥n\nResume promedios de cambios relativos; menos afectada por valores grandes que la media aritm√©tica.\n\n\nMedia Arm√≥nica\nDescripci√≥n:\nRec√≠proco del promedio de los rec√≠procos; adecuada para promediar tasas (p.¬†ej., velocidad promedio en tramos iguales).\nF√≥rmula\n\\[\n\\bar{x}_h = \\frac{n}{\\sum_{i=1}^{n} \\frac{1}{x_i}}\n\\] Implementaci√≥n en R\n\nx &lt;- c(40, 60, 80)  # velocidades, tasas &gt; 0\nlength(x) / sum(1/x)\n\n[1] 55.38462\n\n\nInterpretaci√≥n\nDa mayor peso a valores peque√±os; √∫til cuando la cantidad fija est√° en el denominador (tiempo por unidad, costo por unidad).\n\n\nPromedio de los Cuartiles\nDescripci√≥n:\nPromedio simple de \\(Q_1\\), \\(Q_2\\) (mediana) y \\(Q_3\\); combina posici√≥n central y dispersi√≥n central.\nF√≥rmula \\[\n\\bar{x}_{Q} = \\frac{Q_1 + Q_2 + Q_3}{3}\n\\] Implementaci√≥n en R\n\nx &lt;- c(1,2,3,4,5,6,7,8,9,10)\nqs &lt;- quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\nmean(qs)\n\n[1] 5.5\n\n\nInterpretaci√≥n\nMedida robusta de tendencia central que considera el comportamiento del 50% central de los datos.\n\n\nTrimedia\nDescripci√≥n:\nPromedio ponderado de (Q_1), mediana ((Q_2)) y (Q_3), con doble peso a la mediana.\nF√≥rmula\n\\[\n\\text{Trimedia} = \\frac{Q_1 + 2Q_2 + Q_3}{4}\n\\]\nImplementaci√≥n en R\n\nx &lt;- c(1,2,3,4,5,6,7,8,9,10)\nqs &lt;- quantile(x, probs = c(0.25, 0.5, 0.75), na.rm = TRUE)\n(qs[1] + 2*qs[2] + qs[3]) / 4\n\n25% \n5.5 \n\n\nInterpretaci√≥n\nEquilibra robustez (mediana) y distribuci√≥n intermedia (\\(Q_1\\), \\(Q_3\\)); √∫til con asimetr√≠as moderadas.\n\n\nCentrimedia o Media Intercuart√≠lica\nDescripci√≥n:\nPromedio de \\(Q_1\\) y \\(Q_3\\); resume el centro del rango intercuart√≠lico (IQR), ignorando colas.\nF√≥rmula\n\\[\n\\text{Centrimedia} = \\frac{Q_1 + Q_3}{2}\n\\] Implementaci√≥n en R\n\nx &lt;- c(1,2,3,4,5,6,7,8,9,10)\nqs &lt;- quantile(x, probs = c(0.25, 0.75), na.rm = TRUE)\nmean(qs)\n\n[1] 5.5\n\n\nInterpretaci√≥n\nMide el ‚Äúcentro‚Äù del 50% medio de los datos, con poca influencia de valores extremos.\n\n\n\nMedidas de Posici√≥n o Localizaci√≥n\n\nCuantiles\n\nPercentiles\nDescripci√≥n:\nLos percentiles dividen un conjunto de datos ordenados en 100 partes iguales. Cada percentil indica el valor debajo del cual se encuentra un porcentaje dado de las observaciones.\nF√≥rmula\n\\[P_k = \\text{valor de la variable tal que } k\\% \\text{ de¬†las¬†observaciones¬†son¬†menores¬†o¬†iguales}\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\npercentil_25 &lt;- quantile(datos, probs = 0.25)\npercentil_25\n\n25% \n  7 \n\n\nInterpretaci√≥n\nUn percentil indica la posici√≥n relativa de un dato dentro de la distribuci√≥n. Por ejemplo, el percentil 25 indica el valor por debajo del cual se encuentra el 25% de los datos.\n\n\nDeciles\nDescripci√≥n:\nLos deciles dividen un conjunto de datos ordenados en 10 partes iguales.\nF√≥rmula \\[D_j = \\text{valor de la variable tal que } \\dfrac{j}{10} \\text{ de las observaciones son menores o iguales}\\] Implementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\ndeciles &lt;- quantile(datos, probs = seq(0.1, 0.9, by = 0.1))\ndeciles\n\n 10%  20%  30%  40%  50%  60%  70%  80%  90% \n 5.2  6.4  7.6  8.8 10.0 12.0 14.0 16.0 18.0 \n\n\nInterpretaci√≥n\nLos deciles permiten identificar la posici√≥n de los datos en intervalos del 10%. Por ejemplo, el decil 4 corresponde al valor debajo del cual est√° el 40% de los datos.\n\n\nCuartiles\nDescripci√≥n:\nLos cuartiles dividen un conjunto de datos ordenados en 4 partes iguales de acuerdo con una probabilidad predefinida.\nF√≥rmula \\[Q_k = x_{\\left( \\frac{k(n+1)}{4} \\right)}, \\quad k=1,2,3\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\ncuartiles &lt;- quantile(datos, probs = c(0.25, 0.5, 0.75))\ncuartiles\n\n25% 50% 75% \n  7  10  15 \n\n\nInterpretaci√≥n\nLos cuartiles permiten identificar c√≥mo se distribuyen los datos y ayudan a detectar la dispersi√≥n. - Q1 indica el valor que deja por debajo el 25% de los datos. - Q2 (la mediana) divide los datos en dos partes iguales. - Q3 deja por debajo el 75% de los datos. Estos valores son √∫tiles para construir diagramas de caja (boxplots) y analizar la simetr√≠a o la presencia de valores at√≠picos en la distribuci√≥n\n\n\n\n\nMedidas de Dispersi√≥n o Variabilidad\n\nRango\nDescripci√≥n:\nEl rango es la diferencia entre el valor m√°ximo y el valor m√≠nimo de un conjunto de datos.\nF√≥rmula \\[\nR = X_{\\max} - X_{\\min}\n\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\nrango &lt;- max(datos) - min(datos)\nrango\n\n[1] 16\n\n\nInterpretaci√≥n\nEl rango indica la amplitud total de los datos, es decir, qu√© tan dispersos est√°n entre el valor m√°s bajo y el m√°s alto.\n\n\nRango Intercuart√≠lico\nDescripci√≥n:\nEl rango intercuart√≠lico (RIC) es la diferencia entre el tercer cuartil (\\(Q_3\\)) y el primer cuartil (\\(Q_1\\)). Mide la dispersi√≥n de los datos centrales (el 50% intermedio), eliminando la influencia de valores extremos o at√≠picos.\nF√≥rmula\n\\[ RIC = Q_3 - Q_1 \\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20, 22, 25, 30, 35, 40)\ncuartiles &lt;- quantile(datos, probs = c(0.25, 0.75))\nRIC &lt;- cuartiles[2] - cuartiles[1]\nRIC\n\n 75% \n17.5 \n\n\nInterpretaci√≥n\nEl rango intercuart√≠lico muestra la amplitud donde se encuentra la mitad central de los datos. Un RIC peque√±o indica que los datos centrales est√°n muy agrupados, mientras que un RIC grande refleja mayor dispersi√≥n en la zona central. Adem√°s, es una medida robusta porque no se ve afectada por valores extremos.\n\n\nMediana de las Desviaciones Absolutas\nDescripci√≥n:\nLa mediana de las desviaciones absolutas (MAD) mide la dispersi√≥n de los datos alrededor de la mediana. Es una medida robusta, poco sensible a valores at√≠picos.\nF√≥rmula\n\\[\nMAD = \\text{mediana} \\left( \\, |X_i - \\text{mediana}(X)| \\, \\right)\n\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\nmad_value &lt;- mad(datos, constant = 1) # sin factor de correcci√≥n\nmad_value\n\n[1] 5\n\n\nInterpretaci√≥n\nEl MAD refleja la variabilidad t√≠pica respecto a la mediana. Si el MAD es bajo, los datos est√°n muy concentrados cerca de la mediana; si es alto, los datos est√°n m√°s dispersos.\n\n\nDesviaci√≥n Est√°ndar\nDescripci√≥n:\nLa desviaci√≥n est√°ndar mide la dispersi√≥n promedio de los datos respecto a la media. Es la medida de variabilidad m√°s usada en estad√≠stica cl√°sica.\nF√≥rmula\n\\[\ns = \\sqrt{\\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2}\n\\] Implementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\ndesv_est &lt;- sd(datos)\ndesv_est\n\n[1] 6.379655\n\n\nInterpretaci√≥n\nUn valor alto de desviaci√≥n est√°ndar indica que los datos est√°n muy dispersos respecto a la media, mientras que un valor bajo indica mayor concentraci√≥n alrededor de ella.\n\n\nVarianza\nDescripci√≥n:\nLa varianza es la medida de dispersi√≥n que indica el promedio de los cuadrados de las desviaciones respecto a la media.\nF√≥rmula\n\\[\ns^2 = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})^2\n\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\nvarianza &lt;- var(datos)\nvarianza\n\n[1] 40.7\n\n\nInterpretaci√≥n\nLa varianza expresa la dispersi√≥n en unidades cuadradas de la variable. Es √∫til en c√°lculos estad√≠sticos posteriores, aunque menos interpretable directamente que la desviaci√≥n est√°ndar.\n\n\nEstandarizaci√≥n\nDescripci√≥n:\nLa estandarizaci√≥n transforma los datos para que tengan media cero y desviaci√≥n est√°ndar uno, permitiendo comparaciones entre variables en diferentes escalas.\nF√≥rmula\n\\[\nz_i = \\dfrac{x_i - \\bar{x}}{s}\n\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\ndatos_estandarizados &lt;- scale(datos)\ndatos_estandarizados\n\n           [,1]\n[1,] -1.1285876\n[2,] -0.6583428\n[3,] -0.1880979\n[4,]  0.5956435\n[5,]  1.3793849\nattr(,\"scaled:center\")\n[1] 11.2\nattr(,\"scaled:scale\")\n[1] 6.379655\n\n\nInterpretaci√≥n\nLos valores estandarizados (z-scores) indican cu√°ntas desviaciones est√°ndar se encuentra cada dato por encima o debajo de la media.\n\n\nCoeficiente de Variaci√≥n\nDescripci√≥n:\nEl coeficiente de variaci√≥n (CV) mide la dispersi√≥n relativa dividiendo la desviaci√≥n est√°ndar entre la media. Es √∫til para comparar la variabilidad entre diferentes conjuntos de datos con medias distintas.\nF√≥rmula\n\\[\nCV = \\dfrac{s}{\\bar{x}} \\times 100\\%\n\\]\nImplementaci√≥n en R\n\ndatos &lt;- c(4, 7, 10, 15, 20)\ncv &lt;- sd(datos) / mean(datos) * 100\ncv\n\n[1] 56.96121\n\n\nInterpretaci√≥n\nUn CV bajo indica que la variabilidad relativa respecto a la media es peque√±a; un CV alto indica mayor dispersi√≥n en relaci√≥n al promedio de los datos.\n\n\n\nMedidas de Forma\n\nMedidas de Asimetr√≠a\n\nCoeficiente de Pearson\nDescripci√≥n:\nMide la asimetr√≠a de una distribuci√≥n a partir de la diferencia entre la media y la moda o mediana.\nF√≥rmula\n\\[\nA_p = \\frac{\\bar{x} - \\text{Mo}}{s}\n\\quad \\text{o bien} \\quad\nA_p = \\frac{3(\\bar{x} - \\text{Me})}{s}\n\\]\nImplementaci√≥n en R\n\npearson_skewness &lt;- function(x) {\n  (mean(x) - median(x)) / sd(x) * 3\n}\n\nInterpretaci√≥n\n\n\\(A_p &gt; 0\\): distribuci√≥n sesgada a la derecha (cola larga hacia valores grandes).\n\\(A_p &lt; 0\\): distribuci√≥n sesgada a la izquierda (cola larga hacia valores peque√±os).\n\\(A_p \\approx 0\\): sim√©trica.\n\n\n\nCoeficiente de Fisher\nDescripci√≥n:\nMide la asimetr√≠a bas√°ndose en el tercer momento estandarizado de la distribuci√≥n.\nF√≥rmula\n\\[\ng_1 = \\frac{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\bar{x})^3}{s^3}\n\\]\nImplementaci√≥n en R\n\nlibrary(e1071)\nskewness(x, type = 1)  # Fisher\n\n[1] 0\n\n\nInterpretaci√≥n\n\n\\(g_1 &gt; 0\\): sesgo positivo (cola derecha m√°s larga).\n\\(g_1 &lt; 0\\): sesgo negativo (cola izquierda m√°s larga).\n\\(g_1 = 0\\): simetr√≠a perfecta.\n\n\n\n√çndice de Yule-Bowley\nDescripci√≥n:\nMide la asimetr√≠a a partir de los cuartiles de la distribuci√≥n.\nF√≥rmula\n\\[\nA_{YB} = \\frac{(Q_3 + Q_1 - 2Q_2)}{Q_3 - Q_1}\n\\]\nImplementaci√≥n en R\n\nyule_bowley &lt;- function(x) {\n  qs &lt;- quantile(x, probs = c(0.25, 0.5, 0.75))\n  (qs[3] + qs[1] - 2*qs[2]) / (qs[3] - qs[1])\n}\n\nInterpretaci√≥n\n\n\\(A_{YB} &gt; 0\\): distribuci√≥n con cola m√°s pesada hacia la derecha.\n\\(A_{YB} &lt; 0\\): distribuci√≥n con cola m√°s pesada hacia la izquierda.\n\\(A_{YB} = 0\\): sim√©trica.\n\n\n\n√çndice de Kelly\nDescripci√≥n:\nBasado en deciles, mide la asimetr√≠a comparando la distancia de la mediana a los percentiles extremos.\nF√≥rmula\n\\[\nA_K = \\frac{(P_{90} + P_{10} - 2P_{50})}{P_{90} - P_{10}}\n\\]\nImplementaci√≥n en R\n\nkelly_index &lt;- function(x) {\n  ps &lt;- quantile(x, probs = c(0.1, 0.5, 0.9))\n  (ps[3] + ps[1] - 2*ps[2]) / (ps[3] - ps[1])\n}\n\nInterpretaci√≥n\n\n\\(A_K &gt; 0\\): sesgo a la derecha.\n\\(A_K &lt; 0\\): sesgo a la izquierda.\n\\(A_K = 0\\): sim√©trica.\n\n\n\n\nMedidas de Curtosis\n\nCoeficiente de Apuntamiento de Fisher\nDescripci√≥n:\nLa curtosis mide el grado de concentraci√≥n de los datos en torno a la media. El coeficiente de apuntamiento de Fisher compara la forma de la distribuci√≥n con la distribuci√≥n normal.\nCurtosis positiva (leptoc√∫rtica): la distribuci√≥n tiene colas m√°s pesadas y mayor concentraci√≥n en la media que la normal.\nCurtosis cero (mesoc√∫rtica): la distribuci√≥n tiene una forma similar a la normal.\nCurtosis negativa (platic√∫rtica): la distribuci√≥n tiene colas m√°s ligeras y menos concentraci√≥n en la media que la normal.\nF√≥rmula\n\\[\ng_2 = \\frac{\\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^4}{\\left( \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})^2 \\right)^2} - 3\n\\]\nImplementaci√≥n en R\n\n# Paquete necesario\nif (!require(moments)) install.packages(\"moments\")\n\nCargando paquete requerido: moments\n\n\n\nAdjuntando el paquete: 'moments'\n\n\nThe following objects are masked from 'package:e1071':\n\n    kurtosis, moment, skewness\n\nlibrary(moments)\n\ndatos &lt;- c(4, 7, 10, 15, 20)\nkurtosis(datos) # por defecto ya usa la definici√≥n de Fisher (resta 3)\n\n[1] 1.736748\n\n\nInterpretaci√≥n\nSi g2 &gt; 0: los datos son leptoc√∫rticos (m√°s pico y colas pesadas que la normal).\nSi g2 = 0: los datos son mesoc√∫rticos (similar a la normal).\nSi g2 &lt; 0: los datos son platic√∫rticos (menos pico y colas m√°s ligeras).\n\n\n\n\nMedidas Descriptivas para Dos Variables\n\nMedidas de Asociaci√≥n\n\nCovarianza\nDescripci√≥n:\nLa covarianza mide el grado de variaci√≥n conjunta de dos variables. Indica si tienden a aumentar o disminuir juntas, pero su valor depende de las unidades de medida, lo que dificulta su comparaci√≥n entre estudios.\nF√≥rmula\n\\[\n\\text{Cov}(X,Y) = \\frac{1}{n} \\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})\n\\]\nImplementaci√≥n en R\n\nx &lt;- c(4, 7, 10, 15, 20)\ny &lt;- c(3, 6, 9, 12, 18)\n\ncov(x, y)\n\n[1] 36.6\n\n\nInterpretaci√≥n\n\nCov &gt; 0: ambas variables tienden a crecer juntas.\nCov &lt; 0: cuando una crece, la otra tiende a decrecer.\nCov ‚âà 0: no hay relaci√≥n lineal aparente.\n\n\n\nCoeficiente de Correlaci√≥n de Pearson\nDescripci√≥n:\nMide la fuerza y direcci√≥n de la relaci√≥n lineal entre dos variables cuantitativas. A diferencia de la covarianza, est√° normalizado entre -1 y 1.\nF√≥rmula\n\\[\nr_{xy} = \\frac{\\text{Cov}(X,Y)}{\\sigma_X \\, \\sigma_Y}\n\\]\nImplementaci√≥n en R\n\ncor(x, y, method = \"pearson\")\n\n[1] 0.9941725\n\n\nInterpretaci√≥n\n\nr ‚âà 1: fuerte relaci√≥n lineal positiva.\nr ‚âà -1: fuerte relaci√≥n lineal negativa.\nr ‚âà 0: ausencia de relaci√≥n lineal.\n\n\n\nCoeficiente de Correlaci√≥n de Spearman\nDescripci√≥n:\nEs una medida no param√©trica de asociaci√≥n basada en los rangos de los datos. Eval√∫a la relaci√≥n mon√≥tona (creciente o decreciente), sin requerir linealidad ni normalidad.\nF√≥rmula\n\\[\n\\rho = 1 - \\frac{6 \\sum d_i^2}{n(n^2 - 1)}\n\\]\nImplementaci√≥n en R\n\ncor(x, y, method = \"spearman\")\n\n[1] 1\n\n\nInterpretaci√≥n\n\nœÅ cercano a 1: asociaci√≥n mon√≥tona positiva.\nœÅ cercano a -1: asociaci√≥n mon√≥tona negativa.\nœÅ cercano a 0: no hay relaci√≥n mon√≥tona.\n\n\n\nCoeficiente de Correlaci√≥n de Kendall\nDescripci√≥n:\nMide la concordancia entre pares de observaciones. Es m√°s robusto que Spearman cuando hay empates.\nF√≥rmula\n\\[\n\\tau = \\frac{(N_c - N_d)}{\\frac{1}{2}n(n-1)}\n\\]\nImplementaci√≥n en R\ncor(x, y, method = ‚Äúkendall‚Äù)\nInterpretaci√≥n\n\nœÑ &gt; 0: existe concordancia positiva entre las variables.\nœÑ &lt; 0: existe concordancia negativa.\nœÑ ‚âà 0: no hay asociaci√≥n.\n\n\n\n\n\n\n\nNote\n\n\n\nCorrelation does not imply causation Spurious relationship \\(\\neq\\) Causal Relationship (https://tylervigen.com/spurious-correlations)\n\n\n\n\nCoeficiente de Gini\nDescripci√≥n:\nMide la desigualdad o concentraci√≥n en una distribuci√≥n. Aunque es m√°s com√∫n en econom√≠a (para medir desigualdad de ingresos), tambi√©n se aplica a la concentraci√≥n de cualquier variable.\nF√≥rmula\n\\[\nG = \\frac{\\sum_{i=1}^n \\sum_{j=1}^n |x_i - x_j|}{2n^2 \\bar{x}}\n\\]\nImplementaci√≥n en R\n\nif (!require(ineq)) install.packages(\"ineq\")\n\nCargando paquete requerido: ineq\n\nlibrary(ineq)\nGini(x)\n\n[1] 0.2857143\n\n\nInterpretaci√≥n\n\nG = 0: perfecta igualdad (todos tienen el mismo valor).\nG = 1: m√°xima desigualdad (un individuo concentra todo el valor).\nValores intermedios: indican distintos grados de concentraci√≥n/desigualdad.\n\n\n\n\n\nGr√°ficos\n\nHerramientas y Plataformas Digitales\nData Viz Project - Copenhagen, Denmark.\nData Viz Project es la biblioteca m√°s grande del mundo de visualizaciones de datos. Re√∫ne m√°s de 160 tipos de visualizaciones (y sigue creciendo), cada una con su definici√≥n, taxonom√≠a y ejemplos, lo que la convierte en la colecci√≥n m√°s completa para encontrar la visualizaci√≥n adecuada e inspirarse.\nNo est√° dirigido √∫nicamente a analistas de datos, dise√±adores gr√°ficos o usuarios avanzados de hojas de c√°lculo, sino que busca ser un recurso de valor e inspiraci√≥n para cualquier persona que necesite representar datos y explorar nuevas formas de hacerlo: estudiantes, investigadores, periodistas, dise√±adores u otros profesionales.\nThe R Graph Gallery - Montpellier, France.\nR Graph Gallery es una colecci√≥n de gr√°ficos creados con el lenguaje de programaci√≥n R. Presenta cientos de gr√°ficos organizados en secciones, siempre acompa√±ados de su c√≥digo reproducible. La galer√≠a pone especial √©nfasis en el uso de tidyverse y ggplot2.\nCon m√°s de 400 ejemplos clasificados en cerca de 50 tipos de gr√°ficos siguiendo la taxonom√≠a de data-to-viz, constituye la compilaci√≥n m√°s completa de gr√°ficos en R disponible en la web. Cada ejemplo incluye tanto el c√≥digo como una explicaci√≥n detallada de su funcionamiento.\nCada tipo de gr√°fico comienza con un tutorial introductorio que explica su estructura y prop√≥sito. Una vez comprendidos los fundamentos, se ofrecen gu√≠as paso a paso con personalizaciones b√°sicas, para lograr gr√°ficos que no solo representen los datos de manera efectiva, sino que tambi√©n se adapten a las necesidades espec√≠ficas de cada usuario.\nfrom Data to Viz - Montpellier, France.\n\n\n\n\n\n\n\nComplete decision tree\n\n\nDescargar el poster del √°rbol de decisi√≥n\nFrom Data to Viz es una clasificaci√≥n de tipos de gr√°ficos basada en el formato de los datos de entrada. Se presenta como un √°rbol de decisiones que conduce a un conjunto de visualizaciones potencialmente adecuadas para representar un conjunto de datos.\nEl proyecto se apoya en dos ideas principales:\n\nLa mayor√≠a de los an√°lisis de datos pueden resumirse en unos veinte formatos de dataset.\nTanto los datos como el contexto determinan el gr√°fico m√°s apropiado.\n\nLa metodolog√≠a consiste en identificar y probar los tipos de gr√°ficos viables para encontrar el que mejor se ajuste a los datos y al prop√≥sito del an√°lisis. Una vez definido este conjunto, la web data-to-viz.com orienta hacia la mejor elecci√≥n, advierte sobre errores comunes y siempre ofrece un fragmento de c√≥digo reproducible en R.\nAunque el mundo de la visualizaci√≥n de datos es vasto e inagotable, este proyecto busca ser un punto de partida s√≥lido para quienes necesitan elegir y aplicar gr√°ficos de forma adecuada.\n\n\nEjemplos de gr√°ficos\nUtilizaremos un conjunto de datos con informaci√≥n relacionada a registros de estudiantes que presentaron el examen ICFES en el segundo periodo acad√©mico del a√±o 2022. Descargar Base de Datos\n\nestudiante_train2 &lt;- readRDS(\"D:/Usuario/Escritorio/Quarto Pubs Applied BioStats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/estudiante_train2.rds\")\n\nHistograma\n\nhist(estudiante_train2$punt_global)\n\n\n\n\n\n\n\n\nBox-plot o Diagrama de Cajas y Bigotes\n\nboxplot(estudiante_train2$punt_global)\n\n\n\n\n\n\n\n\nPie chart o Diagrama de Pastel\n\nlibrary(ggrepel)\n\nWarning: package 'ggrepel' was built under R version 4.4.3\n\n\nCargando paquete requerido: ggplot2\n\nlibrary(dplyr)\n\n\nAdjuntando el paquete: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(ggplot2)\n\n# Paleta profesional\npaleta_profesional &lt;- c(\n  \"Navy\"        = \"#1D3557\",\n  \"Steel\"       = \"#457B9D\",\n  \"AccentBlue\"  = \"#A8DADC\",\n  \"ForestGreen\" = \"#2A9D8F\"\n)\n\n### Variable fami_numlibros ----\nfami_numlibros &lt;- estudiante_train2$fami_numlibros\n\n# Extraer y resumir variable\ndatos_num_libros &lt;- estudiante_train2 |&gt;\n  count(categoria = fami_numlibros) |&gt;\n  mutate(\n    fraccion   = n / sum(n),\n    porcentaje = round(fraccion * 100, 1),\n    etiqueta   = paste0(porcentaje, \"%\")\n  ) |&gt;\n  arrange(desc(fraccion)) |&gt;\n  mutate(\n    categoria = factor(categoria, levels = categoria),\n    pos = cumsum(fraccion) - fraccion/2  # posici√≥n acumulada para etiquetas\n  )\n\n# Total de observaciones\ntotal_estudiantes &lt;- 236487\n\n# Colores\ncolores_libros &lt;- setNames(\n  paleta_profesional[c(\"Navy\", \"Steel\", \"AccentBlue\", \"ForestGreen\")],\n  levels(datos_num_libros$categoria)\n)\n\n# Gr√°fico de dona moderna corregido\nplot_num_libros_dona &lt;- ggplot(datos_num_libros, aes(x = 2, y = fraccion, fill = categoria)) +\n  geom_col(color = \"white\", width = 1, show.legend = TRUE) +\n  coord_polar(theta = \"y\") +\n  xlim(c(0.5, 2.8)) +  # Aumentado el l√≠mite superior para acomodar etiquetas\n  geom_text_repel(\n    aes(y = pos, label = etiqueta),\n    nudge_x = 0.3,    # Reducido el nudge para mantener etiquetas dentro del √°rea\n    direction = \"y\",   # Forzar direcci√≥n vertical\n    segment.size = 0.6,\n    segment.color = \"gray30\",\n    color = \"black\",\n    size = 4.5,\n    fontface = \"bold\",\n    family = \"serif\",\n    show.legend = FALSE,\n    max.overlaps = Inf  # Permitir todas las etiquetas\n  ) +\n  annotate(\"text\", x = 0, y = 0, \n           label = paste0(\"Total\\n\", format(total_estudiantes, big.mark = \",\")),\n           family = \"serif\", \n           fontface = \"bold\",\n           size = 6, \n           lineheight = 1.1, \n           color = \"#333333\") +\n  scale_fill_manual(values = colores_libros) +\n  labs(\n    title = \"Distribuci√≥n del N√∫mero de Libros en el Hogar\",\n    subtitle = \"Proporci√≥n de estudiantes seg√∫n el n√∫mero estimado de libros en casa\"\n  ) +\n  theme_void(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", family = \"serif\", hjust = 0.5),\n    plot.subtitle = element_text(size = 13, family = \"serif\", hjust = 0.5, color = \"gray30\"),\n    legend.title = element_blank(),\n    legend.text = element_text(family = \"serif\", size = 12),\n    plot.background = element_rect(fill = \"white\", color = NA),\n    legend.position = \"bottom\"\n  )\n\nplot_num_libros_dona\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_text()`).\n\n\n\n\n\n\n\n\n\nGr√°fico de Barra Apicalada\n\n### Variable fami_educacionmadre ----\nfami_educacionmadre &lt;- estudiante_train2$fami_educacionmadre\ntable(fami_educacionmadre)\n\nfami_educacionmadre\n     0      1 \n201621  34866 \n\n# Datos Originales\ndatos_edu_madre &lt;- data.frame(\n  categoria = c(\"Sin Educaci√≥n Superior\", \"Con Educaci√≥n Superior\"),\n  valor = c(201621, 34866)\n)\n\n# Prepare data\ndatos_edu_madre &lt;- datos_edu_madre %&gt;%\n  mutate(\n    fraccion = valor / sum(valor),\n    porcentaje = round(fraccion * 100, 1),\n    etiqueta = paste0(porcentaje, \"%\")\n  )\n\n# Define color palette (colorblind-friendly, elegant)\ncolores &lt;- c(\"Sin Educaci√≥n Superior\" = \"#ADB5BD\", \n             \"Con Educaci√≥n Superior\" = \"#1D3557\")\n\n# Plot: 100% Stacked Bar Chart\nplot_edu_madres &lt;- ggplot(datos_edu_madre, aes(x = \"Educaci√≥n de las Madres\", y = fraccion, fill = categoria)) +\n  geom_bar(stat = \"identity\", width = 0.5, color = \"white\") +\n  geom_text(aes(label = etiqueta), \n            position = position_stack(vjust = 0.5), \n            color = \"white\", size = 5, fontface = \"bold\") +\n  scale_fill_manual(values = colores) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +\n  coord_flip() +\n  labs(\n    title = \"Distribuci√≥n de la Educaci√≥n Superior en las Madres\",\n    subtitle = \"Proporci√≥n de madres con y sin educaci√≥n superior\",\n    x = NULL, y = NULL, fill = NULL\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", family = \"serif\", hjust = 0.5),\n    plot.subtitle = element_text(size = 13, family = \"serif\", hjust = 0.5, color = \"gray30\"),\n    axis.text = element_blank(),\n    axis.ticks = element_blank(),\n    panel.grid = element_blank(),\n    legend.position = \"bottom\",\n    legend.text = element_text(size = 12, family = \"serif\"),\n    plot.background = element_rect(fill = \"white\", color = NA)\n  )\n#ggsave(plot_edu_madres, \n#       filename = \"plot_edu_madres.pdf\",  # Para guardar el gr√°fico generado.\n#       device = \"pdf\")\nplot_edu_madres\n\n\n\n\n\n\n\n\nGr√°fico de Barras\n\n### Variable fami_estratovivienda ----\n\n# Extraer y resumir variable\nfami_estratovivienda &lt;- estudiante_train2 %&gt;%\n  count(categoria = fami_estratovivienda) %&gt;%\n  mutate(\n    fraccion = n / sum(n),\n    porcentaje = round(fraccion * 100, 1),\n    etiqueta = paste0(porcentaje, \"%\")\n  ) %&gt;%\n  mutate(\n    categoria = factor(categoria, levels = categoria)  # establecer niveles en ese orden\n  )\n\n# Color palette for 4 categories (from your `paleta_profesional`)\ncolores_estratos &lt;- setNames(\n  paleta_profesional[c(\n    \"Navy\", \"Steel\", \"AccentBlue\", \"ForestGreen\",\n    \"Amber\", \"Beige\", \"MediumGray\"\n  )],\n  levels(fami_estratovivienda$categoria)\n)\n\n# Plot\n\n# Configuraci√≥n esencial del gr√°fico de barras\nplot_estratos &lt;- ggplot(fami_estratovivienda, \n                          aes(x = categoria, y = fraccion, fill = categoria)) +\n  geom_col(width = 0.7, color = \"white\") +\n  geom_text(aes(label = etiqueta), \n            vjust = -0.3,\n            color = \"black\", size = 4.5, fontface = \"bold\", family = \"serif\") +  # Fuente serif en etiquetas\n  scale_fill_manual(values = colores_estratos) +\n  scale_y_continuous(labels = scales::percent_format(accuracy = 1),\n                     expand = expansion(mult = c(0, 0.1))) +\n  labs(\n    title = \"Distribuci√≥n del Estrato del Hogar del Estudiante\",\n    subtitle = \"Proporci√≥n de estudiantes seg√∫n el estrato de la vivienda\",\n    x = \"Estratificaci√≥n Socioecon√≥mica\", \n    y = \"Porcentaje\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(size = 16, face = \"bold\", family = \"serif\", hjust = 0.5),\n    plot.subtitle = element_text(size = 13, family = \"serif\", hjust = 0.5, color = \"gray30\"),\n    # Cambiar fuentes de ejes a serif\n    axis.title = element_text(family = \"serif\", size = 13),              # T√≠tulos de ejes\n    axis.text.x = element_text(family = \"serif\", size = 12),             # Texto eje X (categor√≠as)\n    axis.text.y = element_text(family = \"serif\", size = 12),             # Texto eje Y (porcentajes)\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.y = element_blank(),\n    panel.grid.major.y = element_line(linetype = \"dotted\", linewidth = 1),  # L√≠neas de referencia\n    legend.position = \"none\",\n    plot.background = element_rect(fill = \"white\", color = NA)\n  )\n\n# Guardar\n#ggsave(plot_estratos,\n#       filename = \"plot_estratos2.pdf\",\n#       device = \"pdf\")\n\nplot_estratos"
  },
  {
    "objectID": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#tarea-y-repaso",
    "href": "biostats/M√≥dulo 4 - Estad√≠stica Descriptiva Exploratoria/mod4_eda.html#tarea-y-repaso",
    "title": "M√≥dulo 4: An√°lisis Descriptivo y Exploratorio",
    "section": "üóÇÔ∏è Tarea y Repaso",
    "text": "üóÇÔ∏è Tarea y Repaso\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html",
    "href": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html",
    "title": "M√≥dulo 2: Introducci√≥n a RStudio",
    "section": "",
    "text": "En este m√≥dulo se introduce el lenguaje R y el entorno RStudio, herramientas fundamentales para el an√°lisis estad√≠stico y la programaci√≥n en diferentes campos de la ciencia. El prop√≥sito es guiar al estudiante en la descarga, instalaci√≥n y configuraci√≥n del software, as√≠ como en la exploraci√≥n de su interfaz y sus principales funcionalidades.\nA lo largo del m√≥dulo se abordan los siguientes aspectos:\n\nConceptos b√°sicos de programaci√≥n y su importancia en el razonamiento l√≥gico y cient√≠fico.\nHistoria y caracter√≠sticas de R, sus ventajas frente a otros softwares y el papel de la comunidad que lo respalda.\nExploraci√≥n de RStudio, sus paneles y atajos m√°s importantes para facilitar el trabajo diario.\nOperaciones b√°sicas en R: desde c√°lculos simples hasta la creaci√≥n de objetos, variables y estructuras de datos como vectores, matrices, data frames y listas.\nTipos de datos en R y funciones esenciales para su manipulaci√≥n y verificaci√≥n.\nInstalaci√≥n y uso de paquetes, indispensables para ampliar las capacidades de R en an√°lisis estad√≠stico y programaci√≥n avanzada.\nAlternativas a RStudio y plataformas en la nube (Posit Cloud, Google Colab, VS Code).\n\nEste m√≥dulo busca que el estudiante adquiera autonom√≠a en el uso del software, desarrolle confianza en la escritura de c√≥digo y est√© preparado para avanzar en los siguientes contenidos del curso."
  },
  {
    "objectID": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#introducci√≥n",
    "href": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#introducci√≥n",
    "title": "M√≥dulo 2: Introducci√≥n a RStudio",
    "section": "",
    "text": "En este m√≥dulo se introduce el lenguaje R y el entorno RStudio, herramientas fundamentales para el an√°lisis estad√≠stico y la programaci√≥n en diferentes campos de la ciencia. El prop√≥sito es guiar al estudiante en la descarga, instalaci√≥n y configuraci√≥n del software, as√≠ como en la exploraci√≥n de su interfaz y sus principales funcionalidades.\nA lo largo del m√≥dulo se abordan los siguientes aspectos:\n\nConceptos b√°sicos de programaci√≥n y su importancia en el razonamiento l√≥gico y cient√≠fico.\nHistoria y caracter√≠sticas de R, sus ventajas frente a otros softwares y el papel de la comunidad que lo respalda.\nExploraci√≥n de RStudio, sus paneles y atajos m√°s importantes para facilitar el trabajo diario.\nOperaciones b√°sicas en R: desde c√°lculos simples hasta la creaci√≥n de objetos, variables y estructuras de datos como vectores, matrices, data frames y listas.\nTipos de datos en R y funciones esenciales para su manipulaci√≥n y verificaci√≥n.\nInstalaci√≥n y uso de paquetes, indispensables para ampliar las capacidades de R en an√°lisis estad√≠stico y programaci√≥n avanzada.\nAlternativas a RStudio y plataformas en la nube (Posit Cloud, Google Colab, VS Code).\n\nEste m√≥dulo busca que el estudiante adquiera autonom√≠a en el uso del software, desarrolle confianza en la escritura de c√≥digo y est√© preparado para avanzar en los siguientes contenidos del curso."
  },
  {
    "objectID": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#objetivos",
    "href": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#objetivos",
    "title": "M√≥dulo 2: Introducci√≥n a RStudio",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\n\nEntender el proceso de descarga, instalaci√≥n y configuraci√≥n de R y RStudio.\nReconocer las secciones y funciones principales de la interfaz de RStudio.\nValorar la importancia de R como software estad√≠stico libre, destacando sus ventajas, diferencias y el rol de su comunidad frente a otros softwares.\nIntroducir los fundamentos de programaci√≥n en R, fomentando confianza en la escritura de c√≥digo.\nFamiliarizarse con los principales tipos de datos, variables y estructuras (vectores, matrices, data frames, listas).\nExplorar funciones b√°sicas de R para la creaci√≥n, manipulaci√≥n y verificaci√≥n de objetos.\nPromover la autonom√≠a en el uso de R y RStudio, preparando al estudiante para el desarrollo de los siguientes m√≥dulos."
  },
  {
    "objectID": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#desarrollo",
    "href": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#desarrollo",
    "title": "M√≥dulo 2: Introducci√≥n a RStudio",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\n\nüé® El arte de programar\n\nEl proceso de programaci√≥n, como lo define Hadley Wickham, Chief Scientist en Posit y l√≠der del equipo de tidyverse, en su libro R for Data Science, consta de las siguientes etapas:\n\n\n\nFigura 1: En nuestro modelo de proceso de ciencia de datos, se empieza por importar y ordenar los datos. A continuaci√≥n, se comprenden los datos mediante un ciclo iterativo de transformaci√≥n, visualizaci√≥n y modelizaci√≥n. El proceso finaliza con la comunicaci√≥n de los resultados a otras personas. Tomada de R for Data Science (2e).\n\n\nSaber programar no implica necesariamente memorizar las librer√≠as y funciones de Python, R, C++, etc., ni te lo garantiza realizar cursos en los que copies y pegues c√≥digo para ver la salida de estos. Programar involucra un proceso de razonamiento, que, de desarrollarse permitir√° al usuario desenvolverse en diversos escenarios, para diferentes retos y en distintos programas. Este proceso, contrario a lo que se cree tiene como prop√≥sito ser √∫til, ameno, replicable y funcionar como una herramienta desarrollada para facilitar procesos y producir nuevo conocimiento.\n\n\n\n‚ÄúPrograms must be written for people to read, and only incidentally for machines to execute.‚Äù\n‚Äî Hal Abelson\n\n\n\nProgramar no se reduce a solucionar un problema a trav√©s de c√≥digo, tambi√©n es la documentaci√≥n de c√≥mo este fue resuelto para que las personas interesadas puedan entender el camino que se sigui√≥. Hardley, lo define bajo los siguientes principios: estar centrado en el ser humano, ser coherente, componible e inclusivo. Los mismos que componen el universo Tidyverse, colecci√≥n de paquetes en R que veremos m√°s adelante.\n\n\nDatos ‚û°Ô∏è Informaci√≥n ‚û°Ô∏è Conocimiento\n\n\n\nüõ†Ô∏è R y RStudio\n\nR fue creado a principios de la d√©cada de 1990 por los estad√≠sticos de la Universidad de Auckland, Ross Ihaka y Robert Gentleman. Por si alguno de ustedes se lo preguntaba, s√≠, el lenguaje se llama R por ser la inicial de ambos nombres de los autores.\n\n\n\n\n\n\n\n‚ÄúR tiene sus or√≠genes en S, un lenguaje de programaci√≥n creado en los Laboratorios Bell de Estados Unidos. S√≠, los mismos laboratorios que inventaron el transistor, el l√°ser, el sistema operativo Unix y algunas otras cosas m√°s.‚Äù Juan Bosco Mendoza Vega - R para principiantes.\n\n\n\n\nR es un lenguaje de programaci√≥n de uso libre con una gran comunidad a nivel mundial. La cual al ser activa mantiene a R en constante renovaci√≥n y actualizaci√≥n, esto lo hace un software poderoso y vers√°til. Al momento de escribir este material vamos en la versi√≥n 4.4.1 ‚ÄúRace for Your Life‚Äù\nEs un programa gratuito, multiplataforma, con extensa documentaci√≥n como soporte a sus numerosos m√©todos, funciones y tecnolog√≠a que crece todos los d√≠as. Permite realizar investigaci√≥n reproducible y la posibilidad de programar un proyecto de diversas maneras.\nR nos permite hacer an√°lisis de c√°lculo estad√≠stico y graficaci√≥n.\n\n\nEntonces, ¬øuso R, Python o Excel?\n\nNing√∫n lenguaje de programaci√≥n es mejor que otro, cada uno tiene sus puntos fuertes y es ut√≠l en escenarios particulares. En ocasiones nos ser√° mas ventajoso trabajar con los datos desde Excel, sin embargo este curso se desarrollara en su basta mayor√≠a a trav√©s de R, m√°s precisamente, RStudio.\n\n\n\n¬øD√≥nde puedo usar R?\n\nPodemos usar el lenguaje de programaci√≥n R a trav√©s de diferentes servicios, algunos de instalaci√≥n local y otros a los que podremos acceder de manera gratuita a trav√©s de internet.\nExisten alternativas a Rstudio como lo son Visual Studio Code y Google Colab por medio de los cuales podemos programar con c√≥digo R pero sin la posibilidad de aprovechar los beneficios y funciones de la aplicaci√≥n RStudio.\nAlgunas de las alternativas m√°s comunes son:\n\n\nHerramientas para programar en lenguaje R\n\n\nCloud-based solution\nSoftwares\n\n\n\n\nPosit Cloud\nRStudio Desktop\n\n\nGoogle Colab\nVisual Studio Code\n\n\n\n\nExisten alternativas a Rstudio como lo vemos en la anterior tabla, por medio de los cuales podemos programar en c√≥digo R pero sin la posibilidad de aprovechar los beneficios y funciones de la aplicaci√≥n RStudio mencionados previamente.\nAlgunas de las caracter√≠sticas m√°s relevantes de cada uno se listan a continuaci√≥n:\n\nPosit Cloud: Posit Cloud es una soluci√≥n basada en la nube que le permite acceder al potente conjunto de herramientas de ciencia de datos de Posit directamente desde su navegador, sin necesidad de instalaciones ni configuraciones complejas.\nAcceso a trav√©s de: Posit Cloud Website\nGoogle Colab: Colab es un servicio alojado de Jupyter Notebook que no requiere configuraci√≥n y proporciona acceso gratuito a recursos inform√°ticos, incluidas GPU y TPU. Colab es especialmente adecuado para el aprendizaje autom√°tico, la ciencia de datos y la educaci√≥n.\nAcceso a trav√©s de: Colab Website\nVisual Studio Code: VS Code es un editor de c√≥digo fuente ligero pero eficaz desarrollado por Microsoft que se ejecuta en el escritorio y est√° disponible para Windows, macOS y Linux. Incluye compatibilidad integrada con JavaScript, TypeScript y Node.js, y cuenta con un amplio ecosistema de extensiones para otros lenguajes y entornos de ejecuci√≥n.\nAcceso a trav√©s de: Download Visual Studio\nRStudio Desktop: es un entorno de desarrollo integrado (IDE) dise√±ado para ayudarle a ser m√°s productivo en su trabajo diario de ciencia de datos. En otras palabras, es la herramienta que nos permitir√° programar en lenguaje R, la interfaz y el veh√≠culo de nuestro an√°lisis. Ademas del an√°lisis ya mencionado, permite la integraci√≥n de otros lenguajes de programaci√≥n y la consolidaci√≥n de documentos, presentaciones, aplicaciones, libros, entre otras m√°s.\n\n\n\n\n\nüö™ Instalaci√≥n de R y RStudio\n\nPara dar inicio al proceso de instalaci√≥n de R y RStudio Desktop, ser√° redirigido a la p√°gina web oficial dando click aqu√≠, all√≠ encontrar√° la posibilidad de descargar ambos archivos. Para el caso de R, ir√° directamente al enlace de la Red Completa de Archivos R (CRAN) en la cual podr√° iniciar la descarga una vez seleccione el link correspondiente a su sistema base. Posterior a la descarga deber√° abrir este archivo con el cual iniciar√° la instalaci√≥n de esta nueva aplicaci√≥n de manera similar, se realizar√° la descarga de la aplicaci√≥n RStudio dependiendo del sistema operativo.\n\n\n\nPosit - Download RStudio Desktop\n\n\nUna vez iniciado el proceso de instalaci√≥n de R, notara la aparici√≥n de recuadros con informaci√≥n relacionada a la carpeta en que se instalar√° el programa y una serie de configuraciones las cuales se muestran a continuaci√≥n y se recomienda dejar de manera predeterminada por la empresa.\n\n\nGu√≠a de Instalaci√≥n de R para Usuarios Windows\n\n\n\nP√°gina de descarga de R\n\n\n\n\n\nP√°gina principal de CRAN\n\n\n\n\n\nPaso 1 para descargar instalador de R en Windows\n\n\n\n\n\nPaso 2 para descargar instalador de R en Windows\n\n\n\n\n\nPaso 3 para descargar instalador de R en Windows\n\n\nTras ejecutar el archivo descargado, lo primero que aparecer√° ser√° una ventana que permitir√° elegir el idioma a utilizar durante la instalaci√≥n. Para este manual utilizaremos ‚ÄúEspa√±ol‚Äù.\n\n\n\nPaso 1 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 2 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 3 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 4 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 5 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 6 instalaci√≥n de R en Windows\n\n\n\n\n\nPaso 7 instalaci√≥n de R en Windows\n\n\nUna vez termines todos los pasos descritos anteriormente, da clic en la opci√≥n Finalizar y ya estar√°s listo para continuar con la instalaci√≥n de la interfaz gr√°fica RStudio.\n\n\n\nPaso 8 instalaci√≥n de R en Windows\n\n\n\n\nGu√≠a de Instalaci√≥n de RStudio para Usuarios Windows\n\n\n\nP√°gina de descarga de RStudio\n\n\n\n\n\nPaso 1 instalaci√≥n de RStudio en Windows\n\n\n\n\n\nPaso 2 instalaci√≥n de RStudio en Windows\n\n\n\n\n\nPaso 3 instalaci√≥n de RStudio en Windows\n\n\n\n\n\nüëÄ Dise√±o del panel\nUna vez abierta la aplicaci√≥n Rstudio evidenciar√° la siguiente ventana:\n\n\nA continuaci√≥n se dar√° una breve explicaci√≥n de las caracter√≠sticas de cada panel:\n\nSource (fuente): Es el espacio para escribir un nuevo script, crear un nuevo documento o cargar uno guardado previamente en nuestra computadora. En este cuadrante podemos seleccionar una o varias l√≠neas de c√≥digo para ejecutarlas.\nConsole (consola): El panel de consola proporciona un √°rea para ejecutar c√≥digo de forma interactiva. Por defecto est√° vinculado a R, pero tambi√©n puede proporcionar una consola Python si lo requieres.\nEnviroments (ambientes): contiene las pesta√±as Environment, donde se almacenan los datos, valores y funciones definidas History, Connections, en caso de enlazar la sesi√≥n a alg√∫n servidor, Build, VCS, y Tutorial\nOutput (salida): contiene las pesta√±as Files, Plots, Packages, Help, Viewer, y Presentation.\n\n\n\n\nüë£ Bases de la programaci√≥n en R\n\nNos concentraremos principalmente en el panel de Source en el cual crearemos un nuevo documento, un R script, en el cual iremos consignando nuestras primeras lineas de c√≥digo.\nPor otra parte, piensa en el panel de Console el cual har√° las veces de calculadora y ser√° la herramienta por medio de la cual ejecutaremos nuestro c√≥digo. Podremos hacer cuentas r√°pidas o realizar operaciones de todo tipo pero ten en cuenta que estas no se guardar√°n.\nEl R Script ser√° nuestro documento y la Consola nuestra hoja de notas y desarrollos. El R Script ser√° nuestra ruta de procedimientos e instrucciones a R que nos mostrar√° los resultados que le solicitemos por medio de la Consola.\nEn el Enviroment podremos ver los objetos guardados, veremos como en ocasiones ser√° de utilidad guardar objetos all√≠ para usarlos en el desarrollo de nuestras tareas.\n\n\n\n\n\n\n\nTip\n\n\n\n¬øSab√≠as que R es un lenguaje de programaci√≥n orientada a objetos? R es un lenguaje orientado a objetos, lo que significa que trabaja con estructuras llamadas objetos que agrupan datos y funciones. Por ejemplo, cuando creas un conjunto de datos, una gr√°fica o un modelo, est√°s creando un objeto. Cada objeto tiene propiedades (atributos) y puede ser manipulado con funciones espec√≠ficas. Esto hace que R sea muy flexible y te permita organizar tu trabajo de forma clara y reutilizable.\n\n\n\nComo mencionamos anteriormente, uno de los usos mas b√°sicos que podemos aprovechar de R es usarlo como una calculadora. Desde operaciones elementales hasta algo un poco m√°s avanzado. Ten en cuenta que no podremos ver los pasos para resolver la operaci√≥n, funci√≥n que no est√° integrada en este software como s√≠ lo est√° en Wolfram Mathematica.\n\n\n\n\n\n\n\nTip\n\n\n\nEn R, cuando tenemos varias operaciones ocurriendo al mismo tiempo, en realidad, algunas de ellas son realizadas antes que otras y el resultado de ellas depender√° de este orden. Este orden sigue la jerarqu√≠a matem√°tica est√°ndar, aritm√©ticas, relacionales, l√≥gicas y de asignaci√≥n.\n\n\n\n\n\n\n\n\n\n\nOrden\nOperadores\nSimbolo\n\n\n\n\n1\nPar√©ntesis (Corchetes)\n() , []\n\n\n2\nExponentes\n^\n\n\n3\nMultiplicaci√≥n y Divisi√≥n\n* , /\n\n\n4\nSuma o Resta\n+ , -\n\n\n5\nRelacionales\n&lt; , &lt;= , &gt; , &gt;= , == , !=\n\n\n6\nL√≥gicos\n! , & , |\n\n\n7\nAsignaci√≥n\n&lt;-\n\n\n\nIniciemos realizando una operaci√≥n b√°sica en la consola, realicemos la suma entre 23 y 58.\n\n23 + 58\n\n[1] 81\n\n\nGuardemos ese resultado, definiendo que el total es igual a esta suma\n\ntotal = 23 + 58\n\nMultipiquemos el resultado por 3\n\ntotal * 3\n\n[1] 243\n\n\n\nDetr√°s de este proceso lo que realizamos fue, una suma de dos n√∫meros enteros, creamos un objeto llamado total en el que almacenamos la suma, luego llamamos ese objeto de total y lo usamos como una forma abreviada para realizar el producto.\nCuando creamos un objeto usualmente utilizamos el signo = o el s√≠mbolo &lt;-. Tenga en cuenta que hay palabras que no pueden ser utilizadas a la hora de crear un objeto, estas son de uso exclusivo para funciones y algunas se muestran a continuaci√≥n:\nReserved Words:\nif , else , repeat , while , fuction , for , in , next , break , TRUE , FALSE , NULL , Inf , NaN , NA .\nAdem√°s, tenga en cuenta que para los nombres definidos para las variables:\n\nUn nombre de variable debe empezar por una letra y puede ser una combinaci√≥n de letras, d√≠gitos, punto(.) y gui√≥n bajo(_). Si empieza por punto(.), no puede ir seguido de un d√≠gito.\nUn nombre de variable no puede empezar por un n√∫mero ni por un gui√≥n bajo (_).\nLos nombres de las variables distinguen entre may√∫sculas y min√∫sculas (age, Age y AGE son tres variables diferentes)\n\n\n\n\nüî¢ Tipos de datos: asignaci√≥n y verificaci√≥n\n\n\n\nTipo\nDescripci√≥n\nEjemplo\n\n\n\n\nnumeric\nN√∫meros reales (decimales o enteros)\n3.14, -2\n\n\ninteger\nN√∫meros enteros\n2L, -5L\n\n\ncharacter\nCadenas de texto\n\"Estad√≠stica\"\n\n\nlogical\nValores l√≥gicos\nTRUE, FALSE\n\n\ncomplex\nN√∫meros complejos\n1 + 2i\n\n\nNA\nDato faltante o no disponible\nNA\n\n\n\n\nPara averiguar el tipo de dato, podemos usar las siguientes funciones typeof(x), class(x) y str(x). Para confirmar un tipo de dato tambi√©n podemos usar is.na(x), is.numeric(x), is.character .\n\na&lt;-pi\na\n\n[1] 3.141593\n\nb&lt;--2\nb\n\n[1] -2\n\nc&lt;-\"Estad√≠stica\"\nc\n\n[1] \"Estad√≠stica\"\n\nd&lt;-2==3\nd\n\n[1] FALSE\n\ne&lt;-1+5i\ne\n\n[1] 1+5i\n\n\nPara averiguar el tipo de dato, podemos usar las siguientes funciones typeof(x), class(x) y str(x). Para confirmar un tipo de dato tambi√©n podemos usar is.na(x), is.numeric(x), is.character.\n\n\n\n\n\n\n\nTip\n\n\n\nEn R, no es lo mismo un n√∫mero algebraico entero a un tipo de dato entero. Los n√∫meros enteros como lo son 0, -2, 8, 400, -26 son un ejemplo de tipo de datos num√©ricos en R. Sin embargo, los tipos de datos enteros los encontramos, por ejemplo, al consultar length(x) las dimensiones de las estructuras de datos son un claro ejemplo de tipo de dato entero.\n\n\n\n\nüèõÔ∏è Estructuras de datos\n\nExisten formas m√°s complejas de almacenar datos, estas son por ejemplo, vectores, matrices, dataframes y listas, este √∫ltimo es bastante vers√°til pues permite almacenar objetos y estructuras de diferentes clases.\n\n\n\n\n\n\n\n\n\nEstructura\nDescripci√≥n\nEjemplo\n\n\n\n\nvector\nSecuencia de elementos del mismo tipo\nc(1, 2, 3)\n\n\nmatrix\nArreglo bidimensional con elementos del mismo tipo\nmatrix(1:4, nrow = 2)\n\n\narray\nArreglo multidimensional\narray(1:8, dim = c(2,2,2))\n\n\nlist\nContenedor de elementos de diferentes tipos\nlist(1, \"a\", TRUE)\n\n\ndata.frame\nTabla de datos con columnas de tipos distintos\ndata.frame(x = 1:3, y = c(\"a\", \"b\", \"c\"))\n\n\nfactor\nVariable categ√≥rica con niveles\nfactor(c(\"alto\", \"bajo\", \"medio\"))\n\n\ntibble\nVersi√≥n moderna de data.frame del paquete tibble\ntibble(x = 1:3, y = letters[1:3])\n\n\n\n\nVectores y Matrices\n\nLos vectores y matrices son arreglos de m√°s de una dimensi√≥n \\(n\\)x\\(1\\) o \\(n\\)x\\(m\\), respectivamente, estos pueden contener datos de texto, num√©ricos y l√≥gicos, entre otros. Las siguientes son diversas formas de crear vectores\n\nc(1,2,3)\n\n[1] 1 2 3\n\ny&lt;-c(0:10)\ny\n\n [1]  0  1  2  3  4  5  6  7  8  9 10\n\nx&lt;-c(seq(from=0,to=100,by=10))\nx\n\n [1]   0  10  20  30  40  50  60  70  80  90 100\n\nc(rep(\"a,b\",times=5))\n\n[1] \"a,b\" \"a,b\" \"a,b\" \"a,b\" \"a,b\"\n\n\nEn R el producto punto entre vectores se realiza usando el comando %*% asegur√°ndonos de que las dimensiones coincidan (usamos t() para transponer), por otro lado la suma y el producto entre vectores se realiza elemento a elemento, de esta forma tambi√©n est√° definida la divisi√≥n entre vectores, ya que se realiza elemento a elemento. Podemos acceder a partes espec√≠ficas de un vector seg√∫n su posici√≥n, concatenar vectores y apilarlos vectores de forma vertical cbind() y horizontal rbind().\n\nx+y\n\n [1]   0  11  22  33  44  55  66  77  88  99 110\n\nx*y\n\n [1]    0   10   40   90  160  250  360  490  640  810 1000\n\n2*x\n\n [1]   0  20  40  60  80 100 120 140 160 180 200\n\ny/x\n\n [1] NaN 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1\n\nx%*%t(y)\n\n      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]\n [1,]    0    0    0    0    0    0    0    0    0     0     0\n [2,]    0   10   20   30   40   50   60   70   80    90   100\n [3,]    0   20   40   60   80  100  120  140  160   180   200\n [4,]    0   30   60   90  120  150  180  210  240   270   300\n [5,]    0   40   80  120  160  200  240  280  320   360   400\n [6,]    0   50  100  150  200  250  300  350  400   450   500\n [7,]    0   60  120  180  240  300  360  420  480   540   600\n [8,]    0   70  140  210  280  350  420  490  560   630   700\n [9,]    0   80  160  240  320  400  480  560  640   720   800\n[10,]    0   90  180  270  360  450  540  630  720   810   900\n[11,]    0  100  200  300  400  500  600  700  800   900  1000\n\nt(x)%*%y\n\n     [,1]\n[1,] 3850\n\nx[3]\n\n[1] 20\n\ncbind(x,y)\n\n        x  y\n [1,]   0  0\n [2,]  10  1\n [3,]  20  2\n [4,]  30  3\n [5,]  40  4\n [6,]  50  5\n [7,]  60  6\n [8,]  70  7\n [9,]  80  8\n[10,]  90  9\n[11,] 100 10\n\nrbind(x,y)\n\n  [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11]\nx    0   10   20   30   40   50   60   70   80    90   100\ny    0    1    2    3    4    5    6    7    8     9    10\n\nc(x,y)\n\n [1]   0  10  20  30  40  50  60  70  80  90 100   0   1   2   3   4   5   6   7\n[20]   8   9  10\n\n\n\nA&lt;-matrix(1:9, nrow = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nB&lt;-diag(c(1:3))\nB\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    2    0\n[3,]    0    0    3\n\nmatrix(NA, ncol = 3,nrow = 2)\n\n     [,1] [,2] [,3]\n[1,]   NA   NA   NA\n[2,]   NA   NA   NA\n\n\nLa suma y el producto de matrices se realiza elemento a elemento, se usa el comando %*% para calcular el producto usual entre matrices siempre las dimensiones sean las correctas, usamos solve() para calcular la inversa siempre que la matriz sea no singular, para calcular la traspuesta de una matriz escribimos t(x), si se quiere extraer la diagonal usamos diag(), para el c√°lculo de el determinante se usa det(). De forma similar a los vectores, podemos acceder a las filas, columnas y entradas de una matriz y unirlas vertical u horizontalmente.\n\nA+B\n\n     [,1] [,2] [,3]\n[1,]    2    4    7\n[2,]    2    7    8\n[3,]    3    6   12\n\nA*B\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0   10    0\n[3,]    0    0   27\n\nA%*%B\n\n     [,1] [,2] [,3]\n[1,]    1    8   21\n[2,]    2   10   24\n[3,]    3   12   27\n\nsolve(B)\n\n     [,1] [,2]      [,3]\n[1,]    1  0.0 0.0000000\n[2,]    0  0.5 0.0000000\n[3,]    0  0.0 0.3333333\n\ndiag(A)\n\n[1] 1 5 9\n\ndet(B)\n\n[1] 6\n\nA[,1]\n\n[1] 1 2 3\n\nB[1,]\n\n[1] 1 0 0\n\nB[c(1,2),c(2,3)]\n\n     [,1] [,2]\n[1,]    0    0\n[2,]    2    0\n\ncbind(A,B)\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    1    4    7    1    0    0\n[2,]    2    5    8    0    2    0\n[3,]    3    6    9    0    0    3\n\nrbind(A,B)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n[4,]    1    0    0\n[5,]    0    2    0\n[6,]    0    0    3\n\n\n\n\n\nDataframes\n\nLos dataframes son conjuntos de datos de dimensi√≥n \\(n\\)x\\(m\\), estos pueden contener diferentes variables, usualmente ubicadas por columna, as√≠ como mezclar diferentes tipos de datos, pueden ser exportadas y estar en diversos formatos como .xlsx,.csv,.txt entre otros, o ser cargadas o creadas directamente desde R.\n\n\n\n\nüéä Bonus\n\nAtajos y comandos r√°pidos\n\n\n\nComando\nEspacio\nFunci√≥n\n\n\n\n\n‚¨ÜÔ∏è\nConsola\nVolver a mostrar los c√≥digos anteriores\n\n\nCtrl + L\nConsola\nLimpiar Consola\n\n\nCtrl + Enter\nScript\nCorrer l√≠nea de c√≥digo\n\n\nCtrl + Alt + R\nScript\nCorrer todo\n\n\nCtrl + S\nScript\nGuardar\n\n\nCtrl + F\nScript\nGuardar\n\n\n#\nScript\nInsertar alg√∫n comentario en el c√≥digo\n\n\n\n\n\nFunciones √∫tiles\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\ngetwd()\nDevuelve la direcci√≥n del documento en el directorio de trabajo actual del proceso R\n\n\nsetwd()\nDefinir una direcci√≥n del directorio de trabajo para la sesi√≥n actual\n\n\nrm(object)\nEliminar del Enviroment alg√∫n elemento guardado, como value, dataframe, function, etc.\n\n\nrm(list=ls())\nEliminar todos los elementos del Enviroment\n\n\nkeepit &lt;- c(‚Äúdata1‚Äù, ‚Äúdata2‚Äù) rm(list = setdiff(ls(), keepit))\nEn caso de desear mantener solo unos objetos y eliminar el resto\n\n\nrm(list = setdiff(ls(), c(‚Äúdatabase_1‚Äù, ‚Äúdatabase_2‚Äù)))\nEliminar todos los objetos del enviroment menos los especificados\n\n\ngc()\nLiberar RAM\n\n\n\n\n\nGuardar y abrir objetos creados\nEn caso de querer guardar un objeto creado de cualquier tipo se recomiendan las siguientes funciones:\n\n# Para Guardar el Objeto en formato .rds\nsaveRDS(mi_df, \"file_folder/datos_limpios.mi_df\")\n\n# Para volver a cargar mi objeto\nmi_df &lt;- readRDS(\"file_folder/datos_limpios.mi_df\")\n\n# Para guardar varios objetos en formato .RData\nsave(df, diccionario_var, plot1, file= here(\"data_clean\", \"base2.RData\"))\nload(here(\"data_clean\", \"base2.RData\"))\n\nLa funci√≥n here del paquete del mismo nombre es √∫til para tener mas control y especificar un folder file del directorio de trabajo en el que se este trabajando.\n\n\n\nüì¶ ¬øQu√© son los paquetes (Packages) y las librer√≠as (Libraries) y por qu√© son tan importantes?\n\nSi bien hasta este punto no hemos requerido la instalaci√≥n de ning√∫n paquete, ser√°n indispensables a la hora de necesitar funciones y procedimientos que no vengan incluidos en la base de R. Por defecto, R nos proporciona lo suficiente para aprovechar las ventajas de este lenguaje. nos permite realizar operaciones entre objetos de diferente tipo, cargar datos como veremos en el siguiente modulo, realizar consultas de estos y usar una gran cantidad de funciones matem√°ticas y estad√≠sticas. Sin embargo, ya veremos que en ocasiones esto no es suficiente y con el prop√≥sito de realizar operaciones m√°s avanzadas, optimizar procesos al interior del programa o usar repositorios y datos ya consolidados, ser√° de gran utilidad y nos facilitar√° gran parte del trabajo aprender a usar estas dependencias externas.\n\n\n\n\n\n\n\nNote\n\n\n\nEn R los comando para realizar la instalaci√≥n de un determinado paquete, son:\ninstall.packages(‚ÄúBoruta‚Äù) # Esta instalaci√≥n se realiza por √∫nica vez en el software.\nUna vez realizada la instalaci√≥n, cada que queramos utilizar las funciones de este paquete, llamaremos la librer√≠a al inicio del documento o en la secci√≥n anterior a usar alguna de sus funciones, por medio de la siguiente instrucci√≥n:\nlibrary(Boruta) # En cada script que deseemos usar alguna de las funciones de esta librer√≠a.\nUn an√°logo a este procedimiento ser√≠a en python cuando definimos:\npip install tensorflow\nimport tensorflow as tf"
  },
  {
    "objectID": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#tareas-y-repaso",
    "href": "biostats/M√≥dulo 2 - Intro R Studio/mod2_intro_r.html#tareas-y-repaso",
    "title": "M√≥dulo 2: Introducci√≥n a RStudio",
    "section": "üóÇ Tareas y Repaso",
    "text": "üóÇ Tareas y Repaso\n\n\nInstalaci√≥n y Configuraci√≥n de RStudio y R\n\nDescarga ambos programas siguiendo las instrucciones del m√≥dulo\n\nExploraci√≥n de la interfaz y atajos\n\nAbre RStudio y crea un nuevo script. Usa al menos tres atajos de teclado (por ejemplo, Ctrl + Enter para ejecutar una l√≠nea, Ctrl + S para guardar, Alt + - para insertar el operador de asignaci√≥n &lt;-).\nEscribe un comentario en el script explicando qu√© hace cada atajo que usaste. Guarda el script con el nombre exploracion_atajos.R.\n\nOperaciones b√°sicas y tipos de datos\n\nCrea cuatro variables en R que representen diferentes tipos de datos: un n√∫mero entero (integer), un n√∫mero decimal (numeric), una cadena de texto (character) y un valor l√≥gico (logical).\nRealiza una operaci√≥n aritm√©tica con las variables num√©ricas (por ejemplo, suma o multiplicaci√≥n) y una concatenaci√≥n con la variable de texto usando paste().\nUsa la funci√≥n class() para verificar el tipo de dato de cada variable y muestra los resultados en la consola.\n\nEstructuras de datos\n\nCrea un vector con los nombres de cinco frutas y una lista con tres elementos: un n√∫mero, un texto y un vector de n√∫meros (por ejemplo, c(1, 2, 3)).\nAccede al segundo elemento del vector de frutas y al primer elemento de la lista usando la indexaci√≥n (por ejemplo, vector[2] o lista[[1]]).\nImprime ambos resultados en la consola.\n\nUso de una funci√≥n b√°sica y paquetes\n\nInstala el paquete dplyr usando install.packages(\"dplyr\") y c√°rgalo con library(dplyr) .\nCrea un data frame simple con dos columnas: una con nombres de personas (m√≠nimo 3) y otra con sus edades.\n\nGuardar y cargar datos\n\nGuarda el data frame creado en la tarea anterior como un archivo .RData usando la funci√≥n save().\nCierra RStudio, vuelve a abrirlo, y carga el archivo .RData con load().\nEscribe en el script un comentario que indique si el data frame se carg√≥ correctamente (por ejemplo, verificando con print()).\n\n\nEn caso de obtener alg√∫n mensaje de error (warnings) en la consola, verifica a qu√© se pudo deber, invest√≠galo y corr√≠gelo hasta obtener una salida esperada. Recuerda que si no estas seguro de c√≥mo implementar alguna funci√≥n puedes utilizar el comando ?help en la consola para acceder a la ayuda en la que encontrar√°s la documentaci√≥n de paquetes y funciones implementadas en R.\n\n\n\n\n\n\n\nüìö Bibliograf√≠a\n\n\n\n\n\n\nWickham, Hadley; √áetinkaya-Rundel, Mine & Grolemund, Garrett. 2023. R for Data Science, 2nd Edition. O‚ÄôREILLY. https://r4ds.hadley.nz/\nAlonso, Julio C√©sar & Ocampo, Maria Paula. Empezando a usaR: Una gu√≠a paso a paso. Universidad Icesi. https://www.icesi.edu.co/editorial/empezando-usar-web/\n\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biography.html",
    "href": "biography.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "Last updated September 2025"
  },
  {
    "objectID": "biography.html#personal-information",
    "href": "biography.html#personal-information",
    "title": "Curriculum Vitae",
    "section": "Personal Information",
    "text": "Personal Information\n\n\n\nPhone: +57 3208716294\n\nEmail: jmlion@proton.me\n\n\n\nLinkedIn: linkedin.com/in/jmlion\n\nLocation: Bogot√°, D. C., Colombia"
  },
  {
    "objectID": "biography.html#professional-profile",
    "href": "biography.html#professional-profile",
    "title": "Curriculum Vitae",
    "section": "Professional Profile",
    "text": "Professional Profile\n\nFinal-year Statistics student with a focus on sampling, spatio-temporal data analysis, and econometrics. I am passionate about applying statistics as a tool to address complex problems in interdisciplinary contexts, particularly in economic, biological, and social domains. I stand out for my analytical skills, commitment, and intellectual curiosity‚Äîqualities that allow me to combine methodological rigor with an applied perspective, building bridges between statistics and other disciplines, and generating reliable evidence to support strategic decisions grounded in data and context."
  },
  {
    "objectID": "biography.html#skills",
    "href": "biography.html#skills",
    "title": "Curriculum Vitae",
    "section": "Skills",
    "text": "Skills\n\n\n\nStatistical data analysis and modeling\n\nTime series and spatial data analysis\n\nApplied machine learning and Bayesian methods\n\nMultivariate analysis and dimensionality reduction\n\nExperimental design and survey methodology\n\nProgramming in R, SAS, Python, and SQL\n\nData wrangling, integration, and cleaning\n\nReproducible reporting with LaTeX, Quarto, and Markdown\n\n\n\n\nData visualization and storytelling with Power BI, Shiny, and Tableau\n\nVersion control and collaborative work with Git/GitHub\n\nAdvanced use of Microsoft 365 tools\n\nEffective communication and results presentation\n\nTeamwork and collaborative leadership\n\nData ethics and privacy in statistical analysis\n\nLanguages\n\n\nSpanish: Native\n\nEnglish: Advanced\n\nFrench: Beginner"
  },
  {
    "objectID": "biography.html#work-experience",
    "href": "biography.html#work-experience",
    "title": "Curriculum Vitae",
    "section": "Work Experience",
    "text": "Work Experience\n\n\nTeaching Assistant ‚Äì National University of Colombia\nApr 2025 ‚Äì Aug 2025\nSupported teaching in undergraduate courses on Biostatistics, Probability and Fundamental Statistics, assisting students from various disciplines. Developed guide materials to apply course concepts through R programming, reinforcing statistical learning and practice.\nResearch Assistant ‚Äì National University of Colombia ‚Äì Ministry of Education\nOct 2024 ‚Äì Apr 2025\nLed quantitative analysis in a research project funded by the Ministry of Education on student retention, identifying key socioeconomic, academic, and personal factors. Conducted multivariate analyses and survey processing using sampling and inference methods. Prepared reports and presentations to support strategies for improving retention and educational outcomes.\nBilingual Customer Service Representative ‚Äì SharkNinja, Inc.\nNov 2020 ‚Äì Apr 2021\nProvided customer support for international clients, managing service inquiries, troubleshooting technical issues, and offering product guidance. Delivered personalized assistance and supported sales efforts to ensure customer satisfaction and build strong client relationships."
  },
  {
    "objectID": "biography.html#academic-events",
    "href": "biography.html#academic-events",
    "title": "Curriculum Vitae",
    "section": "Academic Events",
    "text": "Academic Events\n\nSpeaker (Oral Presentation) ‚Äì 34th International Symposium on Statistics\nJul 29 ‚Äì Aug 1, 2025, Pasto, Colombia\nLatent structures of the care economy in Colombia: an approach using mixture models and statistical learning.\nSpeaker (Workshop) ‚Äì 38th Latin American Meeting on Mathematics Education\nJul 20 ‚Äì 26, 2025, Bogot√°, Colombia\nMathematical modeling through allometry: strategies for classroom teaching."
  },
  {
    "objectID": "biography.html#educational-background",
    "href": "biography.html#educational-background",
    "title": "Curriculum Vitae",
    "section": "Educational Background",
    "text": "Educational Background\n\nNational University of Colombia ‚Äì Bogot√°, Colombia\nB.Sc. in Statistics (Ongoing)\nInternational Language Academy of Canada ‚Äì Toronto, Canada\nCambridge English Program, 2020\nColegio Colsubsidio Ciudadela ‚Äì Bogot√°, Colombia\nHigh School Diploma, Physics & Mathematics emphasis, 2019\n\n\n\nDownload Printable Version of the Resume"
  },
  {
    "objectID": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html",
    "href": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "",
    "text": "Este programa est√° dirigido a estudiantes de diversas √°reas del conocimiento que est√©n interesados en la aplicaci√≥n de conceptos estad√≠sticos a trav√©s del software RStudio, una de las herramientas m√°s utilizadas a nivel mundial en investigaci√≥n, docencia y an√°lisis de datos. El curso se enfoca en la ense√±anza pr√°ctica de la Estad√≠stica Fundamental, asignatura que conforman la oferta acad√©mica del Departamento de Estad√≠stica en el nivel de pregrado de la Facultad de Ciencias de la Universidad Nacional de Colombia Sede Bogot√°.\nLa propuesta de este curso es brindar al estudiante una gu√≠a pr√°ctica que complemente el aprendizaje te√≥rico recibido en clase. A lo largo de los m√≥dulos se presentar√°n ejemplos, bases de datos y ejercicios que permitir√°n afianzar la comprensi√≥n de los temas y, sobre todo, adquirir destrezas en el uso de R para el an√°lisis estad√≠stico.\nEs importante destacar que este curso tiene un car√°cter acad√©mico complementario y en ning√∫n momento reemplaza ni sustituye las clases programadas por el docente de la asignatura. Ante dudas conceptuales, ser√° indispensable consultar con el profesor encargado, dado que la claridad en los fundamentos te√≥ricos es esencial para llevar a cabo la correcta implementaci√≥n de los procedimientos estad√≠sticos en R.\nSe recomienda avanzar en paralelo con los contenidos de la asignatura, replicando los ejemplos y ejercicios de cada m√≥dulo conforme se desarrollen los temas en clase. De esta manera, al finalizar el curso el estudiante no solo comprender√° los conceptos fundamentales de la estad√≠stica, sino que tambi√©n adquirir√° habilidades pr√°cticas para aplicar estos conocimientos en diferentes contextos acad√©micos y profesionales, desde proyectos de investigaci√≥n hasta an√°lisis de datos en entornos laborales."
  },
  {
    "objectID": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#introducci√≥n",
    "href": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#introducci√≥n",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "",
    "text": "Este programa est√° dirigido a estudiantes de diversas √°reas del conocimiento que est√©n interesados en la aplicaci√≥n de conceptos estad√≠sticos a trav√©s del software RStudio, una de las herramientas m√°s utilizadas a nivel mundial en investigaci√≥n, docencia y an√°lisis de datos. El curso se enfoca en la ense√±anza pr√°ctica de la Estad√≠stica Fundamental, asignatura que conforman la oferta acad√©mica del Departamento de Estad√≠stica en el nivel de pregrado de la Facultad de Ciencias de la Universidad Nacional de Colombia Sede Bogot√°.\nLa propuesta de este curso es brindar al estudiante una gu√≠a pr√°ctica que complemente el aprendizaje te√≥rico recibido en clase. A lo largo de los m√≥dulos se presentar√°n ejemplos, bases de datos y ejercicios que permitir√°n afianzar la comprensi√≥n de los temas y, sobre todo, adquirir destrezas en el uso de R para el an√°lisis estad√≠stico.\nEs importante destacar que este curso tiene un car√°cter acad√©mico complementario y en ning√∫n momento reemplaza ni sustituye las clases programadas por el docente de la asignatura. Ante dudas conceptuales, ser√° indispensable consultar con el profesor encargado, dado que la claridad en los fundamentos te√≥ricos es esencial para llevar a cabo la correcta implementaci√≥n de los procedimientos estad√≠sticos en R.\nSe recomienda avanzar en paralelo con los contenidos de la asignatura, replicando los ejemplos y ejercicios de cada m√≥dulo conforme se desarrollen los temas en clase. De esta manera, al finalizar el curso el estudiante no solo comprender√° los conceptos fundamentales de la estad√≠stica, sino que tambi√©n adquirir√° habilidades pr√°cticas para aplicar estos conocimientos en diferentes contextos acad√©micos y profesionales, desde proyectos de investigaci√≥n hasta an√°lisis de datos en entornos laborales."
  },
  {
    "objectID": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#objetivos",
    "href": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#objetivos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üèÅ Objetivos",
    "text": "üèÅ Objetivos\n\nüèÜ Objetivo General\n\nFortalecer la comprensi√≥n y aplicaci√≥n de los conceptos fundamentales de la estad√≠stica mediante el uso del software RStudio, promoviendo un aprendizaje pr√°ctico y aut√≥nomo que complemente la formaci√≥n te√≥rica de los estudiantes universitarios.\n\n\n\nüéØ Objetivos Especificos\n\n\nFamiliarizar al estudiante con el entorno de R y RStudio como herramienta de an√°lisis estad√≠stico.\nDesarrollar competencias en la importaci√≥n, manipulaci√≥n y organizaci√≥n de bases de datos.\nAplicar m√©todos de an√°lisis descriptivo y exploratorio para la caracterizaci√≥n de datos.\nIntroducir los fundamentos de la probabilidad y su aplicaci√≥n en el an√°lisis estad√≠stico.\nComprender e implementar t√©cnicas b√°sicas de inferencia estad√≠stica en R.\nExplorar modelos de regresi√≥n como herramientas de an√°lisis y predicci√≥n.\nMotivar la aplicaci√≥n de los m√©todos estad√≠sticos en problemas de diversas disciplinas acad√©micas y profesionales."
  },
  {
    "objectID": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#estructura-de-los-m√≥dulos",
    "href": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#estructura-de-los-m√≥dulos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üß± Estructura de los m√≥dulos",
    "text": "üß± Estructura de los m√≥dulos\n\nCada uno de los m√≥dulos est√° dise√±ado bajo una estructura clara y progresiva que busca facilitar la comprensi√≥n y aplicaci√≥n de los contenidos. La organizaci√≥n incluye:\n\nIntroducci√≥n a la Tem√°tica: contextualizaci√≥n del tema, su importancia dentro de la bioestad√≠stica y la justificaci√≥n de su aplicaci√≥n en R.\nObjetivos del M√≥dulo: enunciado de las metas de aprendizaje que el estudiante debe alcanzar al finalizar el trabajo con el m√≥dulo.\nDesarrollo del Contenido: explicaciones detalladas acompa√±adas de ejemplos pr√°cticos en R, anotaciones te√≥ricas de apoyo, consejos t√©cnicos y recomendaciones para el uso eficiente del software.\nActividades de Aplicaci√≥n: ejercicios guiados y aut√≥nomos orientados a la pr√°ctica, que permiten al estudiante comprobar su comprensi√≥n y afianzar el aprendizaje.\nTareas y Repaso: conjunto de actividades de evaluaci√≥n y autoevaluaci√≥n que refuerzan lo aprendido y preparan al estudiante para avanzar al siguiente m√≥dulo."
  },
  {
    "objectID": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#m√≥dulos",
    "href": "biostats/M√≥dulo 1 - Intro al Curso/mod1_curso.html#m√≥dulos",
    "title": "M√≥dulo 1: Bioestad√≠stica Fundamental Aplicada en R",
    "section": "üìö M√≥dulos",
    "text": "üìö M√≥dulos\n\nA continuaci√≥n se presentan los m√≥dulos que conforman el curso Bioestad√≠stica Fundamental Aplicada en R.\n\nüß† M√≥dulo 1: Introducci√≥n al Programa\nüñ•Ô∏è M√≥dulo 2: Introducci√≥n al Software RStudio\nüßÆ M√≥dulo 3: Manipulaci√≥n de Bases de Datos\nüìä M√≥dulo 4: An√°lisis Descriptivo y Exploratorio\nüé≤ M√≥dulo 5: Probabilidad\nüí≠ M√≥dulo 6: Inferencia Estad√≠stica\nüîÆ M√≥dulo 7: M√©todos de Regresi√≥n\n\n\n\n\n\n\n\n\nüöß Acerca de\n\n\n\n\n\nEste proyecto ha sido elaborado por Jos√© Miguel Le√≥n Puentes (Teaching Assistant) durante el primer semestre acad√©mico del a√±o 2025 y se encontrar√° en continua construcci√≥n y supervisi√≥n junto a la Profesora PhD. Lina Ang√©lica Buitrago Reyes.\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "",
    "text": "Ve√≠amos en el m√≥dulo anterior algunas de las diferentes estructuras de datos disponibles en R para almacenar informaci√≥n, como lo son vectores, listas, matrices, data frames y tibbles. A continuaci√≥n, se realiza una breve explicaci√≥n de los diferentes m√©todos y herramientas indispensables a la hora de trabajar con bases de datos en cualquier formato. El prop√≥sito de las siguientes secciones es permitirle conocer diferentes formas de realizar consultas y de comunicarse con los datos, encontrar y resumir informaci√≥n que posteriormente le permitir√° realizar an√°lisis y procedimientos estad√≠sticos m√°s profundos. Este m√≥dulo es introductorio y junto al primer modulo constituyen la base de la autonom√≠a en el lenguaje R."
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#introducci√≥n",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#introducci√≥n",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "",
    "text": "Ve√≠amos en el m√≥dulo anterior algunas de las diferentes estructuras de datos disponibles en R para almacenar informaci√≥n, como lo son vectores, listas, matrices, data frames y tibbles. A continuaci√≥n, se realiza una breve explicaci√≥n de los diferentes m√©todos y herramientas indispensables a la hora de trabajar con bases de datos en cualquier formato. El prop√≥sito de las siguientes secciones es permitirle conocer diferentes formas de realizar consultas y de comunicarse con los datos, encontrar y resumir informaci√≥n que posteriormente le permitir√° realizar an√°lisis y procedimientos estad√≠sticos m√°s profundos. Este m√≥dulo es introductorio y junto al primer modulo constituyen la base de la autonom√≠a en el lenguaje R."
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#objetivos",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#objetivos",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\nRecordar las estructuras de datos disponibles en el software\nEntender como crear una base de datos dentro o fuera de la aplicaci√≥n\nDescubrir las diferentes formas de acceder a bases de datos\nVer las funciones requeridas para importar bases al programa\nMostrar opciones para manipulaci√≥n de bases de datos\nProveer de elementos para la limpieza de bases de datos\nIntroducci√≥n al concepto de imputaci√≥n\nGarantizar la autonom√≠a en el manejo de cualquier base de datos."
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#desarrollo",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#desarrollo",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\n\nüèóÔ∏è Creaci√≥n de Bases de Datos\n\nDebemos tener en cuenta que siempre que se desee almacenar informaci√≥n en formato arreglo, por lo general denotaremos las columnas como aquellos atributos o variables de inter√©s, mientras que las filas en nuestro marco de datos ser√°n los valores para los determinados individuos u objetos a analizar. Las celdas de este arreglo se conocen como las observaciones registradas.\n\n\n\nTomado de: R-Data Frames GeeksforGeeks\n\n\nUna de las maneras mas sencillas para crear una tabla de este estilo en R es de la siguiente manera, creamos un data frame que iremos llenando por columnas o filas, para ello necesitaremos crear internamente o externamente listas, para este caso crearemos la base por columnas y las listas al interior del data frame:\n\nbaseball_df &lt;- data.frame(id = 0:6,\n           name = c(\"Avery Bradley\", \"John Holland\", \"Jonas Jerebko\", \"Jordan Mickey\", \n                    \"Terry Rozier\", \"Jared Sullinger\", \"Evan Turner\"),\n           team = rep(\"Boston Celtics\", 7),\n           number = c(0, 30, 8, NA, 12, 7, 11),\n           position = c(\"PG\", \"SG\", \"PF\", \"PF\", \"PG\", \"C\", \"SG\"),\n           age = c(25, 27, 29, 21, 22, NA, 27))\nbaseball_df\n\n  id            name           team number position age\n1  0   Avery Bradley Boston Celtics      0       PG  25\n2  1    John Holland Boston Celtics     30       SG  27\n3  2   Jonas Jerebko Boston Celtics      8       PF  29\n4  3   Jordan Mickey Boston Celtics     NA       PF  21\n5  4    Terry Rozier Boston Celtics     12       PG  22\n6  5 Jared Sullinger Boston Celtics      7        C  NA\n7  6     Evan Turner Boston Celtics     11       SG  27\n\n\nOtra opci√≥n es crear la base de datos e ir llenando por filas, en esta ocasi√≥n haremos uso del paquete tibble y la funci√≥n tribble que nos permite generar un data frame en formato tibble fila por fila.\n\nlibrary(tibble)\n\ntribble(\n  ~id, ~name,            ~team,            ~number, ~position, ~age,\n  0,   \"Avery Bradley\",   \"Boston Celtics\", 0,      \"PG\",      25,\n  1,   \"John Holland\",    \"Boston Celtics\", 30,     \"SG\",      27,\n  2,   \"Jonas Jerebko\",   \"Boston Celtics\", 8,      \"PF\",      29,\n  3,   \"Jordan Mickey\",   \"Boston Celtics\", NA,     \"PF\",      21,\n  4,   \"Terry Rozier\",    \"Boston Celtics\", 12,     \"PG\",      22,\n  5,   \"Jared Sullinger\", \"Boston Celtics\", 7,      \"C\",       NA,\n  6,   \"Evan Turner\",     \"Boston Celtics\", 11,     \"SG\",      27\n)\n\n# A tibble: 7 √ó 6\n     id name            team           number position   age\n  &lt;dbl&gt; &lt;chr&gt;           &lt;chr&gt;           &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n1     0 Avery Bradley   Boston Celtics      0 PG          25\n2     1 John Holland    Boston Celtics     30 SG          27\n3     2 Jonas Jerebko   Boston Celtics      8 PF          29\n4     3 Jordan Mickey   Boston Celtics     NA PF          21\n5     4 Terry Rozier    Boston Celtics     12 PG          22\n6     5 Jared Sullinger Boston Celtics      7 C           NA\n7     6 Evan Turner     Boston Celtics     11 SG          27\n\n\nLa siguiente base simula un conjunto de 10 parcelas experimentales de quinoa en zonas altoandinas, para ilustrar c√≥mo se integran datos de distintas fuentes (biolog√≠a, clima, suelo y producci√≥n) en un contexto bioestad√≠stico.\n\n\n\nTable¬†1: Base de datos preliminar - Microbioma y rendimiento agr√≠cola\n\n\nlibrary(dplyr)\n\nset.seed(230125)\n\nparcelas &lt;- paste0(\"P\", 1:10)\n\nvariedad_quinoa &lt;- sample(\n  c(\"Blanca Real\", \"Negra Collana\", \"Roja Pasankalla\"),\n  size = 10, replace = TRUE\n)\n\nmicrobioma_richness &lt;- sample(120:250, size = 10, replace = TRUE)\nprecipitacion_mm &lt;- sample(50:200, size = 10, replace = TRUE)\ntemp_media_c &lt;- round(runif(10, min = 8, max = 18), 1)\nmateria_organica_pct &lt;- round(runif(10, min = 1.5, max = 5.0), 2)\nrendimiento_kg_ha &lt;- round(runif(10, min = 1500, max = 3500), 1)\n\ndf_microbioma &lt;- data.frame(\n  Parcela = parcelas,\n  Variedad_Quinoa = variedad_quinoa,\n  Microbioma_Richness = microbioma_richness,\n  Precipitacion_mm = precipitacion_mm,\n  Temp_Media_C = temp_media_c,\n  Materia_Organica_pct = materia_organica_pct,\n  Rendimiento_kg_ha = rendimiento_kg_ha\n)\n\ndf_microbioma\n\n   Parcela Variedad_Quinoa Microbioma_Richness Precipitacion_mm Temp_Media_C\n1       P1     Blanca Real                 150               62          9.2\n2       P2 Roja Pasankalla                 196              193          8.1\n3       P3     Blanca Real                 221               56         16.4\n4       P4     Blanca Real                 230               86         12.2\n5       P5     Blanca Real                 144              153         13.4\n6       P6 Roja Pasankalla                 158               87         10.3\n7       P7 Roja Pasankalla                 202              163         16.0\n8       P8 Roja Pasankalla                 137               84         13.0\n9       P9 Roja Pasankalla                 174              172         16.9\n10     P10 Roja Pasankalla                 236              111          8.3\n   Materia_Organica_pct Rendimiento_kg_ha\n1                  1.82            1526.5\n2                  4.62            3137.0\n3                  4.37            2790.2\n4                  2.91            2692.7\n5                  2.63            2741.2\n6                  4.10            2229.1\n7                  1.97            2918.1\n8                  4.93            3369.9\n9                  2.67            3038.6\n10                 1.74            2389.7\n\n\n\n\n\n\n\n\nTable¬†2: Descripci√≥n de variables - Base Microbioma y Rendimiento Agr√≠cola\n\n\n\n\n\n\n\n\n\n\n\nVariable\nTipo de dato\nDescripci√≥n\n\n\n\n\nParcela\nCateg√≥rica nominal\nIdentificador √∫nico de la parcela experimental (P1 a P10).\n\n\nVariedad_Quinoa\nCateg√≥rica nominal\nVariedad cultivada: Blanca Real, Negra Collana o Roja Pasankalla.\n\n\nMicrobioma_Richness\nNum√©rica entera\nRiqueza de especies microbianas en el suelo (OTUs) obtenidas por secuenciaci√≥n de ADN.\n\n\nPrecipitacion_mm\nNum√©rica entera\nPrecipitaci√≥n acumulada mensual en mil√≠metros durante la etapa de crecimiento principal.\n\n\nTemp_Media_C\nNum√©rica continua\nTemperatura media (¬∞C) en la parcela durante la temporada de cultivo.\n\n\nMateria_Organica_pct\nNum√©rica continua\nPorcentaje de materia org√°nica del suelo determinado mediante an√°lisis de laboratorio.\n\n\nRendimiento_kg_ha\nNum√©rica continua\nProducci√≥n estimada de quinoa en kilogramos por hect√°rea.\n\n\n\n\n\n\n\n\nSin embargo, m√°s all√° de crear una base de datos o un registro de informaci√≥n desde cero, se suele trabajar con bases de datos ya consolidadas. A continuaci√≥n veremos como acceder a estos registros.\n\n\n\nüóùÔ∏è Acceso a Bases de Datos\n\nExisten muchas opciones de cargar un archivo en el que se encuentren los datos. Desde este programa tenemos la posibilidad de descargar directamente de internet, agregar una base de datos que se encuentre en nuestro computador, o incluso utilizar una de las bases de datos que trae incluidas R o acceder a alguna por medio de librer√≠as.\n\n\n\nüóÉÔ∏è Carga de Bases de Datos guardadas en el equipo\nLa siguiente tabla muestra el tipo de archivo, la funci√≥n por medio de la cual podemos acceder a su informaci√≥n:\n\n\n\n\nTable¬†3: Funciones para importar diferentes tipos de archivos en R\n\n\n\n\n\n\nTipo de archivo\nFunci√≥n en R\n\n\n\n\n.txt\nread.table() o readr::read_table()\n\n\n.csv\nread.csv() o readr::read_csv()\n\n\n.csv (punto y coma)\nread.csv2() o readr::read_csv2()\n\n\n.xlsx / .xls\nreadxl::read_excel()\n\n\n.dta\nhaven::read_dta()\n\n\n.sav\nhaven::read_sav()\n\n\n.xpt\nhaven::read_xpt\n\n\n.json\njsonlite::fromJSON()\n\n\n.rds\nreadRDS()\n\n\n.RData\nload()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nPara usar correctamente estas funciones, se debe tener en cuenta la carpeta en la cual est√° el archivo que deseamos cargar en el programa.\nUna vez contemos con la direcci√≥n del directorio de este archivo, podremos incuirla al interior de los corchetes de la funci√≥n.\nComo ejemplo suponga que la ubicaci√≥n del archivo es D:\\Usuario\\Descargas\\HighEstimate_AgPestUsebyCropGroup92to19.txt\nLuego para abrir este documento necesitar√≠amos usar la funci√≥n de base read.table() del siguiente modo:\nlibrary(readr)\ndf_prueba &lt;- read_table(\"D:/Usuario/Descargas/HighEstimate_AgPestUsebyCropGroup92to19.txt\")\nNote que es indispensable cambiar la disposici√≥n de los s√≠mbolos \\ por su direcci√≥n opuesta, es decir, / .\n\n\n\nOtra opci√≥n preferida por muchos usuarios para cargar alg√∫n archivo es mediante la fuente de editor (source editor). Podr√° hacerlo para archivos cuyo tama√±o no supero los 5 MB. Esta operaci√≥n le permitir√° tanto visualizar como importar el archivo de manera autom√°tica con opci√≥n de personalizaci√≥n. Luego, facilita el proceso, sobre todo en escenarios en los que se desconoce el formato en que se encuentran separados los datos ya sea, coma, punto y coma, o espacio.\n\n\n\n‚õèÔ∏è Extraer Datos de Paquetes\n\nLos paquetes de R contiene datasets (base de datos) que se emplean normalmente para mostrar como funciona el paquete. Otros paquetes son bases de datos, como por ejemplo, el paquete gapminder. El paquete gapminder tiene datos para todos los pa√≠ses de poblaci√≥n, pobreza y esperanza de vida entre otras variables.\nUn listado exhaustivo de paquetes que son exclusivamente bases de datos se puede encontrar en el siguiente enlace: The R Datasets Package. Otros paquetes nos brindan una interfaz para descargar datos de entidades como el Banco Mundial a trav√©s del paquete WDI (40 databases hosted by the World Bank, including the World Development Indicators (‚ÄòWDI‚Äô), International Debt Statistics, Doing Business, Human Capital Index, and Sub-national Poverty indicators).\nEl comando data() nos permite ver el listado de las bases de datos disponibles. Sin embargo podemos acceder a los datos de un solo paquete de la siguiente manera:\n\nlibrary(gapminder)\n\nWarning: package 'gapminder' was built under R version 4.4.3\n\ndata(package = 'gapminder')\n\ncon lo cual obtendremos la siguiente salida:\n\n\n\n\nTable¬†4: Objetos incluidos en el paquete Gapminder\n\n\n\n\n\n\nNombre\nDescripci√≥n\n\n\n\n\ncontinent_colors\nGapminder color schemes\n\n\ncountry_codes\nCountry codes\n\n\ncountry_colors\nGapminder color schemes\n\n\ngapminder\nGapminder data\n\n\ngapminder_unfiltered\nGapminder data, unfiltered\n\n\n\n\n\n\n\n\nPosteriormente podremos cargar la base de datos, por medio de la misma funci√≥n:\n\ndata(\"gapminder\")\nforce(gapminder)\n\n# A tibble: 1,704 √ó 6\n   country     continent  year lifeExp      pop gdpPercap\n   &lt;fct&gt;       &lt;fct&gt;     &lt;int&gt;   &lt;dbl&gt;    &lt;int&gt;     &lt;dbl&gt;\n 1 Afghanistan Asia       1952    28.8  8425333      779.\n 2 Afghanistan Asia       1957    30.3  9240934      821.\n 3 Afghanistan Asia       1962    32.0 10267083      853.\n 4 Afghanistan Asia       1967    34.0 11537966      836.\n 5 Afghanistan Asia       1972    36.1 13079460      740.\n 6 Afghanistan Asia       1977    38.4 14880372      786.\n 7 Afghanistan Asia       1982    39.9 12881816      978.\n 8 Afghanistan Asia       1987    40.8 13867957      852.\n 9 Afghanistan Asia       1992    41.7 16317921      649.\n10 Afghanistan Asia       1997    41.8 22227415      635.\n# ‚Ñπ 1,694 more rows\n\n\n\n\n\nüß≠ Funciones y Operaciones\n\nEn esta secci√≥n del modulo se le dar√°n a conocer algunas de las funciones que resultan m√°s √∫tiles e indispensables a la hora de trabajar con bases de datos, desde el momento en que cargamos los datos en el programa y deseamos conocer el estado de dicha informaci√≥n. Veremos funciones para un primer acercamiento, una especie de summary o glimpse. Posteriormente, se desea proveer al estudiante del concepto de datos faltantes y su correspondiente manejo, introduciendo brevemente el concepto de imputaci√≥n. Finalmente, se mostrar√°n situaciones que requieran del uso de funciones para determinados requerimientos en el procesamiento y/o manejo de la informaci√≥n.\n\n\n¬øQu√© hacer cuando ya he cargado la base de datos?\n\nLo primero que debemos hacer una vez hayamos cargado nuestra base de datos es asegurarnos que la informaci√≥n se encuentre correctamente subida y disponible para su tratamiento. Es por ello que, una de las primeras instrucciones sugeridas es visualizar en el programa la base de datos que se ha cargado. Hay dos formas muy f√°ciles de hacerlo, la primera es por medio de la funci√≥n de base View() o haciendo click en la icono de cuadricula que aparece en la parte derecha del nombre del objeto en la secci√≥n Data del Panel Enviroment.\n\nView(df_microbioma)\n\nTambi√©n nos gustar√≠a conocer informaci√≥n como los tipos de estructuras de datos que hemos cargado y las caracter√≠sticas de ellos. Esto lo podemos hacer mediante las siguientes funciones str() de base y glimpse() de la librer√≠a dplyr. Existe otra alternativa por medio del paquete skimr y de la funci√≥n skim().\n\nstr(df_microbioma)\n\n'data.frame':   10 obs. of  7 variables:\n $ Parcela             : chr  \"P1\" \"P2\" \"P3\" \"P4\" ...\n $ Variedad_Quinoa     : chr  \"Blanca Real\" \"Roja Pasankalla\" \"Blanca Real\" \"Blanca Real\" ...\n $ Microbioma_Richness : int  150 196 221 230 144 158 202 137 174 236\n $ Precipitacion_mm    : int  62 193 56 86 153 87 163 84 172 111\n $ Temp_Media_C        : num  9.2 8.1 16.4 12.2 13.4 10.3 16 13 16.9 8.3\n $ Materia_Organica_pct: num  1.82 4.62 4.37 2.91 2.63 4.1 1.97 4.93 2.67 1.74\n $ Rendimiento_kg_ha   : num  1526 3137 2790 2693 2741 ...\n\nglimpse(df_microbioma)\n\nRows: 10\nColumns: 7\n$ Parcela              &lt;chr&gt; \"P1\", \"P2\", \"P3\", \"P4\", \"P5\", \"P6\", \"P7\", \"P8\", \"‚Ä¶\n$ Variedad_Quinoa      &lt;chr&gt; \"Blanca Real\", \"Roja Pasankalla\", \"Blanca Real\", ‚Ä¶\n$ Microbioma_Richness  &lt;int&gt; 150, 196, 221, 230, 144, 158, 202, 137, 174, 236\n$ Precipitacion_mm     &lt;int&gt; 62, 193, 56, 86, 153, 87, 163, 84, 172, 111\n$ Temp_Media_C         &lt;dbl&gt; 9.2, 8.1, 16.4, 12.2, 13.4, 10.3, 16.0, 13.0, 16.‚Ä¶\n$ Materia_Organica_pct &lt;dbl&gt; 1.82, 4.62, 4.37, 2.91, 2.63, 4.10, 1.97, 4.93, 2‚Ä¶\n$ Rendimiento_kg_ha    &lt;dbl&gt; 1526.5, 3137.0, 2790.2, 2692.7, 2741.2, 2229.1, 2‚Ä¶\n\n\nAmbas nos dan pr√°cticamente la misma informaci√≥n, la especificaci√≥n del n√∫mero de filas u observaciones, n√∫mero de columnas o variables, un listado de las variables, el tipo de datos de cada una de las variables y sus valores. Sin embargo, la funci√≥n de base especifica un elemento adicional y es la clase del objeto. Tenga en cuenta que esta informaci√≥n tambi√©n puede ser consultada de manera especifica de la siguiente manera:\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\ndim()\nDa la dimensi√≥n del objeto, n√∫mero de filas y de columnas.\n\n\nlength() o ncol()\nDa el n√∫mero de columnas del objeto.\n\n\nnrow()\nDa el n√∫mero de filas del objeto\n\n\nnames() o colnames()\nDa los nombres de las columnas\n\n\n\n\nAdem√°s de conocer brevemente c√≥mo est√° compuesta la base, otras caracter√≠sticas que podemos obtener de los datos con la funci√≥n de base summary() es, para las variables que reciben entradas num√©ricas, se resumir√° la informaci√≥n de los cuantiles por variable as√≠ como la media de los datos. Esto se explicar√° m√°s a fondo en el siguiente m√≥dulo de estad√≠stica descriptiva exploratoria.\nEn caso de querer cambiar los nombres que reciben nuestras variables, esto lo podemos hacer por medio de la misma funci√≥n de base colnames() de la siguiente manera:\n\ncolnames(df_microbioma)\n\n[1] \"Parcela\"              \"Variedad_Quinoa\"      \"Microbioma_Richness\" \n[4] \"Precipitacion_mm\"     \"Temp_Media_C\"         \"Materia_Organica_pct\"\n[7] \"Rendimiento_kg_ha\"   \n\ncolnames(df_microbioma) &lt;- c(\"ID\", \"Variedad\", \"Riqueza\", \"Precipitaci√≥n\", \"Temperatura\", \"Materia_Org√°nica\", \"Rendimiento\")\n\nEl paquete stringr proporciona un conjunto coherente y consistente de funciones para trabajar y manipular cadenas (vectores de caracteres). Tiene como objetivo simplificar las operaciones comunes con cadenas, haci√©ndolas m√°s intuitivas y f√°ciles de usar\n\nOperaciones comunes con cadenas:\nProporciona funciones para una amplia gama de tareas, entre las que se incluyen:\n\nDetecci√≥n: str_detect(), str_starts(), str_ends()\nExtracci√≥n: str_sub(), str_extract(), str_match()\nSustituci√≥n: str_replace(), str_replace_all()\nManipulaci√≥n: str_to_lower(), str_to_upper(), str_trim(), str_pad(), str_squish()\nDivisi√≥n y uni√≥n: str_split(), str_c()\n\n\n\nlibrary(stringr)\ncolnames(diccionario_limpio) &lt;- str_trim(colnames(diccionario_limpio))\ncolnames(diccionario_limpio) &lt;- str_replace_all(colnames(diccionario_limpio), \"\\\\s+\", \"_\")\ncolnames(diccionario_limpio) &lt;- tolower(colnames(diccionario_limpio))\ndiccionario_limpio &lt;- diccionario_limpio %&gt;%\n  mutate(variable = tolower(str_trim(variable)))\n\nLa funci√≥n rename() se utiliza para cambiar de nombre a las columnas, por ejemplo:\n\nlibrary(palmerpenguins)\n\nWarning: package 'palmerpenguins' was built under R version 4.4.3\n\ndata(package = 'palmerpenguins')\npenguins &lt;- penguins\npenguins %&gt;% rename(isla = island)\n\n# A tibble: 344 √ó 8\n   species isla      bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           NA            NA                  NA          NA\n 5 Adelie  Torgersen           36.7          19.3               193        3450\n 6 Adelie  Torgersen           39.3          20.6               190        3650\n 7 Adelie  Torgersen           38.9          17.8               181        3625\n 8 Adelie  Torgersen           39.2          19.6               195        4675\n 9 Adelie  Torgersen           34.1          18.1               193        3475\n10 Adelie  Torgersen           42            20.2               190        4250\n# ‚Ñπ 334 more rows\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nAdem√°s de modificar el nombre de nuestras columnas, podremos agregarle atributos a nuestra base de datos para volverla m√°s clara a√±adi√©ndole una breve descripci√≥n a cada variable que deseemos.\n\n\nattr(df_microbioma$ID, \"label\") &lt;- \"Identificador √∫nico de la parcela experimental\"\nattr(df_microbioma$Variedad, \"label\") &lt;- \"Variedad cultivada: Blanca Real, Negra Collana o Roja Pasankalla\"\nattr(df_microbioma$Riqueza, \"label\") &lt;- \"Riqueza de especies microbianas en el suelo (OTUs) obtenidas por secuenciaci√≥n de ADN\"\nattr(df_microbioma$Precipitaci√≥n, \"label\") &lt;- \"Precipitaci√≥n acumulada mensual en mil√≠metros durante la etapa de crecimiento principal\"\nattr(df_microbioma$Temperatura, \"label\") &lt;- \"Temperatura media (¬∞C) en la parcela durante la temporada de cultivo\"\nattr(df_microbioma$Materia_Org√°nica, \"label\") &lt;- \"Porcentaje de materia org√°nica del suelo determinado mediante an√°lisis de laboratorio\"\nattr(df_microbioma$Rendimiento, \"label\") &lt;- \"Producci√≥n estimada de quinoa en kilogramos por hect√°rea\"\n\n\ndata2020$p6210 &lt;- factor(data2020$p6210, levels = 1:12, ordered = TRUE)  # Educaci√≥n (ordinal)\n\ndata2020$p6100 &lt;- factor(data2020$p6100, levels = 1:3, ordered = FALSE)  # R√©gimen de salud (nominal)\n\n\n\nVerificaci√≥n y manejo de datos faltantes (NA‚Äôs)\n\nLa funci√≥n summary nos proporciona tambi√©n la cantidad de NA¬¥s por variable en caso de haberlas. Sin embargo existen otras alternativas para revisar datos faltantes en bases. Una opci√≥n es haciendo uso del comando table(is.na(df)) el cual contabiliza el total de datos NA los cuales ser√°n mostrados como TRUE y el total de valores con alg√∫n valor como entrada que se denominar√°n FALSE. Otra opci√≥n si se cuenta con una base de datos muy grande es revisar solo las variables de inter√©s para ello especificamos en el comando table(is.na(df$varible)). Vea el siguiente ejemplo:\n\n\n\nsummary(baseball_df)\n\n       id          name               team               number     \n Min.   :0.0   Length:7           Length:7           Min.   : 0.00  \n 1st Qu.:1.5   Class :character   Class :character   1st Qu.: 7.25  \n Median :3.0   Mode  :character   Mode  :character   Median : 9.50  \n Mean   :3.0                                         Mean   :11.33  \n 3rd Qu.:4.5                                         3rd Qu.:11.75  \n Max.   :6.0                                         Max.   :30.00  \n                                                     NA's   :1      \n   position              age       \n Length:7           Min.   :21.00  \n Class :character   1st Qu.:22.75  \n Mode  :character   Median :26.00  \n                    Mean   :25.17  \n                    3rd Qu.:27.00  \n                    Max.   :29.00  \n                    NA's   :1      \n\ntable(is.na(baseball_df))\n\n\nFALSE  TRUE \n   40     2 \n\ntable(is.na(baseball_df$number))\n\n\nFALSE  TRUE \n    6     1 \n\ntable(is.na(baseball_df$age))\n\n\nFALSE  TRUE \n    6     1 \n\n\nEn caso de querer identificar variables con valores perdidos\n\ncolnames(df)[colSums(is.na(df)) &gt; 0] # ¬øQu√© variables tienen al menos un NA?\ncolSums(is.na(df)) %&gt;% .[. &gt; 0] # Las que tienen NA's, ¬øCu√°ntas tienen?\n\nUna funci√≥n que nos permite ver la proporci√≥n de datos faltantes en nuestra base de datos es:\n\nlibrary(tidyr)\nproporcion_faltantes &lt;- function(df) {\n  df %&gt;%\n    summarise(across(everything(), ~ sum(is.na(.)) / n())) %&gt;%\n    pivot_longer(everything(), names_to = \"variable\", values_to = \"proporcion_faltantes\") %&gt;%\n    mutate(porcentaje_faltantes = proporcion_faltantes * 100) %&gt;%\n    arrange(desc(porcentaje_faltantes))\n}\n\nprint(proporcion_faltantes(database_ex))\n\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\n\n\n\n\ndrop_na()\nelimina filas con valores perdidos.\n\n\nreplace_na()\nreemplaza valores faltantes por un valor definido.\n\n\nfill()\npropaga valores conocidos hacia adelante o hacia atr√°s.\n\n\n\nEjemplos de uso de las anteriores funciones:\n\ndf_cleaned &lt;- drop_na(df_microbioma)\n\ndf_replaced &lt;- df_microbioma %&gt;% mutate(Riqueza = replace_na(Riqueza, 0))\n\ndf_filled &lt;- df_microbioma %&gt;% fill(Variedad, .direction = \"down\")\n\nAhora suponga que dado un listado de variables que contienen NA‚Äôs desea eliminar aquellos elementos.\n\n# Variables con NA's \nvariables_a_revisar &lt;- c(\"estu_cod_depto_presentacion\",   \"punt_ingles\",\n  \"estu_cod_mcpio_presentacion\",   \"estu_cod_reside_depto\",        \n  \"estu_cod_reside_mcpio\",         \"estu_dedicacioninternet\",      \n  \"estu_dedicacionlecturadiaria\",  \"estu_depto_presentacion\",      \n  \"estu_depto_reside\",             \"estu_generacione\",             \n  \"estu_genero\",                   \"estu_horassemanatrabaja\",      \n  \"estu_inse_individual\",          \"estu_mcpio_presentacion\",      \n  \"estu_mcpio_reside\",             \"estu_nse_establecimiento\",     \n  \"estu_nse_individual\",           \"estu_repite\",                  \n  \"estu_tieneetnia\",               \"estu_tiporemuneracion\")\n\n# Filtrar quitando NA en esas columnas\ndatos_saber11 &lt;- datos_saber11 %&gt;%\n  filter(if_all(all_of(variables_a_revisar), ~ !is.na(.)))\n\n\n# Eliminar filas con valores perdidos en variables clave\ndf &lt;- df %&gt;%\n  filter(!is.na(variable1), !is.na(variable2))\n\n# Reemplazar NA en ciertas columnas por 0 (si aplica)\ndf &lt;- df %&gt;%\n  mutate(across(starts_with(\"tiempo_\"), ~replace_na(.x, 0)))\n\n\n\nLimpieza de la base de datos\n\nEl paquete janitor es √∫til para es estandarizar nombres de variables:\n\nlibrary(janitor)\n\nWarning: package 'janitor' was built under R version 4.4.3\n\n\n\nAdjuntando el paquete: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ncolnames(df_microbioma)\n\n[1] \"ID\"               \"Variedad\"         \"Riqueza\"          \"Precipitaci√≥n\"   \n[5] \"Temperatura\"      \"Materia_Org√°nica\" \"Rendimiento\"     \n\ndf_microbioma &lt;- clean_names(df_microbioma)\ncolnames(df_microbioma)\n\n[1] \"id\"               \"variedad\"         \"riqueza\"          \"precipitacion\"   \n[5] \"temperatura\"      \"materia_organica\" \"rendimiento\"     \n\n\nEn caso de trabajar con datos en formato de fechas y/o horas, un paquete que facilita este manejo, simplificando el an√°lisis y las operaciones es lubridate\n\n\nlibrary(\"lubridate\")\n\nWarning: package 'lubridate' was built under R version 4.4.2\n\n\n\nAdjuntando el paquete: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\ndate()\n\n[1] \"Sun Oct 26 08:41:19 2025\"\n\nnow()\n\n[1] \"2025-10-26 08:41:19 -05\"\n\nymd(\"20190317\")\n\n[1] \"2019-03-17\"\n\nmdy(\"03-17-2019\")\n\n[1] \"2019-03-17\"\n\ndmy(\"17/03/2019\")\n\n[1] \"2019-03-17\"\n\nymd(\"20190317\") + years(1:3)\n\n[1] \"2020-03-17\" \"2021-03-17\" \"2022-03-17\"\n\nymd(\"20190317\") + months(0:6)\n\n[1] \"2019-03-17\" \"2019-04-17\" \"2019-05-17\" \"2019-06-17\" \"2019-07-17\"\n[6] \"2019-08-17\" \"2019-09-17\"\n\n\n\n\nOperaciones entre bases de datos\n\nAlgunas funciones √∫tiles que son comunes para combinar distintas fuentes de informaci√≥n, son:\n\n\nUnir bases\n\nCuando tenemos dos bases de datos con una columna en com√∫n (llamada clave o key), podemos combinarlas de distintas formas seg√∫n la informaci√≥n que deseemos conservar.\n\n\n\n\nTomada de: Ciencia de Datos para Ciencias Naturales\n\n\n\n\n\n\n\n\n\n\nFunci√≥n\nDescripci√≥n\nEsquema de conservaci√≥n\n\n\n\n\nleft_join()\nMantiene todas las filas de la base de la izquierda. Si no hay coincidencia en la derecha, completa con NA.\n‚ÄúConservo todo lo de la izquierda, complemento con lo de la derecha si existe.‚Äù\n\n\nright_join()\nMantiene todas las filas de la base de la derecha. Si no hay coincidencia en la izquierda, completa con NA.\n‚ÄúConservo todo lo de la derecha, complemento con lo de la izquierda si existe.‚Äù\n\n\ninner_join()\nMantiene solo las filas coincidentes en ambas bases (la intersecci√≥n).\n‚ÄúMe quedo √∫nicamente con lo que coincide en ambas bases.‚Äù\n\n\nfull_join()\nMantiene todas las filas de ambas bases. Si alguna no tiene coincidencia, completa con NA.\n‚ÄúMe quedo con todo, tanto de la izquierda como de la derecha.‚Äù\n\n\n\n\n# Dos bases peque√±as de ejemplo\ndf1 &lt;- data.frame(ID = c(1,2,3), Var1 = c(\"A\",\"B\",\"C\"))\ndf2 &lt;- data.frame(ID = c(2,3,4), Var2 = c(\"X\",\"Y\",\"Z\"))\ndf3 &lt;- data.frame(ID = c(5,6,7), Var1 = c(\"B\",\"A\",\"A\"))\n\nleft_join(df1, df2, by = \"ID\")   # conserva todos los ID de df1\n\n  ID Var1 Var2\n1  1    A &lt;NA&gt;\n2  2    B    X\n3  3    C    Y\n\nright_join(df1, df2, by = \"ID\")  # conserva todos los ID de df2\n\n  ID Var1 Var2\n1  2    B    X\n2  3    C    Y\n3  4 &lt;NA&gt;    Z\n\ninner_join(df1, df2, by = \"ID\")  # conserva solo los ID que coinciden (2 y 3)\n\n  ID Var1 Var2\n1  2    B    X\n2  3    C    Y\n\nfull_join(df1, df2, by = \"ID\")   # conserva todos los ID de ambos (1,2,3,4)\n\n  ID Var1 Var2\n1  1    A &lt;NA&gt;\n2  2    B    X\n3  3    C    Y\n4  4 &lt;NA&gt;    Z\n\n\n\nbind_rows(df1, df3)   # Apilar filas\n\n  ID Var1\n1  1    A\n2  2    B\n3  3    C\n4  5    B\n5  6    A\n6  7    A\n\nrbind(df1, df3)\n\n  ID Var1\n1  1    A\n2  2    B\n3  3    C\n4  5    B\n5  6    A\n6  7    A\n\nbind_cols(df1, df2)   # Combinar columnas\n\nNew names:\n‚Ä¢ `ID` -&gt; `ID...1`\n‚Ä¢ `ID` -&gt; `ID...3`\n\n\n  ID...1 Var1 ID...3 Var2\n1      1    A      2    X\n2      2    B      3    Y\n3      3    C      4    Z\n\ncbind(df1,df2)\n\n  ID Var1 ID Var2\n1  1    A  2    X\n2  2    B  3    Y\n3  3    C  4    Z\n\n\n\n\n\nManipulaci√≥n de Data Frames\n\nOrdenar\n\ndf &lt;- arrange(df, Variedad)                 # Orden ascendente\ndf &lt;- arrange(df, desc(Rendimiento))        # Orden descendente\n\nPara escoger los individuos que presentaron los cinco valores m√°s altos de una variables se podr√≠a hacer los siguiente:\n\npenguins %&gt;%  \n  arrange(desc(bill_length_mm)) %&gt;% \n  top_n(n=5, wt=bill_length_mm)\n\n# A tibble: 5 √ó 8\n  species   island bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n1 Gentoo    Biscoe           59.6          17                 230        6050\n2 Chinstrap Dream            58            17.8               181        3700\n3 Gentoo    Biscoe           55.9          17                 228        5600\n4 Chinstrap Dream            55.8          19.8               207        4000\n5 Gentoo    Biscoe           55.1          16                 230        5850\n# ‚Ñπ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nSe puede cambiar la localizaci√≥n de las columnas con la funci√≥n relocate() y los par√°metros .before y .after\n\npenguins %&gt;%  relocate(year, .after = species)\n\n# A tibble: 344 √ó 8\n   species  year island    bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;fct&gt;   &lt;int&gt; &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n 1 Adelie   2007 Torgersen           39.1          18.7               181\n 2 Adelie   2007 Torgersen           39.5          17.4               186\n 3 Adelie   2007 Torgersen           40.3          18                 195\n 4 Adelie   2007 Torgersen           NA            NA                  NA\n 5 Adelie   2007 Torgersen           36.7          19.3               193\n 6 Adelie   2007 Torgersen           39.3          20.6               190\n 7 Adelie   2007 Torgersen           38.9          17.8               181\n 8 Adelie   2007 Torgersen           39.2          19.6               195\n 9 Adelie   2007 Torgersen           34.1          18.1               193\n10 Adelie   2007 Torgersen           42            20.2               190\n# ‚Ñπ 334 more rows\n# ‚Ñπ 2 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;\n\n\n\nLos datos a lo ancho tienen una columna para cada variable y una fila para cada observaci√≥n. Los datos a menudo se ingresan y almacenan de esta manera. Los datos ordenados a lo largo, por otro lado, tienen una columna que indica el tipo de variable contenida en esa fila y luego, en una columna separada, el valor de esa variable.\n\n\n\n\nTomada de: R for Excel Users Julie Lowndes & Allison Horst\n\n\n\nlibrary(tidyr)\ndata(\"airquality\")\nhead(airquality)\n\n  Ozone Solar.R Wind Temp Month Day\n1    41     190  7.4   67     5   1\n2    36     118  8.0   72     5   2\n3    12     149 12.6   74     5   3\n4    18     313 11.5   62     5   4\n5    NA      NA 14.3   56     5   5\n6    28      NA 14.9   66     5   6\n\nlargo &lt;- airquality %&gt;%\n  pivot_longer(c(Ozone, Solar.R, Wind, Temp), \n                 names_to = \"variable\", values_to = \"value\")\nlargo\n\n# A tibble: 612 √ó 4\n   Month   Day variable value\n   &lt;int&gt; &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     5     1 Ozone     41  \n 2     5     1 Solar.R  190  \n 3     5     1 Wind       7.4\n 4     5     1 Temp      67  \n 5     5     2 Ozone     36  \n 6     5     2 Solar.R  118  \n 7     5     2 Wind       8  \n 8     5     2 Temp      72  \n 9     5     3 Ozone     12  \n10     5     3 Solar.R  149  \n# ‚Ñπ 602 more rows\n\nancho &lt;- largo %&gt;%\n  pivot_wider(names_from = \"variable\", \n              values_from = \"value\")\nancho\n\n# A tibble: 153 √ó 6\n   Month   Day Ozone Solar.R  Wind  Temp\n   &lt;int&gt; &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     5     1    41     190   7.4    67\n 2     5     2    36     118   8      72\n 3     5     3    12     149  12.6    74\n 4     5     4    18     313  11.5    62\n 5     5     5    NA      NA  14.3    56\n 6     5     6    28      NA  14.9    66\n 7     5     7    23     299   8.6    65\n 8     5     8    19      99  13.8    59\n 9     5     9     8      19  20.1    61\n10     5    10    NA     194   8.6    69\n# ‚Ñπ 143 more rows\n\n\n\n\nTransformar\n\ntransform(airquality, Ozone = -Ozone)\ntransform(airquality, new = -Ozone, Temp = (Temp-32)/1.8)\n\n\n\nSelecci√≥n de variables y creaci√≥n de subconjuntos\n\nsubset(airquality, Temp &gt; 80, select = c(Ozone, Temp))\nsubset(airquality, Day == 1, select = -Temp)\nsubset(airquality, select = Ozone:Wind)\n\nwith(airquality, subset(Ozone, Temp &gt; 80))\n\n\nx &lt;- 1:12\nm &lt;- matrix(1:6, nrow = 2, dimnames = list(c(\"a\", \"b\"), LETTERS[1:3]))\nli &lt;- list(pi = pi, e = exp(1))\nx[10]                 # the tenth element of x\n\n[1] 10\n\nx &lt;- x[-1]            # delete the 1st element of x\nm[1,]                 # the first row of matrix m\n\nA B C \n1 3 5 \n\nm[1, , drop = FALSE]  # is a 1-row matrix\n\n  A B C\na 1 3 5\n\nm[,1]                 # the fisrt column of matrix m\n\na b \n1 2 \n\nm[,c(TRUE,FALSE,TRUE)]# logical indexing\n\n  A C\na 1 5\nb 2 6\n\nm[cbind(c(1,2,1),3:1)]# matrix numeric index\n\n[1] 5 4 1\n\nci &lt;- cbind(c(\"a\", \"b\", \"a\"), c(\"A\", \"C\", \"B\"))\nm[ci]                 # matrix character index\n\n[1] 1 6 3\n\nm &lt;- m[,-1]           # delete the first column of m\nli[[1]]               # the first element of list li\n\n[1] 3.141593\n\ny &lt;- list(1, 2, a = 4, 5)\ny[c(3, 4)]            # a list containing elements 3 and 4 of y\n\n$a\n[1] 4\n\n[[2]]\n[1] 5\n\ny$a                   # the element of y named a\n\n[1] 4\n\nmitad1 &lt;- penguins[1:172, ] # partici√≥n de la primera mitad\nmitad2 &lt;- penguins[173:344, ] # partici√≥n de la segunda mitad\n\nUna alternativa a la funci√≥n de base es con las rutinas de dplyr de las siguiente manera:\n\ndf_sub &lt;- select(df, ID, Variedad, Rendimiento)\ndf_filtrado &lt;- filter(df, Rendimiento &gt; 2000, Variedad == \"Blanca Real\")\ndf &lt;- filter(df, !is.na(variable))\ndf &lt;- filter(df, variable != \"valor\")\npenguins %&gt;% filter(bill_length_mm &gt;= 50)\npenguins %&gt;% filter(bill_length_mm &gt;= 50 & island == \"Dream\")\npenguins %&gt;% filter(island %in% c(\"Torgersen\",\"Dream\")) # permite seleccionar diferentes items dentro de una columna \npenguins %&gt;% filter(near(x = body_mass_g, y = 3500, tol = 500)) # permite escoger dentro de un rango de valores num√©ricos cercanos, estableciendo un valor de tolerancia\npenguins %&gt;% filter(between(bill_length_mm, left = 43, right = 46)) # permite escoger un rango de valores num√©ricos dentro de un l√≠mite espec√≠fico\n\nslice(df, 10:15) # selecciona filas por posici√≥n\n\n\n\nOperaciones entre columnas (Mutate)\nPermite crear nuevas variables y realizar operaciones matem√°ticas entre ellas\n\npenguins %&gt;% mutate(mass_kg = body_mass_g / 1000, .before=bill_length_mm)\ndf &lt;- df %&gt;% mutate(Rendimiento_ajustado = Rendimiento / Precipitaci√≥n)\ndf$suma &lt;- rowSums(df[, c(\"Riqueza\", \"Materia_Org√°nica\")], na.rm = TRUE)\n\n\nSe utiliza la funci√≥n transmute() cuando se quiere generar y mostrar solamente la columna resultante de una operaci√≥n matem√°tica entre variables\n\npenguins %&gt;% \n  transmute(bill_ratio = bill_length_mm/bill_depth_mm)\n\nAdem√°s, con la inclusi√≥n del par√°metro if_else se pueden definir categor√≠as arbitrarias de clasificaci√≥n dentro de variables num√©ricas. Esta funci√≥n literalmente se leer√≠a como ‚Äúsi cumple con la siguiente caracter√≠stica lo clasifica como tal cosa, sino, como tal otra cosa‚Äù.\n\npenguins %&gt;% \n  drop_na() %&gt;% \n  mutate(size = if_else(body_mass_g&gt;4000,\"BIG\",\"SMALL\")) %&gt;% \n  count(size)\n\nLa funci√≥n case_when permite crear nuevas variables a partir de condiciones m√∫ltiples, similar a una sentencia if_else anidada o a la instrucci√≥n CASE WHEN en SQL.\n\n\npacientes &lt;- data.frame(ID = 1:5, IMC = c(18, 22, 27, 31, 35))\n\npacientes &lt;- pacientes %&gt;%\n  mutate(clasificacion = case_when(\n    IMC &lt; 18.5 ~ \"Bajo peso\",\n    IMC &gt;= 18.5 & IMC &lt; 25 ~ \"Normal\",\n    IMC &gt;= 25 & IMC &lt; 30 ~ \"Sobrepeso\",\n    IMC &gt;= 30 ~ \"Obesidad\"\n  ))\n\n\n\nAgrupamiento\n\nPermite agrupar diferentes variables categ√≥ricas, a partir de las cuales se pueden realizar diferentes operaciones de c√°lculo:\n\ndf %&gt;% group_by(Variedad) %&gt;%\n       summarise(media_rend = mean(Rendimiento, na.rm = TRUE),\n                 sd_rend = sd(Rendimiento, na.rm = TRUE)) %&gt;%\n       arrange(desc(media_rend))\n\nSe pueden realizar agrupaciones y c√°lculos para diferentes variables:\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  summarise(\n    across(\n      .cols = c(where(is.numeric),-year),\n      .fns = ~mean(., na.rm = TRUE)))\n\n# A tibble: 3 √ó 5\n  species   bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n  &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;dbl&gt;       &lt;dbl&gt;\n1 Adelie              38.8          18.3              190.       3701.\n2 Chinstrap           48.8          18.4              196.       3733.\n3 Gentoo              47.5          15.0              217.       5076.\n\n\nSe pueden realizar agrupaciones con dos o m√°s variables categ√≥ricas:\n\npenguins %&gt;% \n  group_by(species,island) %&gt;% \n  summarise(avg_flipper = mean(flipper_length_mm,na.rm=TRUE)) %&gt;% \n  arrange(desc(avg_flipper))\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 √ó 3\n# Groups:   species [3]\n  species   island    avg_flipper\n  &lt;fct&gt;     &lt;fct&gt;           &lt;dbl&gt;\n1 Gentoo    Biscoe           217.\n2 Chinstrap Dream            196.\n3 Adelie    Torgersen        191.\n4 Adelie    Dream            190.\n5 Adelie    Biscoe           189.\n\n\n\n\n\nContar frecuencias\n\nUna forma r√°pida de realizar conteos para una sola variable es:\n\ncount(penguins, year)\n\nPara contar elementos dentro de las variables agrupadas:\n\npenguins %&gt;% \n  group_by(species,island) %&gt;% \n  summarise(n())\n\n`summarise()` has grouped output by 'species'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 5 √ó 3\n# Groups:   species [3]\n  species   island    `n()`\n  &lt;fct&gt;     &lt;fct&gt;     &lt;int&gt;\n1 Adelie    Biscoe       44\n2 Adelie    Dream        56\n3 Adelie    Torgersen    52\n4 Chinstrap Dream        68\n5 Gentoo    Biscoe      124\n\n\nLa funci√≥n distinct() se utiliza para ver los factores dentro de una columna\n\npenguins %&gt;% distinct(year)\n\nLa funci√≥n n_distinct() se utiliza para contar el n√∫mero de factores diferentes dentro de una columna. La funci√≥n pull() para escoger la columna a analizar.\n\n\npenguins %&gt;% pull(year) %&gt;% n_distinct()\n\n\n\nEliminar columnas o filas\n\ndf &lt;- select(df, -Temperatura)   # Eliminar columna\ndf &lt;- filter(df, Rendimiento &gt; 0) # Mantener filas con rendimiento positivo\ndf &lt;- df %&gt;% slice(-1087, -1088) # Se eliminan las filas #1087 y #1088 \npenguins %&gt;% select(contains(\"bill\")) # selecciona columnas que contienen \"bill\"\npenguins %&gt;% select(starts_with(\"kg\"))  # selecciona columnas que empiezan con \"kg\"\npenguins %&gt;% select(ends_with(\"mm\"))  # selecciona columnas que terminan con \"mm\"\npenguins %&gt;% select(year,species,body_mass_g,species) # Selecci√≥n y asignaci√≥n de nuevo orden\npenguins %&gt;% select(where(is.factor), body_mass_g) # Distinguiendo por atributos de columnas\n\n\nSi no existe una funci√≥n apropiada, se puede utilizar la funci√≥n do(), en el siguiente ejemplo se desarrolla la construcci√≥n de modelos lineales:\n\n\npenguins %&gt;% \n  group_by(species) %&gt;% \n  do(mod = lm(body_mass_g ~ bill_length_mm, data = .)) %&gt;% \n       summarise(rsq = summary(mod)$r.squared)\n\n\n\nOperador pipe\n\nEl operador ‚Äútuber√≠a‚Äù (%&gt;%) facilita encadenar operaciones de forma legible, una versi√≥n m√°s actualizada de este operador es |&gt;.\n\ndf %&gt;% \n  filter(Rendimiento &gt; 1000) %&gt;%\n  group_by(Variedad) %&gt;%\n  summarise(n = n())\n\nEn palabras, el anterior c√≥digo lo que nos permite es: a partir de una base de datos, se filtran los individuos que tengan un rendimiento mayor a 1000, para luego agruparlas por el tipo de variedad y contar cuantas parcelas de cada variedad hay cuyo rendimiento sea mayor a 1000. Esta serie de pasos en la solicitud que se realiza se facilita con el operador pipe el cual nos va conectando las solicitudes a partir de otras de manera sucesiva.\n\n\n\nConjunto de herramientas de la rutina purrr\n\nEn el contexto de la programaci√≥n funcional de R, la familia de funciones map() permiten reemplazar muchos ‚Äúfor loops‚Äù con c√≥digo que es m√°s breve y m√°s f√°cil de leer.\nOtras funciones m√°s espec√≠ficas de la familia map() son las siguientes:\n\nmap() - genera una lista\nmap_lgl() - genera vector l√≥gico\nmap_int() - genera vector de enteros\nmap_dbl() - genera vector de doubles\nmap_chr() - genera vector de caracteres\nmap_dfr() - genera un data frame\nmap2() - iteraci√≥n sobre dos conjuntos de datos\npmap() - itera sobre una lista de argumentos\n\nEl uso gen√©rico de la familia de funciones map()es el siguiente:\n\nmap(.x, .f, ...)\nmap(INPUT, FUNCTION_TO_APPLY, OPTIONAL_OTHER_STUFF)\n\nPor ejemplo, suponga que desea calcular la mediana de cada columna de manera iterativa. Con esta librar√≠a se omite la necesidad de requerir loops de funciones. As√≠,\n\nlibrary(purrr)\ndata(iris)\niris2= select(iris,1:4)\nmap_dbl(iris2, median)\n\nSepal.Length  Sepal.Width Petal.Length  Petal.Width \n        5.80         3.00         4.35         1.30 \n\ndata(\"airquality\")\nmap_dbl(airquality, mean, na.rm = TRUE) # devuelve directamente un vector num√©rico.\n\n     Ozone    Solar.R       Wind       Temp      Month        Day \n 42.129310 185.931507   9.957516  77.882353   6.993464  15.803922 \n\n\nSin embargo, el paquete dplyr cuenta con las funciones lapply, sapply y tapply las cuales veremos en que se diferencian a la propuesta de purrr o a la funci√≥n de base apply .\n\napply(X, MARGIN, FUN)\n\nSe usa con matrices o arrays.\nAplica una funci√≥n sobre las filas (MARGIN = 1) o columnas (MARGIN = 2).\nEjemplo: apply(matriz, 1, mean) ‚Üí calcula la media por fila.\n\n\n\n\nlapply(X, FUN)\n\nSe usa con listas o vectores.\nDevuelve siempre una lista de la misma longitud que X.\nFunciona similar a lapply().\nEjemplo: lapply(lista, mean) ‚Üí calcula la media de cada elemento de la lista.\n\n\n\n\nsapply(X, FUN)\n\nVersi√≥n m√°s ‚Äúamigable‚Äù de lapply().\nIntenta simplificar el resultado a un vector o matriz, si es posible.\nEjemplo: sapply(lista, mean) ‚Üí devuelve un vector de medias.\n\n\n\n\ntapply(X, INDEX, FUN)\n\nSe usa con vectores categorizados.\nAplica la funci√≥n por grupos definidos en un factor.\nEjemplo: tapply(ingresos, genero, mean) ‚Üí media de ingresos por g√©nero."
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#caso-de-estudio",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#caso-de-estudio",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "üöÄ Caso de Estudio",
    "text": "üöÄ Caso de Estudio\n\nPara el desarrollo de los siguientes m√≥dulos, se ha pensado en trabajar un caso de estudio por medio del cual analizaremos el uso de pesticidas en cultivos en diferentes estados de EE.UU asoci√°ndolo a datos de salud y nutrici√≥n de adultos en este pa√≠s por medio de los resultados de una encuesta nacional. Este caso de estudio permite realizar un an√°lisis ambiental y epidemiol√≥gico teniendo como eje central permitirnos llevar a cabo la ense√±anza y aplicaci√≥n de los diferentes m√≥dulos de este curso de manera transversal. Garantizando as√≠, la aplicaci√≥n de las tem√°ticas vistas en el curso a partir de datos reales.\n\nBase 1: Estimated annual agricultural pesticide use by major crop or crop group for states of the conterminous United States 1992-2019 (including preliminary estimates for 2018-19)\nLa primera base de datos utilizada en este caso de estudio contiene estimaciones anuales del uso agr√≠cola de pesticidas en los estados contiguos de Estados Unidos, para el per√≠odo 1992-2019 (incluyendo estimaciones preliminares para 2018 y 2019). Su objetivo es proporcionar informaci√≥n a nivel estatal sobre el uso de compuestos pesticidas seg√∫n el cultivo o grupo de cultivos, con el fin de mejorar la comprensi√≥n sobre en qu√© cultivos se aplican estos compuestos.\nLos datos provienen de estimaciones previamente elaboradas a nivel de condado mediante metodolog√≠as descritas en estudios de referencia (Thelin y Stone, 2013; Baker y Stone, 2015; Wieben, 2019, 2021a, 2021b). Aunque las estimaciones detalladas por cultivo a nivel de condado no se publican debido a la alta incertidumbre, los cultivos de gran extensi√≥n (ma√≠z, soya, trigo, algod√≥n, arroz y alfalfa) se presentan de manera individual a nivel estatal, mientras que los cultivos de menor superficie se agrupan (hortalizas y frutas, huertos y uvas, pastos y heno, y otros cultivos).\nEl conjunto de datos incluye dos tablas de estimaciones anuales estatales de uso agr√≠cola de pesticidas por cultivo o grupo de cultivos: una con estimaciones bajas y otra con estimaciones altas, adem√°s de la informaci√≥n de metadatos asociada. Estos datos han servido para generar series de tiempo anuales por pesticida y cultivo, disponibles en el Pesticide National Synthesis Project.\nLink de acceso a la base: https://www.sciencebase.gov/catalog/item/6081ae7cd34e8564d6866222\nDescargar la base de datos\nNombre de la base de datos a trabajar: HighEstimate_AgPestUsebyCropGroup92to19\nFormato: .txt\nPropietario de los datos: National Water Quality Program\nResponsable de la elaboraci√≥n: Christine M. Wieben\nEditor: U.S. Geological Survey\nDistribuidor: U.S. Geological Survey ‚Äì ScienceBase\nReferencia: Wieben, C.M., 2021, Estimated annual agricultural pesticide use by major crop or crop group for states of the conterminous United States, 1992-2019 (including preliminary estimates for 2018-19): U.S. Geological Survey, https://doi.org/10.5066/P900FZ6Y.\n\n\n\nlibrary(readr)\npesticide_use &lt;- read_table(\"HighEstimate_AgPestUsebyCropGroup92to19.txt\")\n\n\nBase 2: National Health and Nutrition Examination Survey 2017-March 2020 Pre-pandemic\n\nLa Encuesta Nacional de Examen de Salud y Nutrici√≥n (NHANES) es una encuesta √∫nica en EE. UU. que combina entrevistas presenciales con ex√°menes f√≠sicos estandarizados y pruebas de laboratorio. Desde 1999, se realiza de manera continua con datos representativos a nivel nacional publicados cada dos a√±os. Sin embargo, en marzo de 2020, la pandemia de COVID-19 interrumpi√≥ la recolecci√≥n de datos del ciclo 2019‚Äì2020, lo que impidi√≥ que esa muestra fuera representativa a nivel nacional.\nComo soluci√≥n, los datos parciales de 2019‚Äìmarzo de 2020 se combinaron con los datos completos del ciclo anterior (2017‚Äì2018), creando as√≠ un conjunto de datos llamado NHANES 2017‚Äìmarzo de 2020 prepandemia, que s√≠ permite generar estimaciones representativas para la poblaci√≥n civil no institucionalizada de EE. UU.\nAlrededor de 5,000 personas son seleccionadas mediante un proceso cient√≠fico aleatorio para asegurar que los resultados representen con precisi√≥n la salud y el estado nutricional de toda la diversa naci√≥n estadounidense.\nPara mayor informaci√≥n consultar la p√°gina oficial de National Health Statistics Reports No.¬†158\nLink de acceso a la base: https://wwwn.cdc.gov/nchs/nhanes/continuousnhanes/default.aspx?Cycle=2017-2020\nProgram director: Dr.¬†Alan Simon\nContent source: CDC/National Center for Health Statistics\nLas secciones a considerar de esta encuesta son:\n\nDemographics Data Link\nDietary Data Link\nExamination Data Link\nLaboratory Data Link\nQuestionnaire Data Link\n\nPara cada base se seleccionar√°n exclusivamente variables que sean √∫tiles para el caso de estudio, ya sea por creencia de relaci√≥n entre estas o debido a los registros de la literatura.\nDemographic Data\nDemographic Variables and Sample Weights : P_DEMO.xpt\n\nlibrary(haven)\n\nWarning: package 'haven' was built under R version 4.4.3\n\ndemographic_variables &lt;- read_xpt(\"P_DEMO.xpt\")\n\nDietary Data\nDietary Interview - Total Nutrient Intakes, First Day : P_DR1TOT.xpt\nDietary Interview - Total Nutrient Intakes, Second Day : P_DR2TOT.xpt\nDietary Supplement Use 30-Day - Total Dietary Supplements : P_DSQTOT.xpt\n\nnutrient_intakes_d1 &lt;- read_xpt(\"P_DR1TOT.xpt\")\nnutrient_intakes_d2 &lt;- read_xpt(\"P_DR2TOT.xpt\")\ndietary_supplements &lt;- read_xpt(\"P_DSQTOT.xpt\")\n\nExamination Data\nBlood Pressure - Oscillometric Measurement : P_BPXO.xpt\nBody Measures : P_BMX.xpt\nOral Health - Dentition : P_OHXDEN.xpt\n\nblood_pressure &lt;- read_xpt(\"P_BPXO.xpt\")\nbody_measures  &lt;- read_xpt(\"P_BMX.xpt\")\noral_health    &lt;- read_xpt(\"P_OHXDEN.xpt\")\n\nLaboratory Data\nOrganophosphate Insecticides - Dialkyl Phosphate Metabolites - Urine : P_OPD.xpt\nLead, Cadmium, Total Mercury, Selenium, & Manganese - Blood : P_PBCD.xpt\nGlycohemoglobin : P_GHB.xpt\nHigh-Sensitivity C-Reactive Protein : P_HSCRP.xpt\nPlasma Fasting Glucose : P_GLU.xpt\nComplete Blood Count with 5-Part Differential in Whole Blood : P_CBC.xpt\n\norganophosphate_insecticides &lt;- read_xpt(\"P_OPD.xpt\")\ntoxic_heavy_metals &lt;- read_xpt(\"P_PBCD.xpt\")\nHbA1c &lt;- read_xpt(\"P_GHB.xpt\")\nhs_CRP &lt;- read_xpt(\"P_HSCRP.xpt\")\nfasting_plasma_glucose &lt;- read_xpt(\"P_GLU.xpt\")\ncomplete_blood_count &lt;- read_xpt(\"P_CBC.xpt\")\n\nQuestionnaire Data\nPesticide Use : P_PUQMEC.xpt\nOccupation : P_OCQ.xpt\nVolatile Toxicant : P_VTQ.xpt\nMedical Conditions : P_MCQ.xpt\nAlcohol Use : P_ALQ.xpt\nSmoking - Cigarette Use : P_SMQ.xpt\nSmoking - Recent Tobacco Use : P_SMQRTU.xpt\nPhysical Activity : P_PAQ.xpt\nDiet Behavior & Nutrition : P_DBQ.xpt\nDermatology : P_DEQ.xpt\n\npesticide_use &lt;- read_xpt(\"P_PUQMEC.xpt\")         \noccupation &lt;- read_xpt(\"P_OCQ.xpt\")                \nvolatile_toxicant &lt;- read_xpt(\"P_VTQ.xpt\")         \nmedical_conditions &lt;- read_xpt(\"P_MCQ.xpt\")        \nalcohol_use &lt;- read_xpt(\"P_ALQ.xpt\")               \nsmoking_cigarette &lt;- read_xpt(\"P_SMQ.xpt\")         \nsmoking_recent_tobacco &lt;- read_xpt(\"P_SMQRTU.xpt\") \nphysical_activity &lt;- read_xpt(\"P_PAQ.xpt\")         \ndiet_behavior &lt;- read_xpt(\"P_DBQ.xpt\")             \ndermatology &lt;- read_xpt(\"P_DEQ.xpt\")              \n\nBasado en literatura sobre pesticidas, se considera priorizar las siguientes enfermedades:\n\nTrastornos neurol√≥gicos: Parkinson, neuropat√≠as.\nDiabetes/Obesidad: Disruptores endocrinos.\nC√°ncer: Linfoma, leucemia.\nProblemas respiratorios: Asma."
  },
  {
    "objectID": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#tarea-y-repaso",
    "href": "biostats/M√≥dulo 3 - Manejo Bases/mod3_bases.html#tarea-y-repaso",
    "title": "M√≥dulo 3: Manipulaci√≥n de Bases de Datos",
    "section": "üóÇÔ∏è Tarea y Repaso",
    "text": "üóÇÔ∏è Tarea y Repaso\n\n\nFamiliarizarse con paquetes y funciones necesarias\n\nDescarga los paquetes mencionados en el modulo que te permitan cargar archivos de diferentes extensiones en el programa, algunos de estos programas necesarios ser√°n: haven, readr, readxl, entre otros.\nInvestiga cual es la diferencia entre las funciones de base y de algunos paquetes como por ejemplo: read.table() y read_table(), read.csv() y read_csv(), bind_cols() y cbind(). Concluye si algunas son mejores en algunos escenarios o cu√°l preferir√≠as usar en un entorno de trabajo m√°s √≥ptimo.\nCrea una base de datos con informaci√≥n de f√°cil acceso en Excel y posteriormente abre esta base de datos desde el software de RStudio. Luego intenta hacer la misma base de datos directamente program√°ndola con c√≥digo R.\n\n\nEn caso de obtener alg√∫n mensaje de error (warnings) en la consola, verifica a qu√© se pudo deber, invest√≠galo y corr√≠gelo hasta obtener una salida esperada. Recuerda que si no estas seguro de c√≥mo implementar alguna funci√≥n puedes utilizar el comando ?help en la consola para acceder a la ayuda en la que encontrar√°s la documentaci√≥n de paquetes y funciones implementadas en R.\n\n\n\n\n\n\n\nüìö Bibliograf√≠a\n\n\n\n\n\n\nRojas-Jimenez, K. 2022. Ciencia de Datos para Ciencias Naturales.¬†https://bookdown.org/keilor_rojas/CienciaDatos/\nLowndes, Julie & Horst, Allison. 2020. R for Excel Users. https://jules32.github.io/r-for-excel-users/\nR-Data Frames. 2025. https://www.geeksforgeeks.org/r-language/r-data-frames/\n\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html",
    "href": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html",
    "title": "M√≥dulo 5: Probabilidad",
    "section": "",
    "text": "En este m√≥dulo exploraremos las funciones de masa de probabilidad para variables discretas y las funciones de densidad de probabilidad (pdf) para variables continuas. Comprenderemos c√≥mo estas funciones nos permiten describir la probabilidad de que un evento ocurra en un conjunto de datos biol√≥gicos. Tambi√©n, profundizaremos en conceptos clave como el valor esperado y la varianza, que nos ayudan a caracterizar el centro y la dispersi√≥n de una distribuci√≥n.\nAprender√°s a utilizar el poder de R para trabajar con diferentes distribuciones de probabilidad. Cada distribuci√≥n en R tiene cuatro funciones clave, identificadas por un prefijo:\n\np: para la funci√≥n de distribuci√≥n acumulada (cdf) en un valor particular.\nq: para los cuantiles (la funci√≥n inversa de la cdf) correspondientes a una probabilidad particular.\nd: para la funci√≥n de densidad (pdf) en un valor particular.\nr: para la generaci√≥n de valores aleatorios de una distribuci√≥n particular."
  },
  {
    "objectID": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#introducci√≥n",
    "href": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#introducci√≥n",
    "title": "M√≥dulo 5: Probabilidad",
    "section": "",
    "text": "En este m√≥dulo exploraremos las funciones de masa de probabilidad para variables discretas y las funciones de densidad de probabilidad (pdf) para variables continuas. Comprenderemos c√≥mo estas funciones nos permiten describir la probabilidad de que un evento ocurra en un conjunto de datos biol√≥gicos. Tambi√©n, profundizaremos en conceptos clave como el valor esperado y la varianza, que nos ayudan a caracterizar el centro y la dispersi√≥n de una distribuci√≥n.\nAprender√°s a utilizar el poder de R para trabajar con diferentes distribuciones de probabilidad. Cada distribuci√≥n en R tiene cuatro funciones clave, identificadas por un prefijo:\n\np: para la funci√≥n de distribuci√≥n acumulada (cdf) en un valor particular.\nq: para los cuantiles (la funci√≥n inversa de la cdf) correspondientes a una probabilidad particular.\nd: para la funci√≥n de densidad (pdf) en un valor particular.\nr: para la generaci√≥n de valores aleatorios de una distribuci√≥n particular."
  },
  {
    "objectID": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#objetivos",
    "href": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#objetivos",
    "title": "M√≥dulo 5: Probabilidad",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\nDistinguir y aplicar las funciones de masa de probabilidad para variables discretas y las funciones de densidad para variables continuas.\nCalcular el valor esperado y la varianza para caracterizar distribuciones de probabilidad.\nImplementar en R los m√©todos de conteo como combinaciones, permutaciones y factoriales.\nDominar las cuatro funciones clave (p, q, d, r) para trabajar con las principales distribuciones de probabilidad en R.\nResolver problemas pr√°cticos de probabilidad, utilizando R como alternativa a las tablas estad√≠sticas para obtener valores de distribuci√≥n.\nInterpretar y generar datos pseudo-aleatorios a partir de distribuciones espec√≠ficas en R, comprendiendo la importancia de la replicabilidad."
  },
  {
    "objectID": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#desarrollo",
    "href": "biostats/M√≥dulo 5 - Probabilidad/mod5_proba.html#desarrollo",
    "title": "M√≥dulo 5: Probabilidad",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\nLa probabilidad cl√°sica se basa en el principio de resultados igualmente probables. Si un experimento tiene un espacio muestral finito \\(S\\) con \\(n\\) resultados igualmente probables, y \\(A\\) es un evento de inter√©s dentro de \\(S\\), la probabilidad cl√°sica se define como: \\[P(A)=\\dfrac{n({A})}{n(S)}\\] Donde:\n\n\\(P(A)\\): probabilidad del evento\n\\(n(A)\\): n√∫mero de resultados favorables al evento\n\\(n(S)\\): n√∫mero total de resultados posibles en el espacio muestral \\(S\\).\n\nEn resumen, la probabilidad de un evento se obtiene dividiendo el n√∫mero de resultados favorables entre el total de resultados igualmente probables.\nLanzar una Moneda\nCalculemos la probabilidad de obtener Cara (Heads) al lanzar una moneda justa.\n\noutcomes &lt;- c(\"Heads\", \"Tails\")\ntotal_outcomes &lt;- length(outcomes)\nfavorable_outcomes &lt;- length(outcomes[outcomes == \"Heads\"])\n\nclassical_prob &lt;- favorable_outcomes / total_outcomes\nclassical_prob\n\n[1] 0.5\n\n\nSe define un experimento de lanzar una moneda:\n\noutcomes &lt;- c(\"Heads\", \"Tails\"): crea un vector con los dos posibles resultados: ‚ÄúCara‚Äù y ‚ÄúCruz‚Äù.\ntotal_outcomes &lt;- length(outcomes): obtiene el n√∫mero total de resultados posibles, en este caso 2.\nfavorable_outcomes &lt;- length(outcomes[outcomes == \"Heads\"]): cuenta los resultados favorables, es decir, cu√°ntas veces aparece ‚ÄúCara‚Äù en el vector (1 vez).\nclassical_prob &lt;- favorable_outcomes / total_outcomes: calcula la probabilidad cl√°sica dividiendo los resultados favorables entre el total (1/2 = 0.5).\nclassical_prob: muestra la probabilidad de obtener ‚ÄúCara‚Äù al lanzar una moneda justa, que es 0.5.\n\nBaraja de Cartas\nCalcular la probabilidad de sacar una espada de una baraja est√°ndar de 52 cartas.\n\ndeck &lt;- rep(c(\"Spades\", \"Hearts\", \"Diamonds\", \"Clubs\"), each = 13)\ntotal_cards &lt;- length(deck)\nspades &lt;- length(deck[deck == \"Spades\"])\n\nclassical_prob_spade &lt;- spades / total_cards\nclassical_prob_spade\n\n[1] 0.25\n\n\nEste c√≥digo nos ayuda a calcular la probabilidad de sacar una pica de una baraja normal. Como hay 52 cartas en total y 13 de ellas son picas, la probabilidad de sacar una pica es de 13 sobre 52, lo que se puede simplificar a 1 sobre 4 o 25 %. Por lo tanto, al sacar una carta de una baraja normal, hay un 25 % de probabilidad de que sea pica.\nComo parte del material complementario del m√≥dulo se recomienda la lectura de la introducci√≥n a la probabilidad desde la parte hist√≥rica disponible a trav√©s del siguiente link Chapter 9 Introduction to probability del libro Learning Statistics with R de Danielle Navarro.\n\nM√©todos de Conteo\n\nFactorial\nF√≥rmula\n\\[\nn! = n \\cdot (n-1) \\cdot (n-2) \\cdots 2 \\cdot 1, \\quad n \\geq 0\n\\]\nPropiedad especial \\[0! = 1\\]\nImplementaci√≥n en R\n\nfactorial(n)\n\n\n\nPermutaciones sin repetici√≥n\nF√≥rmula\nN√∫mero de formas de ordenar \\(n\\) elementos distintos:\n\\[P(n) = n!\\]\nN√∫mero de permutaciones de \\(n\\) elementos tomados de \\(k\\):\n\\[P(n,k) = \\frac{n!}{(n-k)!}, \\quad 0 \\leq k \\leq n\\]\nImplementaci√≥n en R\n\n# Permutaciones de n elementos tomados de k\npermutations &lt;- function(n, k) {\n  factorial(n) / factorial(n - k)\n}\n\npermutations(5, 3) # Ejemplo: permutaciones de 5 elementos tomados de 3\n\n[1] 60\n\n\n\n\nPermutaciones con repetici√≥n\nF√≥rmula\nSi hay \\(n\\) elementos con grupos repetidos de tama√±os \\(n_1, n_2, \\dots, n_r\\):\n\\[P = \\frac{n!}{n_1! \\, n_2! \\cdots n_r!}\\]\nImplementaci√≥n en R\n\n# Permutaciones con repetici√≥n\npermutations_with_repetition &lt;- function(counts) {\n  factorial(sum(counts)) / prod(factorial(counts))\n}\n\n# Ejemplo: letras de la palabra \"MAMA\"\npermutations_with_repetition(c(2,1,1))\n\n[1] 12\n\n\n\n\nCombinaciones sin repetici√≥n\nF√≥rmula\nN√∫mero de formas de elegir \\(k\\) elementos de un conjunto de \\(n\\):\n\\[C(n,k) = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}, \\quad 0 \\leq k \\leq n \\]\n\nchoose(n, k)\n\n# Ejemplo: n√∫mero de formas de elegir 3 items de 5 items\nchoose(5, 3)\n\nGenerar Combinaciones\nSuponga que desea generar todas las combinaciones de \\(n\\) elementos (items) tomando \\(k\\) cada vez.\n\nitems &lt;- 2:5\nk &lt;- 2\ncombn(items, k)\n\n     [,1] [,2] [,3] [,4] [,5] [,6]\n[1,]    2    2    2    3    3    4\n[2,]    3    4    5    4    5    5\n\n\nOtro ejemplo ser√≠a generar todas las combinaciones de los n√∫meros 1 al 5 tomando de a tres:\n\ncombn(1:5, 3)\n\n     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]\n[1,]    1    1    1    1    1    1    2    2    2     3\n[2,]    2    2    2    3    3    4    3    3    4     4\n[3,]    3    4    5    4    5    5    4    5    5     5\n\n\nEsta funci√≥n combn() no se restringe a n√∫meros. Tambien podemos generar combinaciones de cadenas de caracteres:\n\ncombn(c(\"T1\", \"T2\", \"T3\", \"T4\"), 3)\n\n     [,1] [,2] [,3] [,4]\n[1,] \"T1\" \"T1\" \"T1\" \"T2\"\n[2,] \"T2\" \"T2\" \"T3\" \"T3\"\n[3,] \"T3\" \"T4\" \"T4\" \"T4\"\n\n\n\n\nCombinaciones con repetici√≥n (combinaciones con reemplazo)\nF√≥rmula\nN√∫mero de formas de elegir \\(k\\) elementos de un conjunto de \\(n\\) con repetici√≥n:\n\\[\nC_r(n,k) = \\binom{n+k-1}{k}\n\\]\nImplementaci√≥n en R\n\ncombinations_with_repetition &lt;- function(n, k) {\n  choose(n + k - 1, k)\n}\n\ncombinations_with_repetition(3, 2) # Ejemplo: elegir 2 de 3 con repetici√≥n\n\n[1] 6\n\n\n\n\nCoeficiente Multinomial\nF√≥rmula\nPara particionar \\(n\\) elementos en \\(k\\) grupos de tama√±os \\(n_1, n_2, \\dots, n_k\\):\n\\[\\binom{n}{n_1, n_2, \\dots, n_k} = \\frac{n!}{n_1! \\, n_2! \\cdots n_k!}, \\quad \\sum_{i=1}^k n_i = n\\]\n\nmultinomial_coefficient &lt;- function(counts) {\n  factorial(sum(counts)) / prod(factorial(counts))\n}\n\n# Ejemplo: particionar 5 en grupos de tama√±os 2,2,1\nmultinomial_coefficient(c(2,2,1))\n\n[1] 30\n\n\n\n\n\nDistribuciones Discretas\n\nDistribuci√≥n Uniforme\nFunci√≥n de Masa de Probabilidad\n\\[P(X = x) = \\frac{1}{b-a+1}, \\quad x = a, a+1, \\dots, b\\]\nValor Esperado\n\\[\nE[X] = \\frac{a+b}{2}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{(b-a+1)^2 - 1}{12}\n\\]\nImplementaci√≥n en R\n\n# Probabilidad\ndunif(x, min = a, max = b)\n\n# Funci√≥n de distribuci√≥n\npunif(q, min = a, max = b)\n\n# Cuantiles\nqunif(p, min = a, max = b)\n\n# Generaci√≥n\nrunif(n, min = a, max = b)\n\n\n\nDistribuci√≥n de Bernoulli\nFunci√≥n de Masa de Probabilidad \\[\nP(X = x) = p^x (1-p)^{1-x}, \\quad x \\in \\{0,1\\}\n\\] Valor Esperado \\[\nE[X] = p\n\\] Varianza \\[\nVar(X) = p(1-p)\n\\] Implementaci√≥n en R\n\n# Probabilidad\ndbinom(x, size = 1, prob = p)\n\n# Funci√≥n de distribuci√≥n\npbinom(q, size = 1, prob = p)\n\n# Cuantiles\nqbinom(p, size = 1, prob = p)\n\n# Generaci√≥n\nrbinom(n, size = 1, prob = p)\n\n\n\nDistribuci√≥n de Binomial\nFunci√≥n de Masa de Probabilidad\n\\[\nP(X = x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0,1,\\dots,n\n\\]\nValor Esperado\n\\[\nE[X] = np\n\\]\nVarianza\n\\[\nVar(X) = np(1-p)\n\\]\nImplementaci√≥n en R\n\ndbinom(x, size = n, prob = p)\npbinom(q, size = n, prob = p)\nqbinom(p, size = n, prob = p)\nrbinom(n, size = n, prob = p)\n\n\n\nDistribuci√≥n Binomial Negativa\nFunci√≥n de Masa de Probabilidad\n\\[\nP(X = x) = \\binom{x+r-1}{x} (1-p)^x p^r, \\quad x = 0,1,2,\\dots\n\\]\nValor Esperado\n\\[\nE[X] = r \\frac{1-p}{p}\n\\]\nVarianza\n\\[\nVar(X) = r \\frac{1-p}{p^2}\n\\]\nImplementaci√≥n en R\n\ndnbinom(x, size = r, prob = p)\npnbinom(q, size = r, prob = p)\nqnbinom(p, size = r, prob = p)\nrnbinom(n, size = r, prob = p)\n\n\n\nDistribuci√≥n Geom√©trica\nFunci√≥n de Masa de Probabilidad\n\\[\nP(X = x) = (1-p)^{x-1}p, \\quad x = 1,2,3,\\dots\n\\]\nValor Esperado\n\\[\nE[X] = \\frac{1}{p}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{1-p}{p^2}\n\\]\nImplementaci√≥n en R\n\ndgeom(x, prob = p)      # Nota: en R cuenta \"fracasos antes del primer √©xito\"\npgeom(q, prob = p)\nqgeom(p, prob = p)\nrgeom(n, prob = p)\n\n\n\nDistribuci√≥n Hipergeom√©trica\nFunci√≥n de Masa de Probabilidad\n\\[\nP(X = x) = \\frac{\\binom{K}{x} \\binom{N-K}{n-x}}{\\binom{N}{n}}, \\quad x = 0,1,\\dots,n\n\\]\nValor Esperado\n\\[\nE[X] = n \\frac{K}{N}\n\\]\nVarianza\n\\[\nVar(X) = n \\frac{K}{N}\\left(1-\\frac{K}{N}\\right)\\frac{N-n}{N-1}\n\\]\nImplementaci√≥n en R\n\ndhyper(x, m = K, n = N-K, k = n)\nphyper(q, m = K, n = N-K, k = n)\nqhyper(p, m = K, n = N-K, k = n)\nrhyper(nn, m = K, n = N-K, k = n)\n\n\n\nDistribuci√≥n Poisson\nFunci√≥n de Masa de Probabilidad\n\\[\nP(X = x) = \\frac{\\lambda^x e^{-\\lambda}}{x!}, \\quad x = 0,1,2,\\dots\n\\]\nValor Esperado\n\\[\nE[X] = \\lambda\n\\]\nVarianza\n\\[\nVar(X) = \\lambda\n\\]\nImplementaci√≥n en R\n\ndpois(x, lambda = lmb)\nppois(q, lambda = lmb)\nqpois(p, lambda = lmb)\nrpois(n, lambda = lmb)\n\n\n\n\n\n\n\nAproximaciones\n\n\n\n\\(Hg(N,M,n)\\longrightarrow Bin(n,p)\\)\nSea \\(0&lt;p&lt;1\\). Si \\(N\\), \\(M\\longrightarrow\\infty\\) , de tal forma que \\(\\frac{M}{N} \\longrightarrow p\\). El Tama√±o de la poblaci√≥n \\(N\\) es ‚Äúgrande‚Äù en comparaci√≥n con el tama√±o de la muestra \\(n\\), es decir, \\(\\frac{n}{N}\\longrightarrow 0\\)\n\\(Bin(n,p) \\longrightarrow Poi(\\lambda)\\) si \\(0&lt;p&lt;1\\) y \\(n\\cdot p \\longrightarrow \\lambda\\) cuando \\(n \\longrightarrow \\infty\\) . Se tiene un \\(n\\) muy ‚Äúgrande‚Äù comparado con un \\(p\\) muy ‚Äúpeque√±o‚Äù\n\n\n\n\n\nDistribuciones Continuas\n\nDistribuci√≥n Uniforme\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\begin{cases} \\frac{1}{b-a}, & a \\leq x \\leq b \\\\ 0, & \\text{en otro caso} \\end{cases}\n\\]\nValor Esperado\n\\[\nE[X] = \\frac{a+b}{2}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{(b-a)^2}{12}\n\\]\nImplementaci√≥n en R\n\n# Densidad\ndunif(x, min = a, max = b)\n\n# Funci√≥n de distribuci√≥n acumulada\npunif(q, min = a, max = b)\n\n# Cuantiles\nqunif(p, min = a, max = b)\n\n# Generaci√≥n de valores\nrunif(n, min = a, max = b)\n\n\n\nDistribuci√≥n Normal\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left( -\\frac{(x-\\mu)^2}{2\\sigma^2} \\right), \\quad -\\infty &lt; x &lt; \\infty\n\\]\nValor Esperado\n\\[\nE[X] = \\mu\n\\]\nVarianza\n\\[\nVar(X) = \\sigma^2\n\\]\nImplementaci√≥n en R\n\ndnorm(x, mean = mu, sd = sigma)\npnorm(q, mean = mu, sd = sigma)\nqnorm(p, mean = mu, sd = sigma)\nrnorm(n, mean = mu, sd = sigma)\n\n\n\nDistribuci√≥n Gamma\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\frac{\\beta^\\alpha}{\\Gamma(\\alpha)} x^{\\alpha - 1} e^{-\\beta x}, \\quad x &gt; 0\n\\]\nValor Esperado\n\\[\nE[X] = \\frac{\\alpha}{\\beta}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{\\alpha}{\\beta^2}\n\\]\nImplementaci√≥n en R\n\ndgamma(x, shape = alpha, rate = beta)   # tambi√©n: scale = 1/beta\npgamma(q, shape = alpha, rate = beta)\nqgamma(p, shape = alpha, rate = beta)\nrgamma(n, shape = alpha, rate = beta)\n\n\n\nDistribuci√≥n Exponencial\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\lambda e^{-\\lambda x}, \\quad x \\geq 0\n\\]\nValor Esperado\n\\[\nE[X] = \\frac{1}{\\lambda}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{1}{\\lambda^2}\n\\]\nImplementaci√≥n en R\n\ndexp(x, rate = lambda)\npexp(q, rate = lambda)\nqexp(p, rate = lambda)\nrexp(n, rate = lambda)\n\n\n\nDistribuci√≥n Chi - Cuadrado\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\frac{1}{2^{k/2}\\Gamma(k/2)} x^{k/2 - 1} e^{-x/2}, \\quad x \\geq 0\n\\]\nValor Esperado\n\\[\nE[X] = k\n\\]\nVarianza\n\\[\nVar(X) = 2k\n\\]\nImplementaci√≥n en R\n\ndchisq(x, df = k)\npchisq(q, df = k)\nqchisq(p, df = k)\nrchisq(n, df = k)\n\n\n\nDistribuci√≥n Beta\nFunci√≥n de Densidad de Probabilidad\n\\[\nf(x) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha)\\Gamma(\\beta)} x^{\\alpha - 1} (1-x)^{\\beta - 1}, \\quad 0 &lt; x &lt; 1\n\\]\nValor Esperado\n\\[\nE[X] = \\frac{\\alpha}{\\alpha + \\beta}\n\\]\nVarianza\n\\[\nVar(X) = \\frac{\\alpha \\beta}{(\\alpha + \\beta)^2 (\\alpha + \\beta + 1)}\n\\]\nImplementaci√≥n en R\n\ndbeta(x, shape1 = alpha, shape2 = beta)\npbeta(q, shape1 = alpha, shape2 = beta)\nqbeta(p, shape1 = alpha, shape2 = beta)\nrbeta(n, shape1 = alpha, shape2 = beta)\n\n\n\n\n\n\n\n\nDistribution\nFunctions (CDF p*, Quantile q*, Density d*, Random r*)\n\n\n\n\nBernoulli\npbinom, qbinom, dbinom, rbinom (con size = 1)\n\n\nBinomial\npbinom, qbinom, dbinom, rbinom\n\n\nNegative Binomial\npnbinom, qnbinom, dnbinom, rnbinom\n\n\nGeometric\npgeom, qgeom, dgeom, rgeom\n\n\nHypergeometric\nphyper, qhyper, dhyper, rhyper\n\n\nPoisson\nppois, qpois, dpois, rpois\n\n\nUniform (discrete)\nNo funci√≥n directa, usar sample() o runif() con redondeo\n\n\nUniform (continuous)\npunif, qunif, dunif, runif\n\n\nNormal\npnorm, qnorm, dnorm, rnorm\n\n\nLog Normal\nplnorm, qlnorm, dlnorm, rlnorm\n\n\nCauchy\npcauchy, qcauchy, dcauchy, rcauchy\n\n\nExponential\npexp, qexp, dexp, rexp\n\n\nGamma\npgamma, qgamma, dgamma, rgamma\n\n\nChi-Square\npchisq, qchisq, dchisq, rchisq\n\n\nBeta\npbeta, qbeta, dbeta, rbeta\n\n\nWeibull\npweibull, qweibull, dweibull, rweibull\n\n\nF\npf, qf, df, rf\n\n\nStudent t\npt, qt, dt, rt\n\n\nStudentized Range\nptukey, qtukey, dtukey, rtukey\n\n\nLogistic\nplogis, qlogis, dlogis, rlogis\n\n\nWilcoxon Rank Sum Statistic\npwilcox, qwilcox, dwilcox, rwilcox\n\n\nWilcoxon Signed Rank Statistic\npsignrank, qsignrank, dsignrank, rsignrank\n\n\n\n\n\n\nUso de R como alternativa a las tablas de valores para las distribuciones.\n\n\n\nRepresentaci√≥n del √°rea acumulada a la izquierda de la puntuaci√≥n Z.\n\n\nLa funci√≥n pnorm() - Probabilidad Acumulada - Calcula la probabilidad acumulada hasta un valor q (z), por defecto corresponde al √°rea a la izquierda de q.\n\npnorm(q = 1.96, mean = 0, sd = 1)\n\n[1] 0.9750021\n\n\nDevuelve ‚âà 0.975, que corresponde a la probabilidad de que una variable normal est√°ndar sea menor o igual que 1.96.\n\nA este resultado es al que llegar√≠amos buscando en la t√≠pica tabla de los anexos de los libros de probabilidad. Usted puede comprobar el resultado observando la primera columna de la primera tabla dirigi√©ndose hasta el valor 1.9 y luego desplaz√°ndose de manera horizontal hasta hacer una intersecci√≥n con el valor .06 de la primera fila.\n\n\n\n\n\n\nUso de lower.tail\n\nlower.tail = TRUE (valor por defecto): √°rea a la izquierda de q.\n\n\n\nlower.tail = FALSE: √°rea a la derecha de q.\n\n\npnorm(q = 1.96, lower.tail = FALSE)\n\n[1] 0.0249979\n\n\nDevuelve ‚âà 0.025, que es el √°rea a la derecha de 1.96. Que tambi√©n podemos ver como 1 - 0.975.\nValor cr√≠tico (cuantil) - qnorm()\nHace el proceso inverso: dado un nivel de probabilidad acumulada p, devuelve el valor de q correspondiente en la distribuci√≥n.\n\nqnorm(p = 0.975, mean = 0, sd = 1)\n\n[1] 1.959964\n\n\nDevuelve ‚âà 1.96, el valor cr√≠tico de la normal est√°ndar para un nivel de confianza del 95%.\nEjemplo:\nSupongamos que la estatura de los hombres en una poblaci√≥n se distribuye ~ Normal(Œº = 170, œÉ = 6).\n\n¬øCu√°l es la probabilidad de que un hombre mida menos de 175 cm?\n\n\npnorm(q = 175, mean = 170, sd = 6)\n\n[1] 0.7976716\n\n\nEs decir, 79.8%.\n\n¬øCu√°l es la probabilidad de que mida m√°s de 175 cm?\n\n\npnorm(q = 175, mean = 170, sd = 6, lower.tail = FALSE)\n\n[1] 0.2023284\n\n\nEs decir, 20.2%.\n\n¬øQu√© estatura corresponde al percentil 90?\n\n\nqnorm(p = 0.90, mean = 170, sd = 6)\n\n[1] 177.6893\n\n\nUn hombre debe medir al menos 177.7 cm para estar en el 10% m√°s alto de la poblaci√≥n.\n\n\n\n\n\n\nAnotaciones\n\n\n\n\nTen en cuenta que al hacer uso de las funciones para la generaci√≥n de valores aleatorios de una distribuci√≥n particular, realmente se producen valores pseudo-aleatorios. ¬ø¬°Por qu√©, cu√°l es la diferencia!?\nEl uso de la semilla garantizar√° la replicabilidad de los resultados obtenidos al generar esos datos a trav√©s de estas funciones.\n\n\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html",
    "href": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html",
    "title": "M√≥dulo 7: M√©todos de Regresi√≥n",
    "section": "",
    "text": "El an√°lisis de regresi√≥n es una herramienta fundamental en bioestad√≠stica para estudiar la relaci√≥n entre una variable respuesta y una o m√°s variables explicativas. En este m√≥dulo nos enfocaremos en el modelo lineal simple o normal, uno de los m√©todos m√°s utilizados para describir y predecir relaciones lineales entre variables cuantitativas.\nA lo largo del m√≥dulo, se abordar√° la formulaci√≥n te√≥rica del modelo, los supuestos que lo sustentan, y los m√©todos necesarios para su ajuste e interpretaci√≥n en el entorno de programaci√≥n R. Adem√°s, se explorar√°n herramientas diagn√≥sticas que permiten evaluar la validez del modelo, identificar observaciones at√≠picas o influyentes, y proponer posibles transformaciones cuando los supuestos no se cumplen.\nEl enfoque de este m√≥dulo estar√° orientado a darle las herramientas necesarias para que pueda realizar una implementaci√≥n del modelo con datos reales, un an√°lisis de la salida generada por R e interpretar adecuadamente los resultados en contextos aplicados de la bioestad√≠stica."
  },
  {
    "objectID": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#introducci√≥n",
    "href": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#introducci√≥n",
    "title": "M√≥dulo 7: M√©todos de Regresi√≥n",
    "section": "",
    "text": "El an√°lisis de regresi√≥n es una herramienta fundamental en bioestad√≠stica para estudiar la relaci√≥n entre una variable respuesta y una o m√°s variables explicativas. En este m√≥dulo nos enfocaremos en el modelo lineal simple o normal, uno de los m√©todos m√°s utilizados para describir y predecir relaciones lineales entre variables cuantitativas.\nA lo largo del m√≥dulo, se abordar√° la formulaci√≥n te√≥rica del modelo, los supuestos que lo sustentan, y los m√©todos necesarios para su ajuste e interpretaci√≥n en el entorno de programaci√≥n R. Adem√°s, se explorar√°n herramientas diagn√≥sticas que permiten evaluar la validez del modelo, identificar observaciones at√≠picas o influyentes, y proponer posibles transformaciones cuando los supuestos no se cumplen.\nEl enfoque de este m√≥dulo estar√° orientado a darle las herramientas necesarias para que pueda realizar una implementaci√≥n del modelo con datos reales, un an√°lisis de la salida generada por R e interpretar adecuadamente los resultados en contextos aplicados de la bioestad√≠stica."
  },
  {
    "objectID": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#objetivos",
    "href": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#objetivos",
    "title": "M√≥dulo 7: M√©todos de Regresi√≥n",
    "section": "üéØ Objetivos",
    "text": "üéØ Objetivos\n\nFormular e interpretar el modelo lineal simple bajo el enfoque cl√°sico y sus supuestos fundamentales.\nAjustar el modelo lineal simple utilizando funciones del entorno R.\nSeleccionar variables explicativas relevantes para el modelo.\nAnalizar los residuos y coeficientes del modelo para evaluar su ajuste.\nInterpretar los par√°metros estimados y la calidad global del modelo.\nAplicar t√©cnicas diagn√≥sticas para detectar problemas como heterocedasticidad, colinealidad, influencia y puntos de apalancamiento, proponiendo soluciones mediante transformaciones cuando sea necesario."
  },
  {
    "objectID": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#contenido",
    "href": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#contenido",
    "title": "M√≥dulo 7: M√©todos de Regresi√≥n",
    "section": "üß∞ Contenido",
    "text": "üß∞ Contenido\n\nSelecci√≥n de variables\nAjuste del modelo\nInformaci√≥n de los residuos\nInformaci√≥n sobre los coeficientes\nInformaci√≥n sobre el modelo\nInterpretaci√≥n de los resultados\nM√©todos diagn√≥sticos\n7.1. An√°lisis residual\n7.2. An√°lisis de sensibilidad o influencia\n7.3. Puntos de apalancamiento\n7.4. Heterocedasticidad\n7.5. Colinealidad\n7.6 Transformaciones"
  },
  {
    "objectID": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#desarrollo",
    "href": "biostats/M√≥dulo 7 - Regresi√≥n/mod7_regre.html#desarrollo",
    "title": "M√≥dulo 7: M√©todos de Regresi√≥n",
    "section": "üìñ Desarrollo",
    "text": "üìñ Desarrollo\n\nModelo Lineal\n\n1. Formulaci√≥n y supuestos\nEn un modelo de regresi√≥n lineal simple se estudia la relaci√≥n entre una variable dependiente \\(Y\\) y una sola variable explicativa \\(X\\):\n\\[Y_i=\\beta_0+\\beta_1X_i+\\varepsilon_i \\quad i=1,2,\\dots, n\\]\ndonde:\n\n\\(Y_i:\\) variable respuesta para la observaci√≥n \\(i\\).\n\\(X_i:\\) variable explicativa para la observaci√≥n \\(i\\).\n\\(\\beta_0:\\) intercepto o t√©rmino constante.\n\\(\\beta_1:\\) pendiente, mide el cambio esperado en \\(Y\\) por un cambio unitario en \\(X\\).\n\\(\\varepsilon_i:\\) t√©rmino de error aleatorio.\n\nEn un modelo de regresi√≥n lineal m√∫ltiple se estudia la relaci√≥n entre una variable dependiente \\(Y\\) y una varias variables explicativas \\((X_1, X_2, \\dots, X_p)\\) :\n\\[Y_i=\\beta_0+\\beta_1X_{i1}+\\beta_2X_{i2}+\\cdots+\\beta_pX_{ip}+\\varepsilon_i \\quad i=1,2,\\dots, n\\] Cuya forma matricial est√° dada por:\n\\[\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}\\] donde:\n\n\\(\\mathbf{Y}\\) es un vector \\(n\\times1\\) de la variable dependiente.\n\\(\\mathbf{Y}\\) es la matriz de dise√±o \\((n\\times(p+1))\\), que incluye una columna de 1‚Äôs para el intercepto.\n\\(\\boldsymbol{\\beta}\\) es el vector de par√°metros \\((p+1)\\times1\\)\n\\(\\boldsymbol{\\varepsilon}\\) es el vector de errores aleatorios\n\nAlgunos de los supuestos b√°sicos de la regresi√≥n lineal son los siguientes:\n\nLinealidad: la relaci√≥n entre \\(X\\) y \\(Y\\) es lineal.\nIndependencia: los errores son independientes entre s√≠.\nHomoscedasticidad: la varianza de los errores es constante.\nNo multicolinealidad (solo en modelos m√∫ltiples).\nNormalidad de los errores (opcional, seg√∫n el objetivo).\n\nSobre este √∫ltimo supuesto, no es necesario para estimar los coeficientes \\((\\hat{\\beta}_0,\\hat{\\beta}_1)\\) ya que gracias al teorema de Gauss‚ÄìMarkov, bajo los tres primeros supuestos los estimadores son insesgados y de varianza m√≠nima (BLUE). Sin embargo, s√≠ es necesario para la inferencia estad√≠stica: pruebas de significancia y construcci√≥n de intervalos de confianza.\nSi nos limitamos a estimar los coeficientes, a√∫n podremos:\n\nPredecir valores de \\(Y\\) para nuevos \\(X\\) a√∫n sin saber si la pendiente es ‚Äúsignificativamente distinta de cero‚Äù.\nDescribir la relaci√≥n observada, el coeficiente pendiente indica cu√°nto cambia \\(Y\\) en promedio cuando \\(X\\) cambia una unidad, en la muestra observada, sin necesidad de inferir a la poblaci√≥n.\nRevisar el ajuste global del modelo (R¬≤, residuos, etc.)\n\nLuego, si el prop√≥sito es predecir o describir, basta con estimar coeficientes, pero si se desea generalizar a la poblaci√≥n o validar hip√≥tesis, requerimos inferencia, por efecto, normalidad o tama√±o de muestra ‚Äúgrande‚Äù para que de manera asint√≥tica esta sea respaldada por el teorema central del l√≠mite.\n\n\n2. Comentarios sobre la interpretaci√≥n de las salidas de R\n\nEvaluar el efecto del termino interacci√≥n en el modelo, es esencialmente, examinar si el efecto de una variable en el resultado depende de los valores de otra variable.\nEl resultado de un modelo de regresi√≥n en R al hacer uso de la rutina summary(modelo) consiste en 4 partes:\n\nFormula del modelo ajustado\nEstad√≠stica descriptiva de los residuos\nEste resumen estad√≠stico de los residuos, representa las diferencias entre las predicciones del modelo y las observaciones reales. Los residuos muestran que tan bien no se ajusta el modelo. La media de los residuos siempre es cero. Si los residuos se distribuyen con distribuci√≥n normal, la mediana se espera que sea cero o un valor muy cercano a este, el primer y tercer cuartil sean sim√©tricos al igual que el m√≠nimo y el m√°ximo.\nInformaci√≥n sobre coeficientes\nEsta secci√≥n muestra 4 apartados que se detallan a continuaci√≥n:\n\nCoeficientes estimados (‚ÄúESTIMATE‚Äù): contiene los valores de cada variable explicatoria que representan el efecto de esa variable sobre la variable dependiente.\nErrores est√°ndar (‚ÄúStd. Error‚Äù): es el valor que mide que tan precisa es la estimaci√≥n de cada coeficiente. Valores altos indican que la predicci√≥n es menos precisa.\nValores t (‚Äút-values‚Äù): valor estad√≠stico para probar que el coeficiente no es cero. Un valor positivo o negativo indica que el coeficiente no es cero. Entre m√°s grande el valor, se indica que el coeficiente es mas fiable. \\(t=estimate/std. error\\)\nValores p (‚Äúp-values‚Äù): indican la probabilidad de obtener un resultado tan extremo como el observado (o m√°s), suponiendo que la hip√≥tesis nula es verdadera. En el caso de un coeficiente de regresi√≥n, la hip√≥tesis nula plantea que dicho coeficiente es igual a cero (es decir, que la variable no tiene efecto).\nSi el \\(valor-p &lt; 0.05\\), existe evidencia estad√≠sticamente significativa al nivel del 5% para rechazar la hip√≥tesis nula y concluir que el coeficiente es distinto de cero.\n\nInformaci√≥n sobre el modelo\n\nLa interpretaci√≥n de los coeficientes se suele dar como sigue: Un incremento de una unidad en la variable distancia, causa un incremento de 4.96 unidades.\nEl intercepto representa el valor predicho de la variable dependiente cuando las otras variables son cero.\nLa linealidad del modelo est√° dada por los coeficientes (los \\(\\beta\\)‚Äôs) mas no hay restricciones de la naturaleza de las covariables respecto a esta caracter√≠stica.\nEl sistema de hip√≥tesis para los coeficientes es el siguiente:\n\\[H_0:\\beta_j=\\beta_j¬∞ \\quad \\text{vs} \\quad H_1:\\beta_j\\neq\\beta_j¬∞\\]\nla regla de decisi√≥n para el anterior sistema de hip√≥tesis es:\nRechazar H_0 con un nivel de significancia de \\(100(\\alpha)\\%\\) si \\(p-value &lt; \\alpha\\)\nDe aqu√≠, el error tipo 1 consiste en rechazar \\(H_0\\) cuando ella es verdadera y el error tipo 2 consiste en no rechazar \\(H_0\\) cuando es falsa.\nExisten varias rutinas disponibles en R para seleccionar variables significativas. algunas de estas son:\nBest Subset Selection\n\nlibrary(leaps)\nfit_a &lt;- regsubsets(Y ~ ., data = datos, nvmax = 10)  # hasta 10 predictores\nsummary(fit_a)\n\nSelecci√≥n paso a paso (Stepwise Selection)\n\nlibrary(glmtoolbox)\ndata(Auto, package = \"ISLR\")\nfit_b &lt;- lm(mpg ~ horsepower + weight +origin, data = Auto)  \nstepCriterion(fit_b, direction=\"forward\", criterion=\"bic\")\n\n\n\n\n3. Ejemplo 1: races - glmtoolbox\nEstos datos, disponibles en el objeto ‚Äúraces‚Äù de la biblioteca ‚Äúglmtoolbox‚Äù, consisten en el tiempo r√©cord, la distancia y la subida acumulada de 35 carreras en cuesta en Escocia. El objetivo del an√°lisis estad√≠stico de estos datos es explicar las diferencias entre el tiempo r√©cord de las carreras (rtime), en minutos, utilizando sus diferencias en distancia (distance), en millas, y subida acumulada (cclimb), en miles de pies.\n\nlibrary(glmtoolbox) \ndata(races)\n\n\nAjuste a los datos un modelo lineal normal en el que el tiempo r√©cord de las carreras sea la variable de respuesta, y la distancia y la subida acumulada sean las variables explicativas.\n\n\nfit &lt;- lm(rtime ~ distance + cclimb, data = races)\n\n\nEval√∫e al nivel de signiÔ¨Åcancia del 5% si el efecto de la distancia sobre el tiempo r√©cord esperado de la carrera depende de la escalada acumulada.\n\n\nfit2 &lt;- lm(rtime ~ distance + cclimb + distance:cclimb, data = races)\nsummary(fit2)\n\n\nCall:\nlm(formula = rtime ~ distance + cclimb + distance:cclimb, data = races)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-23.197  -2.797   0.628   2.243  18.963 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      -0.7672     3.9058  -0.196  0.84556    \ndistance          4.9623     0.4742  10.464 1.07e-11 ***\ncclimb            3.7133     2.3647   1.570  0.12650    \ndistance:cclimb   0.6598     0.1743   3.786  0.00066 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7.338 on 31 degrees of freedom\nMultiple R-squared:  0.9807,    Adjusted R-squared:  0.9788 \nF-statistic: 524.1 on 3 and 31 DF,  p-value: &lt; 2.2e-16\n\nanova(fit,fit2)\n\nAnalysis of Variance Table\n\nModel 1: rtime ~ distance + cclimb\nModel 2: rtime ~ distance + cclimb + distance:cclimb\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1     32 2441.3                                  \n2     31 1669.4  1    771.89 14.334 0.0006597 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nInterprete las estimaciones de los par√°metros, excepto el t√©rmino de intercepci√≥n.\n\nInterpretaci√≥n de la estimaci√≥n de distacia: Por cada milla recorrida se incrementan 4.96 minutos en el tiempo record manteniendo constante la subida acumulada en la carrera. Altamente significante para un nivel del 5%.\nInterpretaci√≥n de la estimacion de subida acumulada: Por cada mil pies que se suban hay un incremento de 3.71 minutos en el tiempo tiempo record manteniendo constante la distancia que se recorre en la carrera. Sin embargo el p-valor no es significante para un nivel del 5%.\nInterpretaci√≥n de la estimacion de la interacci√≥n entre distancia y subida acumulada: Por cada unidad incrementada en la interacci√≥n entre distancia y subida acumulada, el cambio esperado en el tiempo record ser√° aproximadamente de 0.66 unidades, manteniendo las otras variables constantes.\n\nEstime el tiempo r√©cord esperado, en minutos, de una carrera cuya distancia y ascenso acumulado son 7.5 millas y 1800 pies, respectivamente. Calcule esta estimaci√≥n ‚Äúmanualmente‚Äù y utilizando la funci√≥n predict()\n\nManualmente:\n\nfit$coefficients\n\n(Intercept)    distance      cclimb \n -13.108551    6.350955   11.780133 \n\ndistance &lt;- 7.5\ncclimb &lt;- 1.8\n\nrtime = -13.108551 + 6.350955*distance + 11.780133*cclimb\nrtime\n\n[1] 55.72785\n\n\nUsando la funci√≥n predict()\n\nnew_distance &lt;- 7.5\nnew_cclimb &lt;- 1.8\n\ny &lt;- predict(fit, newdata = data.frame(distance=new_distance, cclimb=new_cclimb))\n\ny\n\n       1 \n55.72785 \n\n\n\n\n4. Ejemplo 2: whiteside - MASS\nEstos datos, disponibles en el objeto whiteside de la biblioteca MASS, se recopilaron para evaluar el efecto del aislamiento en el consumo de gas. El consumo semanal de gas (Gas), en miles de pies c√∫bicos, y la temperatura exterior media (Temp), en grados cent√≠grados, se registraron durante 26 semanas antes (Insul=‚ÄúAntes‚Äù) y durante 30 semanas despu√©s (Insul=‚ÄúDespu√©s‚Äù) de que se instalara un aislamiento de la pared hueca de una casa.\n\nlibrary(MASS)\ndata(\"whiteside\")\n\n\nAjuste a los datos un modelo lineal normal en el que el consumo de gas sea la variable de respuesta, y la temperatura exterior media y la presencia/ausencia de aislamiento de la pared de la cavidad sean las variables explicativas.\n\nfit3 &lt;- lm(Gas ~ Temp + Insul, data = whiteside)\n\n\\[\nGas = 6.55133 ‚àí 0.33670(Temp) ‚àí 1.56520\n\\]\nEval√∫e al nivel de signiÔ¨Åcancia del 5% si el efecto de la temperatura exterior media sobre el consumo de gas esperado depende de la presencia/ausencia de aislamiento en la pared.\n\nfit4 &lt;- lm(Gas ~ Temp*Insul, data = whiteside)\nsummary(fit4)\n\n\nCall:\nlm(formula = Gas ~ Temp * Insul, data = whiteside)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.97802 -0.18011  0.03757  0.20930  0.63803 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      6.85383    0.13596  50.409  &lt; 2e-16 ***\nTemp            -0.39324    0.02249 -17.487  &lt; 2e-16 ***\nInsulAfter      -2.12998    0.18009 -11.827 2.32e-16 ***\nTemp:InsulAfter  0.11530    0.03211   3.591 0.000731 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.323 on 52 degrees of freedom\nMultiple R-squared:  0.9277,    Adjusted R-squared:  0.9235 \nF-statistic: 222.3 on 3 and 52 DF,  p-value: &lt; 2.2e-16\n\nanova(fit4)\n\nAnalysis of Variance Table\n\nResponse: Gas\n           Df Sum Sq Mean Sq F value    Pr(&gt;F)    \nTemp        1 35.019  35.019 335.655 &lt; 2.2e-16 ***\nInsul       1 33.224  33.224 318.451 &lt; 2.2e-16 ***\nTemp:Insul  1  1.345   1.345  12.893 0.0007307 ***\nResiduals  52  5.425   0.104                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nAl nivel de significancia del 5%, existe evidencia estad√≠sticamente significativa (0.00073 &lt; 0.05) de que el impacto de un incremento en la temperatura exterior media sobre el consumo de gas depende de la presencia/ausencia de aislamiento en la pared. El consumo de gas esperado disminuye tras la instalaci√≥n del aislamiento, pero la velocidad a la que ocurre esta disminuci√≥n se acent√∫a a medida que la temperatura aumenta.\nInterprete las estimaciones de los par√°metros excepto el t√©rmino de intercepci√≥n.\nInterpretaci√≥n de la estimaci√≥n de la temperatura: Por cada grado centr√≠grado que se incrementa la temperatura exterior, se disminuyen 0.39324 miles de pies c√∫bicos en el consumo semanal de gas. Altamente significante para un nivel del 5%.\n\nInterpretaci√≥n de la estimacion de la instalaci√≥n del aislamiento (despu√©s): Tras la instalacion del aislamiento de la pared hueca de la casa, se disminuyen 2.12998 miles de pies c√∫bico en el consumo de gas semanal esperado, controlando por temperatura. Altamente significante para un nivel del 5%.\n\nInterpretaci√≥n de la interacci√≥n entre estimacion de la temperatura e instalaci√≥n del aislamiento (despu√©s): La velocidad a la que disminuye el consumo de gas semanal es diferente con la ausencia o presencia de aislameinto en la pared de la casa. El cambio esperado en el consumo de gas semanal esperado sera de 0.1153 unidades posterior a la instalaci√≥n del aislamiento e incrementando la temperatura una unidad.\nEstime el consumo de gas esperado, en miles de pies c√∫bicos, en una semana en la que la temperatura exterior media sea de 5 grados cent√≠grados y el aislamiento de la pared est√© presente. Calcule esta estimaci√≥n ‚Äúmanualmente‚Äù y utilizando la funci√≥n predict(). ##### 2.1 Selecci√≥n de variables\n4.1 Estimaci√≥n manual :\n\nfit3$coefficients\n\n(Intercept)        Temp  InsulAfter \n   6.551329   -0.336697   -1.565205 \n\nTemp &lt;- 5\nInsulAfter &lt;- 1\nGas = 6.551329 + -0.336697*Temp - 1.565205*InsulAfter\nGas\n\n[1] 3.302639\n\n\n4.2 Estimaci√≥n con funci√≥n predict() :\n\nnew_Temp &lt;- 5\ny &lt;- predict(fit3, newdata = data.frame(Temp = new_Temp, Insul = \"After\"))\ny\n\n       1 \n3.302639 \n\n\nEn una semana, donde la temperatura promedio exterior es de 5¬∞C y el aislamiento en la pared hueca de la casa ya se encuentra instalado, el consumo de gas estimado ser√° de 3.3026 miles de pies c√∫bicos.\n\n\nCopyright ¬© 2025 Jose Miguel Leon - Created with Quarto"
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Proyectos de Investigaci√≥n",
    "section": "",
    "text": "LATENT STRUCTURES OF THE CARE ECONOMY IN COLOMBIA: AN APPROACH WITH MIXTURE MODELS, ECONOMETRIC MODELS AND STATISTICAL LEARNING\n\n\n\n\n\n\nPublished version on Memories of the 34th International Symposium on Statistics\n\n\nMathematical modeling through allometry:\nstrategies for classroom teaching"
  }
]